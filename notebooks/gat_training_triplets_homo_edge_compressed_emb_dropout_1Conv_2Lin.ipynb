{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T08:47:00.419518Z",
     "start_time": "2024-11-06T08:47:00.416700Z"
    }
   },
   "source": [
    "from util import *\n",
    "from training_heterogeneous import *\n",
    "from gat_models import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn.modules.loss import TripletMarginLoss\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.shared.graph_schema import *\n",
    "from src.shared.graph_sampling import GraphSampling\n",
    "\n",
    "random.seed(40)\n",
    "np.random.seed(40)\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed_all(40)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configurations",
   "id": "ee4fa502d7e51e50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:47:00.465085Z",
     "start_time": "2024-11-06T08:47:00.461887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Graph sampling configurations\n",
    "node_spec = [\n",
    "    NodeType.PUBLICATION,\n",
    "]\n",
    "\n",
    "edge_spec = [\n",
    "    EdgeType.SIM_AUTHOR,\n",
    "]\n",
    "\n",
    "node_properties = [\n",
    "    'id',\n",
    "    'feature_vec',\n",
    "]\n",
    "\n",
    "database = 'homogeneous-graph-compressed-emb'\n",
    "gs = GraphSampling(\n",
    "    node_spec=node_spec,\n",
    "    edge_spec=edge_spec,\n",
    "    node_properties=node_properties,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# Model configurations\n",
    "\n",
    "config = {\n",
    "    'experiment': 'GATv2 encoder (1 Conv layer, 2 linear layers + dropout) trained on homogeneous graph (publication nodes with title and abstract, co-author edges) using Triplet Loss and dimension reduced embeddings',\n",
    "    'max_hops': 3,\n",
    "    'model_node_feature': 'feature_vec',  # Node feature to use for GAT encoder\n",
    "    'hidden_channels': 64,\n",
    "    'out_channels': 16,\n",
    "    'num_heads': 8,\n",
    "    'margin': 1.0,\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "model_class = HeteroGATEncoder1Conv2LinearDropout\n",
    "loss_fn = TripletMarginLoss(margin=config['margin'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TODO: Adjust result folder name!\n",
    "result_folder_name = 'homo_edges compressed_emb 1Conv 2Linear dropout'\n",
    "result_folder_path = f'./data/results/{result_folder_name}'\n",
    "if not os.path.exists(result_folder_path):\n",
    "    os.mkdir(result_folder_path)"
   ],
   "id": "91b04efb689d61f4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Configuration",
   "id": "b67cf89d3d17cc12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T08:47:00.536478Z",
     "start_time": "2024-11-06T08:47:00.508546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DatabaseWrapper(database=database)\n",
    "data_harvester = TripletDataHarvester(db=db, gs=gs, edge_spec=edge_spec, config=config)\n",
    "\n",
    "\n",
    "# Split the pairs into train and test\n",
    "\n",
    "train_size = int(0.85 * len(data_harvester.triplets))\n",
    "test_size = int(0.1 * len(data_harvester.triplets))\n",
    "eval_size = len(data_harvester.triplets) - train_size - test_size\n",
    "\n",
    "# Harvest the evaluation triplets first, since triplets are ordered by author. This will ensure that the evaluation set has authors not seen in the training set.\n",
    "eval_triplets = data_harvester.triplets[:eval_size]\n",
    "\n",
    "train_test_triplets = data_harvester.triplets[eval_size:]\n",
    "random.shuffle(train_test_triplets)\n",
    "\n",
    "train_triplets = train_test_triplets[:train_size]\n",
    "test_triplets = train_test_triplets[train_size:]\n",
    "config['train_size'] = len(train_triplets)\n",
    "config['test_size'] = len(test_triplets)\n",
    "config['eval_size'] = len(eval_triplets)\n",
    "\n",
    "print(f\"Train size: {len(train_triplets)}, Test size: {len(test_triplets)}, Eval size: {len(eval_triplets)}\")\n",
    "\n",
    "# Create the datasets from the pairs (distinct pairs for training and testing)\n",
    "train_dataset = GraphTripletDataset(train_triplets, gs, config=config)\n",
    "test_dataset = GraphTripletDataset(test_triplets, gs, config=config)\n",
    "eval_dataset = GraphTripletDataset(eval_triplets, gs, config=config)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_triplet_collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "\n",
    "# Create model\n",
    "metadata = (\n",
    "    [n.value for n in node_spec],\n",
    "    [edge_pyg_key_vals[r] for r in edge_spec]\n",
    ")\n",
    "config['node_spec'] = metadata[0]\n",
    "config['edge_spec'] = metadata[1]\n",
    "model = model_class(metadata, config['hidden_channels'], config['out_channels'], num_heads=config['num_heads']).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])"
   ],
   "id": "62ef1028a5c5fd5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 09:47:00,511 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-11-06 09:47:00,512 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing triplets...\n",
      "Loading triplets...\n",
      "Loaded 11755 triplets.\n",
      "Train size: 9991, Test size: 1175, Eval size: 589\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "bdf9a36f9d9a6f43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-06T08:47:00.565027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = config['num_epochs']\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_correct_pos = []\n",
    "test_correct_neg = []\n",
    "\n",
    "eval_losses = []\n",
    "eval_accuracies = []\n",
    "eval_correct_pos = []\n",
    "eval_correct_neg = []\n",
    "\n",
    "current_batch = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"=== Epoch {epoch}/{num_epochs} ======================\")\n",
    "    epoch_marker_pos = list(range(0, len(train_dataloader) * epoch, len(train_dataloader)))\n",
    "    current_batch = 1\n",
    "    for batch_anchor, batch_pos, batch_neg in tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "        if batch_anchor is None or batch_pos is None or batch_neg is None:\n",
    "            continue\n",
    "        \n",
    "        if current_batch == 1 or current_batch == len(train_dataloader) // 2:\n",
    "            print(f\"___ Current Batch {current_batch}/{len(train_dataloader)} _________________________\")\n",
    "            # Model testing\n",
    "            print(\"    Test Results:\")\n",
    "            test_loss, test_num_correct, test_correct_pos_val, test_correct_neg_val = test(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=test_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracies.append(test_num_correct)\n",
    "            test_correct_pos.append(test_correct_pos_val)\n",
    "            test_correct_neg.append(test_correct_neg_val)\n",
    "    \n",
    "            plot_loss(test_losses, epoch_len=2, plot_title='Test Loss', plot_avg=False, plot_file=result_folder_path + '/test_loss.png')\n",
    "            plot_loss(\n",
    "                test_accuracies,\n",
    "                epoch_len=2,\n",
    "                plot_title='Test Accuracy',\n",
    "                plot_avg=False, \n",
    "                x_label='Test Iterations',\n",
    "                y_label='Accuracy',\n",
    "                line_label='Accuracy',\n",
    "                plot_file=result_folder_path + '/test_accuracy.png'\n",
    "            )\n",
    "            \n",
    "            # Model evaluation\n",
    "            print(\"    Eval Results:\")\n",
    "            eval_loss, eval_num_correct, eval_correct_pos_val, eval_correct_neg_val = evaluate(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=eval_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            eval_losses.append(eval_loss)\n",
    "            eval_accuracies.append(eval_num_correct)\n",
    "            eval_correct_pos.append(eval_correct_pos_val)\n",
    "            eval_correct_neg.append(eval_correct_neg_val)\n",
    "            \n",
    "            plot_loss(eval_losses, epoch_len=2, plot_title='Evaluation Loss', plot_avg=False, plot_file=result_folder_path + '/eval_loss.png')\n",
    "            plot_loss(\n",
    "                eval_accuracies, \n",
    "                epoch_len=2, \n",
    "                plot_title='Evaluation Accuracy', \n",
    "                plot_avg=False, \n",
    "                x_label='Eval Iterations',\n",
    "                y_label='Accuracy',\n",
    "                line_label='Accuracy',\n",
    "                plot_file=result_folder_path + '/eval_accuracy.png'\n",
    "            )\n",
    "            \n",
    "        loss = train(\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            batch_anchor=batch_anchor,\n",
    "            batch_pos=batch_pos,\n",
    "            batch_neg=batch_neg,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        plot_loss(train_losses, epoch_len=len(train_dataloader), plot_title='Training Loss', plot_avg=True, plot_file=result_folder_path + '/train_loss.png')\n",
    "        current_batch += 1\n",
    "        \n",
    "    # Save config and training results\n",
    "    eval_results = {\n",
    "        'eval_losses': eval_losses,\n",
    "        'eval_accuracies': eval_accuracies,\n",
    "        'eval_correct_pos': eval_correct_pos,\n",
    "        'eval_correct_neg': eval_correct_neg\n",
    "    }\n",
    "    save_training_results(train_losses, test_losses, eval_results, config, result_folder_path + '/training_data.json')\n",
    "    \n",
    "    # Save model if loss has decreased\n",
    "    if len(test_losses) > 1 and test_losses[-1] < min(test_losses[:-1]):\n",
    "        print(f\"Saving model at epoch {epoch}...\")\n",
    "        torch.save(model.state_dict(), result_folder_path + '/gat_encoder.pt')"
   ],
   "id": "c3b28cd52881796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb69be849bba48138e49ccffea16ce52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 1175 (100.00%), Correct negative: 0 (0.00%)\n",
      "Total correct: 1175 (50.00%)\n",
      "Test Loss: 1.0096, Test Accuracy: 0.5000\n",
      "    Eval Results:\n",
      "Correct positive: 589 (100.00%), Correct negative: 0 (0.00%)\n",
      "Total correct: 589 (50.00%)\n",
      "Eval Loss: 1.0170, Eval Accuracy: 0.5000\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 509 (43.32%), Correct negative: 880 (74.89%)\n",
      "Total correct: 1389 (59.11%)\n",
      "Test Loss: 0.7189, Test Accuracy: 0.5911\n",
      "    Eval Results:\n",
      "Correct positive: 153 (25.98%), Correct negative: 509 (86.42%)\n",
      "Total correct: 662 (56.20%)\n",
      "Eval Loss: 0.7596, Eval Accuracy: 0.5620\n",
      "Saving model at epoch 1...\n",
      "=== Epoch 2/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0297721031f440d6872f57e6d4e42cd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 304 (25.87%), Correct negative: 1007 (85.70%)\n",
      "Total correct: 1311 (55.79%)\n",
      "Test Loss: 0.6892, Test Accuracy: 0.5579\n",
      "    Eval Results:\n",
      "Correct positive: 91 (15.45%), Correct negative: 541 (91.85%)\n",
      "Total correct: 632 (53.65%)\n",
      "Eval Loss: 0.7255, Eval Accuracy: 0.5365\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 297 (25.28%), Correct negative: 1069 (90.98%)\n",
      "Total correct: 1366 (58.13%)\n",
      "Test Loss: 0.5476, Test Accuracy: 0.5813\n",
      "    Eval Results:\n",
      "Correct positive: 60 (10.19%), Correct negative: 557 (94.57%)\n",
      "Total correct: 617 (52.38%)\n",
      "Eval Loss: 0.9080, Eval Accuracy: 0.5238\n",
      "Saving model at epoch 2...\n",
      "=== Epoch 3/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f77d1d8965c4282b56671dec4b14adb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 145 (12.34%), Correct negative: 1112 (94.64%)\n",
      "Total correct: 1257 (53.49%)\n",
      "Test Loss: 0.5676, Test Accuracy: 0.5349\n",
      "    Eval Results:\n",
      "Correct positive: 29 (4.92%), Correct negative: 564 (95.76%)\n",
      "Total correct: 593 (50.34%)\n",
      "Eval Loss: 0.9690, Eval Accuracy: 0.5034\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 189 (16.09%), Correct negative: 1126 (95.83%)\n",
      "Total correct: 1315 (55.96%)\n",
      "Test Loss: 0.4473, Test Accuracy: 0.5596\n",
      "    Eval Results:\n",
      "Correct positive: 49 (8.32%), Correct negative: 562 (95.42%)\n",
      "Total correct: 611 (51.87%)\n",
      "Eval Loss: 0.7700, Eval Accuracy: 0.5187\n",
      "Saving model at epoch 3...\n",
      "=== Epoch 4/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eba1161cb95b4c7ca154c68a95e528ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 175 (14.89%), Correct negative: 1123 (95.57%)\n",
      "Total correct: 1298 (55.23%)\n",
      "Test Loss: 0.4407, Test Accuracy: 0.5523\n",
      "    Eval Results:\n",
      "Correct positive: 29 (4.92%), Correct negative: 566 (96.10%)\n",
      "Total correct: 595 (50.51%)\n",
      "Eval Loss: 0.7324, Eval Accuracy: 0.5051\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 162 (13.79%), Correct negative: 1139 (96.94%)\n",
      "Total correct: 1301 (55.36%)\n",
      "Test Loss: 0.3942, Test Accuracy: 0.5536\n",
      "    Eval Results:\n",
      "Correct positive: 27 (4.58%), Correct negative: 564 (95.76%)\n",
      "Total correct: 591 (50.17%)\n",
      "Eval Loss: 0.8220, Eval Accuracy: 0.5017\n",
      "Saving model at epoch 4...\n",
      "=== Epoch 5/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fe31e4dd339400cb4aadab33a8d918e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 132 (11.23%), Correct negative: 1139 (96.94%)\n",
      "Total correct: 1271 (54.09%)\n",
      "Test Loss: 0.4057, Test Accuracy: 0.5409\n",
      "    Eval Results:\n",
      "Correct positive: 31 (5.26%), Correct negative: 565 (95.93%)\n",
      "Total correct: 596 (50.59%)\n",
      "Eval Loss: 0.8605, Eval Accuracy: 0.5059\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 161 (13.70%), Correct negative: 1132 (96.34%)\n",
      "Total correct: 1293 (55.02%)\n",
      "Test Loss: 0.3585, Test Accuracy: 0.5502\n",
      "    Eval Results:\n",
      "Correct positive: 28 (4.75%), Correct negative: 565 (95.93%)\n",
      "Total correct: 593 (50.34%)\n",
      "Eval Loss: 0.8146, Eval Accuracy: 0.5034\n",
      "Saving model at epoch 5...\n",
      "=== Epoch 6/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697cd0ee4b2b4e78a68a419ba7cfab88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 90 (7.66%), Correct negative: 1140 (97.02%)\n",
      "Total correct: 1230 (52.34%)\n",
      "Test Loss: 0.3672, Test Accuracy: 0.5234\n",
      "    Eval Results:\n",
      "Correct positive: 30 (5.09%), Correct negative: 572 (97.11%)\n",
      "Total correct: 602 (51.10%)\n",
      "Eval Loss: 0.9809, Eval Accuracy: 0.5110\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "Correct positive: 134 (11.40%), Correct negative: 1135 (96.60%)\n",
      "Total correct: 1269 (54.00%)\n",
      "Test Loss: 0.3207, Test Accuracy: 0.5400\n",
      "    Eval Results:\n",
      "Correct positive: 29 (4.92%), Correct negative: 561 (95.25%)\n",
      "Total correct: 590 (50.08%)\n",
      "Eval Loss: 0.7688, Eval Accuracy: 0.5008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m epoch_marker_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(train_dataloader) \u001B[38;5;241m*\u001B[39m epoch, \u001B[38;5;28mlen\u001B[39m(train_dataloader)))\n\u001B[1;32m     19\u001B[0m current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_anchor, batch_pos, batch_neg \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch_anchor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m batch_pos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m batch_neg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/tqdm/notebook.py:250\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    249\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m    253\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Git/master-thesis/notebooks/util.py:353\u001B[0m, in \u001B[0;36mGraphTripletDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    350\u001B[0m anchor, pos, neg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtriplets[idx]\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    352\u001B[0m     \u001B[38;5;66;03m# Get n-hop neighbourhood for each paper\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m     g_a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_hop_neighbourhood\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNodeType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPUBLICATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manchor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_hops\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m     g_p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, pos, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    355\u001B[0m     g_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, neg, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Git/master-thesis/src/shared/graph_sampling.py:55\u001B[0m, in \u001B[0;36mGraphSampling.n_hop_neighbourhood\u001B[0;34m(self, start_node_type, start_node_id, node_types, edge_types, max_level)\u001B[0m\n\u001B[1;32m     41\u001B[0m edge_filter \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     42\u001B[0m     [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m et \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_spec] \u001B[38;5;28;01mif\u001B[39;00m edge_types \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[1;32m     43\u001B[0m     [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m et \u001B[38;5;129;01min\u001B[39;00m edge_types]\n\u001B[1;32m     44\u001B[0m )\n\u001B[1;32m     46\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;124m        MATCH (start:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124mid: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124m        CALL apoc.path.subgraphAll(start, \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;124m        RETURN nodes, relationships\u001B[39m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 55\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m data \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39msingle()\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/session.py:313\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m bookmarks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bookmarks()\n\u001B[1;32m    312\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(parameters \u001B[38;5;129;01mor\u001B[39;00m {}, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 313\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_auto_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpersonated_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_access_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbookmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_min_severity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_disabled_categories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:181\u001B[0m, in \u001B[0;36mResult._run\u001B[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pull()\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39msend_all()\n\u001B[0;32m--> 181\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:301\u001B[0m, in \u001B[0;36mResult._attach\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exhausted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m--> 301\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:178\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py:846\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    845\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[0;32m--> 846\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponses\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    849\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_message(tag, fields)\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m monotonic()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:72\u001B[0m, in \u001B[0;36mInbox.pop\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpop\u001B[39m(\u001B[38;5;28mself\u001B[39m, hydration_hooks):\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer_one_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m         size, tag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpacker\u001B[38;5;241m.\u001B[39munpack_structure_header()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:51\u001B[0m, in \u001B[0;36mInbox._buffer_one_chunk\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m chunk_size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;66;03m# Determine the chunk size and skip noop\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m         \u001B[43mreceive_into_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_socket\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m         chunk_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer\u001B[38;5;241m.\u001B[39mpop_u16()\n\u001B[1;32m     53\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk_size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:326\u001B[0m, in \u001B[0;36mreceive_into_buffer\u001B[0;34m(sock, buffer, n_bytes)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(buffer\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;28;01mas\u001B[39;00m view:\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mused \u001B[38;5;241m<\u001B[39m end:\n\u001B[0;32m--> 326\u001B[0m         n \u001B[38;5;241m=\u001B[39m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mview\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mused\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mused\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    328\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py:493\u001B[0m, in \u001B[0;36mBoltSocket.recv_into\u001B[0;34m(self, buffer, nbytes)\u001B[0m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrecv_into\u001B[39m(\u001B[38;5;28mself\u001B[39m, buffer, nbytes):\n\u001B[0;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_io\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_socket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py:468\u001B[0m, in \u001B[0;36mBoltSocket._wait_for_io\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wait_for_io\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deadline \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 468\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    469\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_socket\u001B[38;5;241m.\u001B[39mgettimeout()\n\u001B[1;32m    470\u001B[0m     deadline_timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deadline\u001B[38;5;241m.\u001B[39mto_timeout()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
