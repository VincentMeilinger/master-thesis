{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T14:18:24.318934Z",
     "start_time": "2024-08-21T14:18:24.314996Z"
    }
   },
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot\n",
    "from src.shared import config\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:18:24.772008Z",
     "start_time": "2024-08-21T14:18:24.770060Z"
    }
   },
   "cell_type": "code",
   "source": "driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))",
   "id": "3a6f87824453abb4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:18:29.054866Z",
     "start_time": "2024-08-21T14:18:29.050807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [f\"<{et.value}\" for et in EdgeType] if edge_types is None else \n",
    "            [f\"<{et.value}\" for et in edge_types]\n",
    "        )\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '{edge_filter}',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        # Process nodes\n",
    "        node_data = []\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            node_data.append({\"nodeId\": node_id, node_attr: attr, \"nodeLabels\": list(node.labels)})\n",
    "        \n",
    "        node_df = pd.DataFrame(node_data)\n",
    "        \n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "        for rel in relationships:\n",
    "            if rel.type not in edge_dict:\n",
    "                edge_dict[rel.type] = [[], []]\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "            \n",
    "            edge_dict[rel.type][0].append(source_id)\n",
    "            edge_dict[rel.type][1].append(target_id)\n",
    "    \n",
    "    return node_df, edge_dict"
   ],
   "id": "76af4d06aa310b6b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T14:18:52.098391Z",
     "start_time": "2024-08-21T14:18:52.094361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_topology(new_idx_to_old, topology):\n",
    "    # Reverse index mapping based on new idx -> old idx\n",
    "    old_idx_to_new = dict((v, k) for k, v in new_idx_to_old.items())\n",
    "    return {rel_type: [[old_idx_to_new[node_id] for node_id in nodes] for nodes in topology] for rel_type, topology in topology.items()}\n",
    "\n",
    "def create_edge_index(topology):\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for rel_type, nodes in topology.items():\n",
    "        src_nodes, dst_nodes = nodes\n",
    "        edges = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "        edge_index.append(edges)\n",
    "        edge_feature_vec = edge_one_hot[rel_type]\n",
    "        edge_features.extend([edge_feature_vec for _ in range(len(src_nodes))])\n",
    "    return torch.cat(edge_index, dim=1), torch.vstack(edge_features)\n",
    "\n",
    "def project_node_embeddings(node_df):\n",
    "    def stack_one_hot(row):\n",
    "        one_hot_enc = node_one_hot[row[\"nodeLabels\"][0]]\n",
    "        return torch.hstack((one_hot_enc, torch.tensor(row[\"vec\"])))\n",
    "    return node_df.apply(stack_one_hot, axis=1)"
   ],
   "id": "6089817ba6f16189",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    #EdgeType.SIM_VENUE,\n",
    "    #EdgeType.SIM_ORG,\n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "]\n",
    "\n",
    "def sample_subgraph(node_list):\n",
    "    dataset = []\n",
    "    for node_id in node_list:\n",
    "        node_df, topology = fetch_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node_id, \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=5\n",
    "        )\n",
    "        node_df[\"vec_projected\"] = project_node_embeddings(node_df)\n",
    "        normalized_node_ids = {new_idx: old_idx for new_idx, old_idx in enumerate(node_df[\"nodeId\"])}\n",
    "        normalized_topology = normalize_topology(normalized_node_ids, topology)\n",
    "        if len(normalized_topology) == 0:\n",
    "            continue\n",
    "            \n",
    "        edge_index, edge_features = create_edge_index(normalized_topology)\n",
    "        node_features = torch.vstack(node_df[\"vec_projected\"].tolist())\n",
    "        \n",
    "        dataset.append(Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features\n",
    "        ))\n",
    "    return DataLoader(dataset)"
   ],
   "id": "b2b1f2cab33a61f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
