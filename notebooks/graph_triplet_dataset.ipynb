{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.729890Z",
     "start_time": "2024-08-22T17:32:10.725710Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.datasets.who_is_who import WhoIsWhoDataset\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot\n",
    "from src.shared import config\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.733391Z",
     "start_time": "2024-08-22T17:32:10.731132Z"
    }
   },
   "cell_type": "code",
   "source": "driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))",
   "id": "3a6f87824453abb4",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.738690Z",
     "start_time": "2024-08-22T17:32:10.734601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [f\"<{et.value}\" for et in EdgeType] if edge_types is None else \n",
    "            [f\"<{et.value}\" for et in edge_types]\n",
    "        )\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '{edge_filter}',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        if not data:\n",
    "            return None, None\n",
    "        \n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "        \n",
    "        # Process nodes\n",
    "        node_data = []\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            node_data.append({\"nodeId\": node_id, node_attr: attr, \"nodeLabels\": list(node.labels)})\n",
    "        \n",
    "        node_df = pd.DataFrame(node_data)\n",
    "        \n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "        for rel in relationships:\n",
    "            if rel.type not in edge_dict:\n",
    "                edge_dict[rel.type] = [[], []]\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "            \n",
    "            edge_dict[rel.type][0].append(source_id)\n",
    "            edge_dict[rel.type][1].append(target_id)\n",
    "    \n",
    "    return node_df, edge_dict"
   ],
   "id": "76af4d06aa310b6b",
   "outputs": [],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.743110Z",
     "start_time": "2024-08-22T17:32:10.739518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_topology(new_idx_to_old, topology):\n",
    "    # Reverse index mapping based on new idx -> old idx\n",
    "    old_idx_to_new = dict((v, k) for k, v in new_idx_to_old.items())\n",
    "    return {rel_type: [[old_idx_to_new[node_id] for node_id in nodes] for nodes in topology] for rel_type, topology in topology.items()}\n",
    "\n",
    "def create_edge_index(topology):\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for rel_type, nodes in topology.items():\n",
    "        src_nodes, dst_nodes = nodes\n",
    "        edges = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "        edge_index.append(edges)\n",
    "        edge_feature_vec = edge_one_hot[rel_type]\n",
    "        edge_features.extend([edge_feature_vec for _ in range(len(src_nodes))])\n",
    "    return torch.cat(edge_index, dim=1), torch.vstack(edge_features)\n",
    "\n",
    "def project_node_embeddings(node_df):\n",
    "    def stack_one_hot(row):\n",
    "        one_hot_enc = node_one_hot[row[\"nodeLabels\"][0]]\n",
    "        return torch.hstack((one_hot_enc, torch.tensor(row[\"vec\"])))\n",
    "    return node_df.apply(stack_one_hot, axis=1)"
   ],
   "id": "6089817ba6f16189",
   "outputs": [],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.748816Z",
     "start_time": "2024-08-22T17:32:10.744236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    #EdgeType.SIM_VENUE,\n",
    "    #EdgeType.SIM_ORG,\n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "]\n",
    "\n",
    "def sample_triplet(anchor, pos, neg):\n",
    "    triplet = {}\n",
    "    for label, node_id in zip([\"anchor\", \"pos\", \"neg\"], [anchor, pos, neg]):\n",
    "        node_df, topology = fetch_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node_id, \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=2\n",
    "        )\n",
    "        if node_df is None or len(node_df) == 0:\n",
    "            return None\n",
    "        if topology is None or len(topology) == 0:\n",
    "            return None\n",
    "        node_df[\"vec_projected\"] = project_node_embeddings(node_df)\n",
    "        if node_df[\"vec_projected\"].isnull().values.any():\n",
    "            return None\n",
    "        normalized_node_ids = {new_idx: old_idx for new_idx, old_idx in enumerate(node_df[\"nodeId\"])}\n",
    "        normalized_topology = normalize_topology(normalized_node_ids, topology)\n",
    "        if not normalized_topology or len(normalized_topology) == 0:\n",
    "            return None\n",
    "            \n",
    "        edge_index, edge_features = create_edge_index(normalized_topology)\n",
    "        node_features = torch.vstack(node_df[\"vec_projected\"].tolist())\n",
    "        \n",
    "        if len(node_features) == 0 or len(edge_index) == 0 or len(edge_features) == 0:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        graph = {\n",
    "            \"x\": node_features.tolist(),\n",
    "            \"edge_index\": edge_index.tolist(),\n",
    "            \"edge_attr\": edge_features.tolist(),\n",
    "            \"node_id\": node_id\n",
    "        }\n",
    "        triplet[label] = graph\n",
    "    \n",
    "    json.dumps(triplet, indent=2)\n",
    "    return triplet"
   ],
   "id": "b2b1f2cab33a61f0",
   "outputs": [],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:32:10.753996Z",
     "start_time": "2024-08-22T17:32:10.749577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TripleSampler:\n",
    "    def __init__(self):\n",
    "        self.data = WhoIsWhoDataset.parse_train()\n",
    "        \n",
    "    def iter_triplet_ids_rand(self, num_triplets):\n",
    "        # yield random triplets from the WhoIsWho dataset\n",
    "        current_num_triplets = 0\n",
    "        while current_num_triplets < num_triplets:\n",
    "            # Get random author\n",
    "            author_id = random.choice(list(self.data.keys()))\n",
    "            \n",
    "            # Check if author has enough data\n",
    "            normal_data = self.data[author_id][\"normal_data\"]\n",
    "            outliers = self.data[author_id][\"outliers\"]\n",
    "            if len(normal_data) < 2 or len(outliers) == 0:\n",
    "                self.data.pop(author_id)\n",
    "                continue\n",
    "            # Get random anchor, positive and negative samples, remove anchor\n",
    "            anchor_id = random.choice(normal_data)\n",
    "            self.data[author_id][\"normal_data\"].remove(anchor_id)\n",
    "            \n",
    "            pos_sample = random.choice(normal_data)\n",
    "            neg_sample = random.choice(outliers)\n",
    "            yield anchor_id, pos_sample, neg_sample\n",
    "            current_num_triplets += 1\n",
    "            \n",
    "    def sample_triplet_ids(self, attempt = 0):\n",
    "        if attempt > 30:\n",
    "            print(\"Unable to sample more triples\")\n",
    "            return None\n",
    "        # Get random author\n",
    "        author_id = random.choice(list(self.data.keys()))\n",
    "        \n",
    "        # Check if author has enough data\n",
    "        normal_data = self.data[author_id][\"normal_data\"]\n",
    "        outliers = self.data[author_id][\"outliers\"]\n",
    "        if len(normal_data) < 2 or len(outliers) == 0:\n",
    "            self.data.pop(author_id)\n",
    "            return self.sample_triplet_ids(attempt + 1)\n",
    "        # Get random anchor, positive and negative samples, remove anchor\n",
    "        anchor_id = random.choice(normal_data)\n",
    "        self.data[author_id][\"normal_data\"].remove(anchor_id)\n",
    "        \n",
    "        pos_sample = random.choice(normal_data)\n",
    "        neg_sample = random.choice(outliers)\n",
    "        return anchor_id, pos_sample, neg_sample\n",
    "\n",
    "    def iter_triplets_rand(self, num_triplets):\n",
    "        # Fetch triplets by id from the neo4j database and yield them\n",
    "        count = 0\n",
    "        count_skipped = 0\n",
    "        while count < num_triplets:                \n",
    "            anchor_id, pos_id, neg_id = self.sample_triplet_ids()\n",
    "            triplet = sample_triplet(anchor_id, pos_id, neg_id)\n",
    "            if triplet is None or type(triplet) is not dict:\n",
    "                count_skipped += 1\n",
    "                continue\n",
    "        \n",
    "            yield triplet\n",
    "            count += 1\n",
    "        #print(f\"Requested {num_triplets}, Fetched {count}, Skipped {count_skipped}\")"
   ],
   "id": "b101664d258f7f0e",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:36:42.905343Z",
     "start_time": "2024-08-22T17:32:10.754847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "triplet_sampler = TripleSampler()\n",
    "path = \"./data/triplet_dataset\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for batch_id in range(10000):\n",
    "    file = os.path.join(path, f\"triplet_batch_{batch_id}.json\")\n",
    "    with open(file, \"w\") as f:\n",
    "        data = []\n",
    "        for triplet in triplet_sampler.iter_triplets_rand(10):\n",
    "            #print(json.dumps(triplet, indent=2))\n",
    "            data.append(triplet)\n",
    "        \n",
    "        # Save the triplets to disk\n",
    "        print(f\"Saving batch {batch_id} to disk\")\n",
    "        f.write(json.dumps(data))"
   ],
   "id": "70de02ffe6f0d407",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving batch 0 to disk\n",
      "Saving batch 1 to disk\n",
      "Saving batch 2 to disk\n",
      "Saving batch 3 to disk\n",
      "Saving batch 4 to disk\n",
      "Saving batch 5 to disk\n",
      "Saving batch 6 to disk\n",
      "Saving batch 7 to disk\n",
      "Saving batch 8 to disk\n",
      "Saving batch 9 to disk\n",
      "Saving batch 10 to disk\n",
      "Saving batch 11 to disk\n",
      "Saving batch 12 to disk\n",
      "Saving batch 13 to disk\n",
      "Saving batch 14 to disk\n",
      "Saving batch 15 to disk\n",
      "Saving batch 16 to disk\n",
      "Saving batch 17 to disk\n",
      "Saving batch 18 to disk\n",
      "Saving batch 19 to disk\n",
      "Saving batch 20 to disk\n",
      "Saving batch 21 to disk\n",
      "Saving batch 22 to disk\n",
      "Saving batch 23 to disk\n",
      "Saving batch 24 to disk\n",
      "Saving batch 25 to disk\n",
      "Saving batch 26 to disk\n",
      "Saving batch 27 to disk\n",
      "Saving batch 28 to disk\n",
      "Saving batch 29 to disk\n",
      "Saving batch 30 to disk\n",
      "Saving batch 31 to disk\n",
      "Saving batch 32 to disk\n",
      "Saving batch 33 to disk\n",
      "Saving batch 34 to disk\n",
      "Saving batch 35 to disk\n",
      "Saving batch 36 to disk\n",
      "Saving batch 37 to disk\n",
      "Saving batch 38 to disk\n",
      "Saving batch 39 to disk\n",
      "Saving batch 40 to disk\n",
      "Saving batch 41 to disk\n",
      "Saving batch 42 to disk\n",
      "Saving batch 43 to disk\n",
      "Saving batch 44 to disk\n",
      "Saving batch 45 to disk\n",
      "Saving batch 46 to disk\n",
      "Saving batch 47 to disk\n",
      "Saving batch 48 to disk\n",
      "Saving batch 49 to disk\n",
      "Saving batch 50 to disk\n",
      "Saving batch 51 to disk\n",
      "Saving batch 52 to disk\n",
      "Saving batch 53 to disk\n",
      "Saving batch 54 to disk\n",
      "Saving batch 55 to disk\n",
      "Saving batch 56 to disk\n",
      "Saving batch 57 to disk\n",
      "Saving batch 58 to disk\n",
      "Saving batch 59 to disk\n",
      "Saving batch 60 to disk\n",
      "Saving batch 61 to disk\n",
      "Saving batch 62 to disk\n",
      "Saving batch 63 to disk\n",
      "Saving batch 64 to disk\n",
      "Saving batch 65 to disk\n",
      "Saving batch 66 to disk\n",
      "Saving batch 67 to disk\n",
      "Saving batch 68 to disk\n",
      "Saving batch 69 to disk\n",
      "Saving batch 70 to disk\n",
      "Saving batch 71 to disk\n",
      "Saving batch 72 to disk\n",
      "Saving batch 73 to disk\n",
      "Saving batch 74 to disk\n",
      "Saving batch 75 to disk\n",
      "Saving batch 76 to disk\n",
      "Saving batch 77 to disk\n",
      "Saving batch 78 to disk\n",
      "Saving batch 79 to disk\n",
      "Saving batch 80 to disk\n",
      "Saving batch 81 to disk\n",
      "Saving batch 82 to disk\n",
      "Saving batch 83 to disk\n",
      "Saving batch 84 to disk\n",
      "Saving batch 85 to disk\n",
      "Saving batch 86 to disk\n",
      "Saving batch 87 to disk\n",
      "Saving batch 88 to disk\n",
      "Saving batch 89 to disk\n",
      "Saving batch 90 to disk\n",
      "Saving batch 91 to disk\n",
      "Saving batch 92 to disk\n",
      "Saving batch 93 to disk\n",
      "Saving batch 94 to disk\n",
      "Saving batch 95 to disk\n",
      "Saving batch 96 to disk\n",
      "Saving batch 97 to disk\n",
      "Saving batch 98 to disk\n",
      "Saving batch 99 to disk\n",
      "Saving batch 100 to disk\n",
      "Saving batch 101 to disk\n",
      "Saving batch 102 to disk\n",
      "Saving batch 103 to disk\n",
      "Saving batch 104 to disk\n",
      "Saving batch 105 to disk\n",
      "Saving batch 106 to disk\n",
      "Saving batch 107 to disk\n",
      "Saving batch 108 to disk\n",
      "Saving batch 109 to disk\n",
      "Saving batch 110 to disk\n",
      "Saving batch 111 to disk\n",
      "Saving batch 112 to disk\n",
      "Saving batch 113 to disk\n",
      "Saving batch 114 to disk\n",
      "Saving batch 115 to disk\n",
      "Saving batch 116 to disk\n",
      "Saving batch 117 to disk\n",
      "Saving batch 118 to disk\n",
      "Saving batch 119 to disk\n",
      "Saving batch 120 to disk\n",
      "Saving batch 121 to disk\n",
      "Saving batch 122 to disk\n",
      "Saving batch 123 to disk\n",
      "Saving batch 124 to disk\n",
      "Saving batch 125 to disk\n",
      "Saving batch 126 to disk\n",
      "Saving batch 127 to disk\n",
      "Saving batch 128 to disk\n",
      "Saving batch 129 to disk\n",
      "Saving batch 130 to disk\n",
      "Saving batch 131 to disk\n",
      "Saving batch 132 to disk\n",
      "Saving batch 133 to disk\n",
      "Saving batch 134 to disk\n",
      "Saving batch 135 to disk\n",
      "Saving batch 136 to disk\n",
      "Saving batch 137 to disk\n",
      "Saving batch 138 to disk\n",
      "Saving batch 139 to disk\n",
      "Saving batch 140 to disk\n",
      "Saving batch 141 to disk\n",
      "Saving batch 142 to disk\n",
      "Saving batch 143 to disk\n",
      "Saving batch 144 to disk\n",
      "Saving batch 145 to disk\n",
      "Saving batch 146 to disk\n",
      "Saving batch 147 to disk\n",
      "Saving batch 148 to disk\n",
      "Saving batch 149 to disk\n",
      "Saving batch 150 to disk\n",
      "Saving batch 151 to disk\n",
      "Saving batch 152 to disk\n",
      "Saving batch 153 to disk\n",
      "Saving batch 154 to disk\n",
      "Saving batch 155 to disk\n",
      "Saving batch 156 to disk\n",
      "Saving batch 157 to disk\n",
      "Saving batch 158 to disk\n",
      "Saving batch 159 to disk\n",
      "Saving batch 160 to disk\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[267], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     10\u001B[0m     data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m triplet \u001B[38;5;129;01min\u001B[39;00m triplet_sampler\u001B[38;5;241m.\u001B[39miter_triplets_rand(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m#print(json.dumps(triplet, indent=2))\u001B[39;00m\n\u001B[1;32m     13\u001B[0m         data\u001B[38;5;241m.\u001B[39mappend(triplet)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;66;03m# Save the triplets to disk\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[266], line 54\u001B[0m, in \u001B[0;36mTripleSampler.iter_triplets_rand\u001B[0;34m(self, num_triplets)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m count \u001B[38;5;241m<\u001B[39m num_triplets:                \n\u001B[1;32m     53\u001B[0m     anchor_id, pos_id, neg_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_triplet_ids()\n\u001B[0;32m---> 54\u001B[0m     triplet \u001B[38;5;241m=\u001B[39m \u001B[43msample_triplet\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m triplet \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(triplet) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m     56\u001B[0m         count_skipped \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[0;32mIn[265], line 26\u001B[0m, in \u001B[0;36msample_triplet\u001B[0;34m(anchor, pos, neg)\u001B[0m\n\u001B[1;32m     24\u001B[0m triplet \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label, node_id \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manchor\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpos\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneg\u001B[39m\u001B[38;5;124m\"\u001B[39m], [anchor, pos, neg]):\n\u001B[0;32m---> 26\u001B[0m     node_df, topology \u001B[38;5;241m=\u001B[39m \u001B[43mfetch_n_hop_neighbourhood\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstart_node_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNodeType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPUBLICATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstart_node_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnode_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvec\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnode_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mincluded_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mincluded_edges\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[1;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m node_df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(node_df) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[263], line 22\u001B[0m, in \u001B[0;36mfetch_n_hop_neighbourhood\u001B[0;34m(start_node_type, start_node_id, node_attr, node_types, edge_types, max_level)\u001B[0m\n\u001B[1;32m     12\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124m        MATCH (start:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124mid: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124m        CALL apoc.path.subgraphAll(start, \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124m        RETURN nodes, relationships\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     21\u001B[0m result \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mrun(query)\n\u001B[0;32m---> 22\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msingle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:485\u001B[0m, in \u001B[0;36mResult.single\u001B[0;34m(self, strict)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;129m@NonConcurrentMethodChecker\u001B[39m\u001B[38;5;241m.\u001B[39mnon_concurrent_method\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msingle\u001B[39m(\u001B[38;5;28mself\u001B[39m, strict: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mOptional[Record]:\n\u001B[1;32m    451\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Obtain the next and only remaining record or None.\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \n\u001B[1;32m    453\u001B[0m \u001B[38;5;124;03m    Calling this method always exhausts the result.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;124;03m        * Can raise :exc:`.ResultConsumedError`.\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 485\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    486\u001B[0m     buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer \u001B[38;5;241m=\u001B[39m deque()\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:318\u001B[0m, in \u001B[0;36mResult._buffer\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    317\u001B[0m record_buffer \u001B[38;5;241m=\u001B[39m deque()\n\u001B[0;32m--> 318\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m    319\u001B[0m     record_buffer\u001B[38;5;241m.\u001B[39mappend(record)\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(record_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m n:\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:270\u001B[0m, in \u001B[0;36mResult.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discarding:\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discard()\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:178\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py:846\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    845\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[0;32m--> 846\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponses\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    849\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_message(tag, fields)\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m monotonic()\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:75\u001B[0m, in \u001B[0;36mInbox.pop\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     size, tag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpacker\u001B[38;5;241m.\u001B[39munpack_structure_header()\n\u001B[0;32m---> 75\u001B[0m     fields \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpacker\u001B[38;5;241m.\u001B[39munpack(hydration_hooks)\n\u001B[1;32m     76\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(size)]\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tag, fields\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;66;03m# Reset for new message\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:75\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m     size, tag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpacker\u001B[38;5;241m.\u001B[39munpack_structure_header()\n\u001B[0;32m---> 75\u001B[0m     fields \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpacker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(size)]\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tag, fields\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;66;03m# Reset for new message\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:292\u001B[0m, in \u001B[0;36mUnpacker.unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munpack\u001B[39m(\u001B[38;5;28mself\u001B[39m, hydration_hooks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 292\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:359\u001B[0m, in \u001B[0;36mUnpacker._unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;66;03m# List\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0x90\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0x9F\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0xD4\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xD6\u001B[39m:\n\u001B[0;32m--> 359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_list_items\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;66;03m# Map\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0xA0\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xAF\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0xD8\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xDA\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:395\u001B[0m, in \u001B[0;36mUnpacker._unpack_list_items\u001B[0;34m(self, marker, hydration_hooks)\u001B[0m\n\u001B[1;32m    393\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    394\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(size):\n\u001B[0;32m--> 395\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m marker \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0xD4\u001B[39m:  \u001B[38;5;66;03m# LIST_8:\u001B[39;00m\n\u001B[1;32m    397\u001B[0m     size, \u001B[38;5;241m=\u001B[39m struct_unpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>B\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:359\u001B[0m, in \u001B[0;36mUnpacker._unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;66;03m# List\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0x90\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0x9F\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0xD4\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xD6\u001B[39m:\n\u001B[0;32m--> 359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_list_items\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;66;03m# Map\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0xA0\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xAF\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0xD8\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xDA\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:403\u001B[0m, in \u001B[0;36mUnpacker._unpack_list_items\u001B[0;34m(self, marker, hydration_hooks)\u001B[0m\n\u001B[1;32m    401\u001B[0m     size, \u001B[38;5;241m=\u001B[39m struct_unpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>H\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(size):\n\u001B[0;32m--> 403\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m marker \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0xD6\u001B[39m:  \u001B[38;5;66;03m# LIST_32:\u001B[39;00m\n\u001B[1;32m    405\u001B[0m     size, \u001B[38;5;241m=\u001B[39m struct_unpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>I\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m4\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:374\u001B[0m, in \u001B[0;36mUnpacker._unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    372\u001B[0m value \u001B[38;5;241m=\u001B[39m Structure(tag, \u001B[38;5;241m*\u001B[39m([\u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m size))\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(value)):\n\u001B[0;32m--> 374\u001B[0m     value[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m hydration_hooks:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:365\u001B[0m, in \u001B[0;36mUnpacker._unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;66;03m# Map\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0xA0\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xAF\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0xD8\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xDA\u001B[39m:\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack_map\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;66;03m# Structure\u001B[39;00m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;241m0xB0\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m marker \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0xBF\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:422\u001B[0m, in \u001B[0;36mUnpacker._unpack_map\u001B[0;34m(self, marker, hydration_hooks)\u001B[0m\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(size):\n\u001B[1;32m    421\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpack(hydration_hooks\u001B[38;5;241m=\u001B[39mhydration_hooks)\n\u001B[0;32m--> 422\u001B[0m         value[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m marker \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0xD8\u001B[39m:  \u001B[38;5;66;03m# MAP_8:\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/packstream/v1/__init__.py:347\u001B[0m, in \u001B[0;36mUnpacker._unpack\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m marker_high \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0x80\u001B[39m:  \u001B[38;5;66;03m# TINY_STRING\u001B[39;00m\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(marker \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0x0F\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 347\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mmarker\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0xD0\u001B[39;49m:  \u001B[38;5;66;03m# STRING_8:\u001B[39;00m\n\u001B[1;32m    348\u001B[0m     size, \u001B[38;5;241m=\u001B[39m struct_unpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>B\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(size), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 267
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T17:36:42.906234Z",
     "start_time": "2024-08-22T17:36:42.906169Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "39b558c7a655980f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
