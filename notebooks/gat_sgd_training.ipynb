{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-13T16:26:56.079135Z",
     "start_time": "2024-08-13T16:26:56.071777Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot\n",
    "from src.shared import config"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:26:56.084965Z",
     "start_time": "2024-08-13T16:26:56.080782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "id": "f4212cea93939031",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:26:56.090251Z",
     "start_time": "2024-08-13T16:26:56.085861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_topology(new_idx_to_old, topology):\n",
    "    # Reverse index mapping based on new idx -> old idx\n",
    "    old_idx_to_new = dict((v, k) for k, v in new_idx_to_old.items())\n",
    "    return {rel_type: [[old_idx_to_new[node_id] for node_id in nodes] for nodes in topology] for rel_type, topology in topology.items()}\n",
    "\n",
    "def create_edge_index(topology):\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for rel_type, nodes in topology.items():\n",
    "        src_nodes, dst_nodes = nodes\n",
    "        edges = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "        edge_index.append(edges)\n",
    "        edge_feature_vec = edge_one_hot[rel_type]\n",
    "        edge_features.extend([edge_feature_vec for _ in range(len(src_nodes))])\n",
    "    return torch.cat(edge_index, dim=1), torch.vstack(edge_features)\n",
    "\n",
    "def project_node_embeddings(node_df):\n",
    "    def stack_one_hot(row):\n",
    "        one_hot_enc = node_one_hot[row[\"nodeLabels\"][0]]\n",
    "        return torch.hstack((one_hot_enc, torch.tensor(row[\"vec\"])))\n",
    "    return node_df.apply(stack_one_hot, axis=1)\n"
   ],
   "id": "7af7c76c9910e14a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:26:56.100662Z",
     "start_time": "2024-08-13T16:26:56.091834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))\n",
    "\n",
    "def fetch_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [f\"<{et.value}\" for et in EdgeType] if edge_types is None else\n",
    "            [f\"<{et.value}\" for et in edge_types]\n",
    "        )\n",
    "\n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '{edge_filter}',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        # Process nodes\n",
    "        node_data = []\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            node_data.append({\"nodeId\": node_id, node_attr: attr, \"nodeLabels\": list(node.labels)})\n",
    "\n",
    "        node_df = pd.DataFrame(node_data)\n",
    "\n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "        for rel in relationships:\n",
    "            if rel.type not in edge_dict:\n",
    "                edge_dict[rel.type] = [[], []]\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "\n",
    "            edge_dict[rel.type][0].append(source_id)\n",
    "            edge_dict[rel.type][1].append(target_id)\n",
    "\n",
    "    return node_df, edge_dict"
   ],
   "id": "ecf63735832cd563",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:26:56.106159Z",
     "start_time": "2024-08-13T16:26:56.101868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "included_nodes = [\n",
    "    NodeType.PUBLICATION,\n",
    "    NodeType.VENUE,\n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.SIM_VENUE,\n",
    "    EdgeType.SIM_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_CO_AUTHOR,\n",
    "    EdgeType.CO_AUTHOR_AUTHOR,\n",
    "    EdgeType.PUB_CO_AUTHOR,\n",
    "    EdgeType.CO_AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.CO_AUTHOR_ORG,\n",
    "    EdgeType.ORG_CO_AUTHOR\n",
    "]\n",
    "\n",
    "def sample_subgraph(node_list):\n",
    "    dataset = []\n",
    "    for node_id in node_list:\n",
    "        node_df, topology = fetch_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node_id, \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=3\n",
    "        )\n",
    "        node_df[\"vec_projected\"] = project_node_embeddings(node_df)\n",
    "        normalized_node_ids = {new_idx: old_idx for new_idx, old_idx in enumerate(node_df[\"nodeId\"])}\n",
    "        normalized_topology = normalize_topology(normalized_node_ids, topology)\n",
    "        if len(normalized_topology) == 0:\n",
    "            continue\n",
    "            \n",
    "        edge_index, edge_features = create_edge_index(normalized_topology)\n",
    "        node_features = torch.vstack(node_df[\"vec_projected\"].tolist())\n",
    "        \n",
    "        dataset.append(Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features\n",
    "        ))\n",
    "    return DataLoader(dataset)"
   ],
   "id": "16465ddeb3ddcffb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:28:14.373813Z",
     "start_time": "2024-08-13T16:26:56.107169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_wrapper = DatabaseWrapper()\n",
    "start_nodes = []\n",
    "for nodes in db_wrapper.iter_nodes(NodeType.PUBLICATION, [\"id\"]):\n",
    "    for node in nodes:\n",
    "        start_nodes.append(node[\"id\"])\n",
    "        \n",
    "    break\n",
    "dataset = sample_subgraph(start_nodes)"
   ],
   "id": "dc0cbea84e93fb80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 18:26:56,108 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-08-13 18:26:56,123 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:28:14.423492Z",
     "start_time": "2024-08-13T16:28:14.374905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_feature_dim = NodeType.PUBLICATION.one_hot().shape[0] + 32\n",
    "edge_feature_dim = EdgeType.SIM_TITLE.one_hot().shape[0]\n",
    "gat_embedding_dim = 32\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(device)\n",
    "\n",
    "encoder = GATv2Encoder(\n",
    "    in_channels=node_feature_dim,\n",
    "    hidden_channels=32,\n",
    "    out_channels=gat_embedding_dim,\n",
    "    edge_dim=edge_feature_dim,\n",
    "    add_self_loops=False\n",
    ")\n",
    "encoder.to(device)"
   ],
   "id": "65cda043db9a88fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GATv2Decoder(\n",
       "  (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:28:14.427401Z",
     "start_time": "2024-08-13T16:28:14.424294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_gat(encoder, dataloader, epochs=1000, lr=0.01):\n",
    "    # Define the optimizer for the encoder and decoder\n",
    "    optimizer = optim.SGD(list(encoder.parameters()), lr=lr)\n",
    "    \n",
    "    # Define a loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            batch.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the encoder\n",
    "            encoded_nodes = encoder(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "            # Compute loss \n",
    "            loss = criterion(decoded_graph, batch.x)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')"
   ],
   "id": "921a79247a6e9d92",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:37:46.877636Z",
     "start_time": "2024-08-13T16:28:14.428168Z"
    }
   },
   "cell_type": "code",
   "source": "train_gat(encoder, dataset)",
   "id": "f34c647ef5332c1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.3939819603860377\n",
      "Epoch 10, Loss: 0.7240211872756481\n",
      "Epoch 20, Loss: 0.6629132080674172\n",
      "Epoch 30, Loss: 0.6235688451975584\n",
      "Epoch 40, Loss: 0.5977477539926768\n",
      "Epoch 50, Loss: 0.5801704302728176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_gat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[15], line 31\u001B[0m, in \u001B[0;36mtrain_gat\u001B[0;34m(encoder, decoder, dataloader, epochs, lr)\u001B[0m\n\u001B[1;32m     28\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(decoded_graph, batch\u001B[38;5;241m.\u001B[39mx)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Optimize the parameters\u001B[39;00m\n\u001B[1;32m     34\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/master/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:37:46.879296Z",
     "start_time": "2024-08-13T16:37:46.879205Z"
    }
   },
   "cell_type": "code",
   "source": "# Idea: Predict links between papers purely based on graph structure depending on whether they were written by the same author",
   "id": "241a579e9f048ab7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
