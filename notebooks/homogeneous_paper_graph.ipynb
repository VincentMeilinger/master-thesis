{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T13:00:47.096641Z",
     "start_time": "2024-10-10T13:00:45.328224Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from src.datasets.who_is_who import WhoIsWhoDataset\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.shared.graph_schema import NodeType, EdgeType\n",
    "from src.shared.graph_sampling import GraphSampling\n",
    "from src.shared import config"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincie/.anaconda3/envs/master/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "f934f5daf06dbc1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:00:47.101130Z",
     "start_time": "2024-10-10T13:00:47.099613Z"
    }
   },
   "cell_type": "code",
   "source": "max_iterations = 10000",
   "id": "bb1b78124474912c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:00:47.146688Z",
     "start_time": "2024-10-10T13:00:47.144658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DatabaseWrapper(database='homogeneous-graph')\n",
    "#db.delete_all_nodes()"
   ],
   "id": "39befe6e82597c35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 15:00:47,145 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-10-10 15:00:47,145 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:00:56.749945Z",
     "start_time": "2024-10-10T13:00:47.390060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = WhoIsWhoDataset.parse_data()\n",
    "train_data = WhoIsWhoDataset.parse_train()"
   ],
   "id": "7b4f2bfe1943d12a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.471926458Z",
     "start_time": "2024-09-24T08:48:09.712199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    device='cuda'\n",
    ")\n",
    "print(f\"Model dim: {model.get_sentence_embedding_dimension()}\")"
   ],
   "id": "9a313d7d87172b1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dim: 384\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add publication nodes to the graph database",
   "id": "15768f9232b8a006"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_batch(batch):\n",
    "    if not batch[NodeType.PUBLICATION]:\n",
    "        return\n",
    "    title_embs = model.encode(\n",
    "        [node['title'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    abstract_embs = model.encode(\n",
    "        [node['abstract'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    venue_embs = model.encode(\n",
    "        [node['venue'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    for i, node in enumerate(batch[NodeType.PUBLICATION]):\n",
    "        node['title_emb'] = title_embs[i]\n",
    "        node['abstract_emb'] = abstract_embs[i]\n",
    "        node['venue_emb'] = venue_embs[i]\n",
    "    db.merge_nodes(NodeType.PUBLICATION, batch[NodeType.PUBLICATION])\n",
    "    batch[NodeType.PUBLICATION] = []"
   ],
   "id": "fb863533ee3db7cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.472160714Z",
     "start_time": "2024-09-24T08:48:11.332846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_nodes = defaultdict(list)\n",
    "current_iteration = 0\n",
    "\n",
    "with tqdm(total=max_iterations) as pbar:\n",
    "    for author_id, values in train_data.items():\n",
    "        papers = values.get('normal_data', [])\n",
    "        papers.extend(values.get('outliers', []))\n",
    "        \n",
    "        if max_iterations is not None and current_iteration >= max_iterations:\n",
    "            break\n",
    "        current_iteration += len(papers)\n",
    "        \n",
    "        for paper_id in papers:\n",
    "            values = data[paper_id]\n",
    "            paper_node = {\n",
    "                'id': values['id'],\n",
    "                'title': values['title'],\n",
    "                'abstract': values['abstract'],\n",
    "                'year': values['year'],\n",
    "                'venue': values['venue'],\n",
    "            }\n",
    "            batch_nodes[NodeType.PUBLICATION].append(paper_node)\n",
    "            \n",
    "            if len(batch_nodes[NodeType.PUBLICATION]) % 1000 == 0:\n",
    "                process_batch(batch_nodes)\n",
    "                \n",
    "            pbar.update(1)\n",
    "        \n",
    "process_batch(batch_nodes)"
   ],
   "id": "29946cd86c709ff8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f3bf67f72bf42fd965bfd63b02463b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add true author data to the nodes",
   "id": "ebf992fa74894e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.473194312Z",
     "start_time": "2024-09-24T08:49:33.189463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reverse_dict(author_dict):\n",
    "    paper_to_author = {}\n",
    "    for author_id, values in author_dict.items():\n",
    "        normal_papers = values.get('normal_data', [])\n",
    "        for paper_id in normal_papers:\n",
    "            paper_to_author[paper_id] = author_id\n",
    "    return paper_to_author\n",
    "\n",
    "paper_id_to_author = reverse_dict(train_data)\n",
    "\n",
    "props = []\n",
    "with tqdm(total=db.count_nodes(NodeType.PUBLICATION), desc=\"Merging WhoIsWho train_author.json\") as pbar:\n",
    "    for nodes in db.iter_nodes(NodeType.PUBLICATION, ['id']):\n",
    "        for node in nodes:\n",
    "            true_author_id = paper_id_to_author.get(node['id'], '')\n",
    "            true_author_name = train_data.get(true_author_id, {}).get('name', '')\n",
    "            \n",
    "            db.merge_properties(\n",
    "                type=NodeType.PUBLICATION, \n",
    "                node_id=node['id'], \n",
    "                properties={'true_author_id': true_author_id, 'true_author_name': true_author_name}\n",
    "            )\n",
    "            pbar.update(1)\n",
    "\n",
    "\"\"\"\n",
    "        for pub_id in values['normal_data']:\n",
    "            props.append({'id': pub_id, 'properties': {'true_author': author_name}})\n",
    "        pbar.update(1)\n",
    "        if len(props) > 1000:\n",
    "            db.merge_properties_batch(NodeType.PUBLICATION, props)\n",
    "            props.clear()\n",
    "\n",
    "    if props:\n",
    "        db.merge_properties_batch(NodeType.PUBLICATION, props)\n",
    "\"\"\""
   ],
   "id": "9b2f2a4cbd1f8ad1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merging WhoIsWho train_author.json:   0%|          | 0/10829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dbf971e288c4facb0c5189d876fad0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n        for pub_id in values['normal_data']:\\n            props.append({'id': pub_id, 'properties': {'true_author': author_name}})\\n        pbar.update(1)\\n        if len(props) > 1000:\\n            db.merge_properties_batch(NodeType.PUBLICATION, props)\\n            props.clear()\\n\\n    if props:\\n        db.merge_properties_batch(NodeType.PUBLICATION, props)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Link nodes based on co-author relationships",
   "id": "f289de4073e4964f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:04:36.006715Z",
     "start_time": "2024-10-10T13:04:36.001130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_co_author_network(db: DatabaseWrapper, node_type: NodeType):\n",
    "    num_nodes = db.count_nodes(node_type)\n",
    "    attrs = ['id']\n",
    "    co_author_map = defaultdict(list)\n",
    "    co_author_overlap = defaultdict(int)\n",
    "        \n",
    "    print(f\"Linking {node_type.value} nodes based on co-authorship ...\")\n",
    "    with tqdm(total=num_nodes, desc=f\"Progress {node_type.value} co-authorship\") as pbar:\n",
    "        for nodes in db.iter_nodes(node_type, attrs):\n",
    "            for node in nodes:\n",
    "                co_authors = [author[\"name\"] for author in data[node['id']]['authors']]\n",
    "                for author in co_authors:\n",
    "                    name = author.strip()\n",
    "                    name = re.sub(r'[^A-Za-z\\s]', '', name)\n",
    "                    name_parts = name.split()\n",
    "                    if len(name_parts) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    surname = name_parts[-1]\n",
    "                    given_name_initial = (name_parts[0] if len(name_parts) > 1 else ' ')[0]\n",
    "                    abbrev = f\"{surname} {given_name_initial}\"\n",
    "                    co_author_map[abbrev].append(node['id'])\n",
    "                pbar.update(1)\n",
    "    \n",
    "    for k, v in co_author_map.items():\n",
    "        for i in range(len(v)):\n",
    "            for j in range(i + 1, len(v)):\n",
    "                co_author_overlap[(v[i], v[j])] += 1\n",
    "                \n",
    "    for k, v in co_author_overlap.items():\n",
    "        total_num_authors = data[k[0]][\"authors\"] + data[k[1]][\"authors\"]\n",
    "        co_author_overlap[k] = v / len(total_num_authors)\n",
    "    \n",
    "    print(f\"Max. co-authors: {max(len(v) for v in co_author_map.values())}\")\n",
    "    print(f\"Max. co-author overlap: {max(co_author_overlap.values())}\")\n",
    "    \n",
    "    print(\"Number of co-author pairs:\", len(co_author_overlap))\n",
    "    print(\"Number of co-author pairs with overlap > 0.25:\", len([v for v in co_author_overlap.values() if v > 0.25]))\n",
    "    \n",
    "    print(\"Merging edges ...\")\n",
    "    edges_to_merge = [[k[0], k[1], {'sim': v}] for k, v in co_author_overlap.items() if v > 0.25]\n",
    "    with tqdm(total=len(edges_to_merge), desc=\"Merging co-author edges\") as pbar:\n",
    "        for i in range(0, len(edges_to_merge), 1000):\n",
    "            db.merge_edges(start_label=node_type, end_label=node_type, edge_type=EdgeType.SIM_AUTHOR, edges=edges_to_merge[i:i+1000])\n",
    "            pbar.update(1000)"
   ],
   "id": "a7757bd1c39b85df",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:11:26.676399Z",
     "start_time": "2024-10-10T13:04:36.617871Z"
    }
   },
   "cell_type": "code",
   "source": "link_co_author_network(db, NodeType.PUBLICATION)",
   "id": "e663cedfc1fbdc51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking Publication nodes based on co-authorship ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication co-authorship:   0%|          | 0/10829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b893a2343144b769cc54a375d1773e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. co-authors: 1649\n",
      "Max. co-author overlap: 1.2181571815718157\n",
      "Number of co-author pairs: 2840769\n",
      "Number of co-author pairs with overlap > 0.25: 67731\n",
      "Merging edges ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Merging co-author edges:   0%|          | 0/67731 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6966a1be1cff4fa1ac2ac839bc3181c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Link nodes based on cosine similarity of their embeddings",
   "id": "4a98eaadf5534888"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.473829819Z",
     "start_time": "2024-09-24T08:51:01.823018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_node_attr_cosine(db: DatabaseWrapper, node_type: NodeType, vec_attr: str, edge_type: EdgeType, threshold: float = 0.7, filter_empty_original_attr: str = None):\n",
    "    num_nodes = db.count_nodes(node_type)\n",
    "    edges = []\n",
    "    attrs = ['id', vec_attr]\n",
    "    if filter_empty_original_attr:\n",
    "        attrs.append(filter_empty_original_attr)\n",
    "        \n",
    "    print(f\"Linking {node_type.value} nodes based on {vec_attr} attribute ...\")\n",
    "    with tqdm(total=num_nodes, desc=f\"Progress {node_type.value} {vec_attr}\") as pbar:\n",
    "        for nodes in db.iter_nodes(node_type, attrs):\n",
    "            for node in nodes:\n",
    "                if filter_empty_original_attr and not node[filter_empty_original_attr]:\n",
    "                    pbar.update(1)\n",
    "                    print(f\"Skipping node {node['id']} because {filter_empty_original_attr} is empty\")\n",
    "                    continue\n",
    "                k = 8\n",
    "                similar_nodes = db.get_similar_nodes_vec(\n",
    "                    node_type,\n",
    "                    vec_attr,\n",
    "                    node[vec_attr],\n",
    "                    threshold,\n",
    "                    k\n",
    "                )\n",
    "                for ix, row in similar_nodes.iterrows():\n",
    "                    if row['id'] == node['id']:\n",
    "                        continue\n",
    "                    edges.append([node['id'], row['id']])\n",
    "                    #db.merge_edge(node_type, node['id'], node_type, row['id'], edge_type, {\"sim\": row['sim']})\n",
    "                if len(edges) > 1000:\n",
    "                    print(f\"Merging {len(edges)} edges ...\")\n",
    "                    db.merge_edges(start_label=node_type, end_label=node_type, edge_type=edge_type, edges=edges)\n",
    "                    edges.clear()\n",
    "                    \n",
    "                pbar.update(1)\n",
    "    if edges:\n",
    "        db.merge_edges(start_label=node_type, end_label=node_type, edge_type=edge_type, edges=edges)"
   ],
   "id": "df5874196d002a6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "faff03512cfe5f37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.474066745Z",
     "start_time": "2024-09-24T08:51:01.937019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dim = model.get_sentence_embedding_dimension()\n",
    "db.create_vector_index('title_index', NodeType.PUBLICATION, 'title_emb', model_dim)\n",
    "db.create_vector_index('abstract_index', NodeType.PUBLICATION, 'abstract_emb', model_dim)\n",
    "db.create_vector_index('venue_index', NodeType.PUBLICATION, 'venue_emb', model_dim)\n",
    "link_node_attr_cosine(db, NodeType.PUBLICATION, 'title_emb', EdgeType.SIM_TITLE)\n",
    "link_node_attr_cosine(db, NodeType.PUBLICATION, 'abstract_emb', EdgeType.SIM_ABSTRACT)\n",
    "link_node_attr_cosine(db, NodeType.PUBLICATION, 'venue_emb', EdgeType.SIM_VENUE, threshold=0.9)"
   ],
   "id": "71010a3d4cd7ff1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking Publication nodes based on title_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication title_emb:   0%|          | 0/10829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "110c653e0c0042cf8400322e7406d2fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1004 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Linking Publication nodes based on abstract_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication abstract_emb:   0%|          | 0/10829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "962dfea94c4c448989f5f44afa898ae8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1008 edges ...\n",
      "Linking Publication nodes based on venue_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication venue_emb:   0%|          | 0/10829 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61f48485912346f0b40470cd55164ad1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1006 edges ...\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.474257390Z",
     "start_time": "2024-09-24T11:27:55.282820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove edges if according attribute is empty\n",
    "db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_TITLE, 'title')\n",
    "db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_ABSTRACT, 'abstract')\n",
    "db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_VENUE, 'venue')"
   ],
   "id": "837c860f5efe8056",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.474440215Z",
     "start_time": "2024-09-24T10:11:20.605287Z"
    }
   },
   "cell_type": "code",
   "source": "print(db.count_nodes(NodeType.PUBLICATION))",
   "id": "f02c30d1f448354f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10829\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.474608Z",
     "start_time": "2024-09-20T09:30:33.199658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gs = GraphSampling(\n",
    "    node_spec=[NodeType.PUBLICATION], \n",
    "    edge_spec=[], \n",
    "    node_properties=['abstract_emb', 'title_emb', 'venue_emb']\n",
    ")"
   ],
   "id": "cabd3b3063d244b2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T14:40:13.474791135Z",
     "start_time": "2024-09-20T09:30:33.299864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nodes = gs.random_nodes(\n",
    "    node_type=NodeType.PUBLICATION,\n",
    "    node_properties=['abstract_emb', 'title_emb', 'venue_emb', 'true_author'],\n",
    "    n=1000\n",
    ")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node)\n",
    "    break"
   ],
   "id": "9052fcccde7d1b21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '6IsfnuWU', 'abstract_emb': None, 'title_emb': None, 'venue_emb': None, 'true_author': None}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "82533ad81894da8a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
