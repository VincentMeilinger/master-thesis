{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:27.935556Z",
     "start_time": "2024-09-08T06:40:27.932458Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "from neo4j import GraphDatabase, Result\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot, edge_val_to_pyg_key_vals\n",
    "from src.shared import config\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:27.965804Z",
     "start_time": "2024-09-08T06:40:27.945521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))\n",
    "gds = GraphDataScience(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))"
   ],
   "id": "f86e564187669603",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:27.991748Z",
     "start_time": "2024-09-08T06:40:27.987948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def fetch_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [f\"<{et.value}\" for et in EdgeType] if edge_types is None else \n",
    "            [f\"<{et.value}\" for et in edge_types]\n",
    "        )\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '{edge_filter}',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        # Process nodes\n",
    "        node_data = []\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            node_data.append({\"nodeId\": node_id, node_attr: attr, \"nodeLabels\": list(node.labels)})\n",
    "        \n",
    "        node_df = pd.DataFrame(node_data)\n",
    "        \n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "        for rel in relationships:\n",
    "            if rel.type not in edge_dict:\n",
    "                edge_dict[rel.type] = [[], []]\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "            \n",
    "            edge_dict[rel.type][0].append(source_id)\n",
    "            edge_dict[rel.type][1].append(target_id)\n",
    "    \n",
    "    return node_df, edge_dict"
   ],
   "id": "e70ec590b134a545",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.035945Z",
     "start_time": "2024-09-08T06:40:28.032875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_topology(new_idx_to_old, topology):\n",
    "    # Reverse index mapping based on new idx -> old idx\n",
    "    old_idx_to_new = dict((v, k) for k, v in new_idx_to_old.items())\n",
    "    return {rel_type: [[old_idx_to_new[node_id] for node_id in nodes] for nodes in topology] for rel_type, topology in topology.items()}\n",
    "\n",
    "def create_edge_index(topology):\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for rel_type, nodes in topology.items():\n",
    "        src_nodes, dst_nodes = nodes\n",
    "        edges = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "        edge_index.append(edges)\n",
    "        edge_feature_vec = edge_one_hot[rel_type]\n",
    "        edge_features.extend([edge_feature_vec for _ in range(len(src_nodes))])\n",
    "    return torch.cat(edge_index, dim=1), torch.vstack(edge_features)\n",
    "\n",
    "def project_node_embeddings(node_df):\n",
    "    def stack_one_hot(row):\n",
    "        one_hot_enc = node_one_hot[row[\"nodeLabels\"][0]]\n",
    "        return torch.hstack((one_hot_enc, torch.tensor(row[\"vec\"])))\n",
    "    return node_df.apply(stack_one_hot, axis=1)"
   ],
   "id": "5e3f57dde09c71f9",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.080027Z",
     "start_time": "2024-09-08T06:40:28.076948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "]\n",
    "\n",
    "def sample_subgraph(node_list):\n",
    "    dataset = []\n",
    "    for node_id in node_list:\n",
    "        node_df, topology = fetch_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node_id, \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=5\n",
    "        )\n",
    "        node_df[\"vec_projected\"] = project_node_embeddings(node_df)\n",
    "        normalized_node_ids = {new_idx: old_idx for new_idx, old_idx in enumerate(node_df[\"nodeId\"])}\n",
    "        normalized_topology = normalize_topology(normalized_node_ids, topology)\n",
    "        if len(normalized_topology) == 0:\n",
    "            continue\n",
    "            \n",
    "        edge_index, edge_features = create_edge_index(normalized_topology)\n",
    "        node_features = torch.vstack(node_df[\"vec_projected\"].tolist())\n",
    "        \n",
    "        dataset.append(Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features\n",
    "        ))\n",
    "    return DataLoader(dataset)"
   ],
   "id": "25f12b271e3e6d43",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.126133Z",
     "start_time": "2024-09-08T06:40:28.122048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [f\"<{et.value}\" for et in EdgeType] if edge_types is None else \n",
    "            [f\"<{et.value}\" for et in edge_types]\n",
    "        )\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '{edge_filter}',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        G = nx.Graph()\n",
    "\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            G.add_node(node_id, label=node.labels, vec=attr)\n",
    "\n",
    "        for rel in relationships:\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "            G.add_edge(source_id, target_id, type=rel.type)\n",
    "\n",
    "        return G"
   ],
   "id": "44d8164c80527b84",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.184982Z",
     "start_time": "2024-09-08T06:40:28.169486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_graph(G):\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    edge_trace = []\n",
    "    annotations = []\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "\n",
    "        edge_trace.append(go.Scatter(\n",
    "            x=[x0, x1, None],\n",
    "            y=[y0, y1, None],\n",
    "            line=dict(width=1, color='#888'),\n",
    "            hoverinfo='none',\n",
    "            mode='lines'))\n",
    "\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                ax=x0, ay=y0,\n",
    "                x=x1, y=y1,\n",
    "                xref='x', yref='y',\n",
    "                axref='x', ayref='y',\n",
    "                showarrow=True,\n",
    "                arrowhead=3,\n",
    "                arrowsize=1.5,\n",
    "                arrowwidth=1,\n",
    "                arrowcolor='#888'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=[],\n",
    "        y=[],\n",
    "        text=[],\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=True,\n",
    "            colorscale='YlGnBu',\n",
    "            reversescale=True,\n",
    "            color=[],\n",
    "            size=10,\n",
    "            colorbar=dict(\n",
    "                thickness=15,\n",
    "                title='Node Connections',\n",
    "                xanchor='left',\n",
    "                titleside='right'\n",
    "            ),\n",
    "        ))\n",
    "\n",
    "    for node in G.nodes(data=True):\n",
    "        x, y = pos[node[0]]\n",
    "        node_trace['x'] += tuple([x])\n",
    "        node_trace['y'] += tuple([y])\n",
    "\n",
    "        node_info = f\"{node[0]}<br>{list(node[1]['label'])[0]}\"\n",
    "        node_trace['text'] += tuple([node_info])\n",
    "        node_trace['marker']['color'] += tuple([len(G[node[0]])])\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=edge_trace + [node_trace],\n",
    "        layout=go.Layout(\n",
    "            title='<br>Subgraph',\n",
    "            titlefont=dict(size=16),\n",
    "            showlegend=False,\n",
    "            hovermode='closest',\n",
    "            margin=dict(b=0, l=0, r=0, t=0),\n",
    "            annotations=annotations,\n",
    "            xaxis=dict(showgrid=False, zeroline=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "db_wrapper = DatabaseWrapper()\n",
    "\"\"\"\n",
    "for nodes in db_wrapper.iter_nodes(NodeType.PUBLICATION, [\"id\"]):\n",
    "    for node in nodes:\n",
    "        G = visualize_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node.get(\"id\"), \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=2\n",
    "        )\n",
    "        plot_graph(G)\n",
    "        sleep(5)\n",
    "        \n",
    "\"\"\""
   ],
   "id": "4da85a0ccf045b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 08:40:28,174 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-09-08 08:40:28,181 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor nodes in db_wrapper.iter_nodes(NodeType.PUBLICATION, [\"id\"]):\\n    for node in nodes:\\n        G = visualize_n_hop_neighbourhood(\\n            start_node_type=NodeType.PUBLICATION, \\n            start_node_id=node.get(\"id\"), \\n            node_attr=\"vec\",\\n            node_types=included_nodes,\\n            edge_types=included_edges,\\n            max_level=2\\n        )\\n        plot_graph(G)\\n        sleep(5)\\n        \\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.223185Z",
     "start_time": "2024-09-08T06:40:28.221260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_ids = []# [\"wgKatLxf\"]\n",
    "for node_id in node_ids:\n",
    "    G = visualize_n_hop_neighbourhood(\n",
    "        start_node_type=NodeType.PUBLICATION, \n",
    "        start_node_id=node_id, \n",
    "        node_attr=\"vec\",\n",
    "        node_types=included_nodes,\n",
    "        edge_types=included_edges,\n",
    "        max_level=2\n",
    "    )\n",
    "    print(len(G.nodes) * 37)\n",
    "    plot_graph(G)\n",
    "    sleep(5)"
   ],
   "id": "12efd4152d49c76f",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.268210Z",
     "start_time": "2024-09-08T06:40:28.264994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_heterodata(data, node_colors=None, node_size=300, font_size=12):\n",
    "    # Convert HeteroData to NetworkX graph\n",
    "    G = to_networkx(data, node_attrs=['x'], edge_attrs=['edge_attr'])\n",
    "\n",
    "    # Create a color map for the nodes based on type\n",
    "    if node_colors is None:\n",
    "        cmap = mpl.colormaps.get_cmap('tab20')\n",
    "        node_colors = {key: cmap(i % cmap.N) for i, key in enumerate(data.node_types)}\n",
    "\n",
    "    color_map = []\n",
    "    for node in G.nodes(data=True):\n",
    "        node_type = node[1]['type']\n",
    "        color_map.append(node_colors[node_type])\n",
    "    \n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=color_map, node_size=node_size, font_size=font_size, cmap=plt.get_cmap('tab20'))\n",
    "\n",
    "    for node_type, color in node_colors.items():\n",
    "        plt.scatter([], [], c=[color], label=node_type, s=node_size)\n",
    "    plt.legend(scatterpoints=1, frameon=False, labelspacing=1, loc='upper left')\n",
    "\n",
    "    plt.show()"
   ],
   "id": "dbde5e03641459f5",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:28.322700Z",
     "start_time": "2024-09-08T06:40:28.313407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphSampling:\n",
    "    def __init__(self, node_spec: list, relationship_spec: list, node_properties: list):\n",
    "        self.driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))\n",
    "        self.node_spec = node_spec\n",
    "        self.relationship_spec = relationship_spec\n",
    "        self.node_properties = node_properties\n",
    "        \n",
    "    def spanning_tree(\n",
    "            self,\n",
    "            start_node_type: NodeType,\n",
    "            start_node_id: str,\n",
    "            node_types: list = None,\n",
    "            edge_types: list = None,\n",
    "            max_level: int = 3,\n",
    "            limit: int = 300\n",
    "    ):\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            node_filter = '|'.join(\n",
    "                [nt.value for nt in NodeType] if node_types is None else\n",
    "                [nt.value for nt in node_types]\n",
    "            )\n",
    "            edge_filter = '|'.join(\n",
    "                [f\"<{et.value}\" for et in EdgeType] if edge_types is None else\n",
    "                [f\"<{et.value}\" for et in edge_types]\n",
    "            )\n",
    "\n",
    "            query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.spanningTree(start, {{\n",
    "                    maxLevel: {max_level},\n",
    "                    limit: {limit}, \n",
    "                    relationshipFilter: '{edge_filter}',\n",
    "                    labelFilter: '+{node_filter}'\n",
    "                }}) YIELD path\n",
    "                WITH apoc.coll.flatten(collect(nodes(path))) AS allNodes, apoc.coll.flatten(collect(relationships(path))) AS allRels\n",
    "                UNWIND allNodes AS node\n",
    "                UNWIND allRels AS rel\n",
    "                WITH collect(DISTINCT node) AS nodes, collect(DISTINCT rel) AS relationships\n",
    "                RETURN \n",
    "                  [node IN nodes | {{id: node.id, labels: labels(node), vec: node.vec}}] AS nodes, \n",
    "                    [rel IN relationships | {{start_node: {{id: startNode(rel).id}}, type: type(rel), end_node: {{endNode(rel).id}}}}] AS relationships\n",
    "            \"\"\"\n",
    "            result = session.run(query)\n",
    "            data = result.data()\n",
    "            return data\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def neo_to_pyg(\n",
    "        data,\n",
    "        node_attr: str\n",
    "    ):\n",
    "        if not data:\n",
    "            return None, None\n",
    "\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        print(f\"Nodes: {len(nodes)}, Relationships: {len(relationships)}\")\n",
    "        if len(nodes) > 500:\n",
    "            print(f\"Too many nodes: {len(nodes)}\")\n",
    "            return None, None\n",
    "\n",
    "        # Create data object\n",
    "        h_data = HeteroData()\n",
    "\n",
    "        node_features = {}\n",
    "        node_ids = {}\n",
    "        node_id_map = {}\n",
    "\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            node_feature = node.get(node_attr, None)\n",
    "            if node_feature is None:\n",
    "                print(f\"Node {node_id} has no attribute {node_attr}\")\n",
    "                continue\n",
    "            node_label = list(node.labels)[0]\n",
    "            if node_label not in node_features:\n",
    "                node_features[node_label] = []\n",
    "                node_ids[node_label] = []\n",
    "\n",
    "            # Convert node features to tensors\n",
    "            node_features[node_label].append(torch.tensor(node_feature, dtype=torch.float32))\n",
    "            node_ids[node_label].append(node_id)\n",
    "\n",
    "            # Map node ID to its index in the list\n",
    "            node_id_map[node_id] = len(node_ids[node_label]) - 1\n",
    "\n",
    "        # Convert list of features to a single tensor per node type\n",
    "        for node_label, node_features in node_features.items():\n",
    "            h_data[node_label].x = torch.vstack(node_features)\n",
    "\n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "\n",
    "        for rel in relationships:\n",
    "            key = edge_val_to_pyg_key_vals[rel.type]  # edge_val_to_pyg_key_vals maps edge types to tuples (src, dst)\n",
    "            if key not in edge_dict:\n",
    "                edge_dict[key] = [[], []]\n",
    "\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "\n",
    "            # Append the indices of the source and target nodes\n",
    "            edge_dict[key][0].append(node_id_map[source_id])\n",
    "            edge_dict[key][1].append(node_id_map[target_id])\n",
    "\n",
    "        # Convert edge lists to tensors\n",
    "        for key in edge_dict:\n",
    "            h_data[key[0], key[1], key[2]].edge_index = torch.vstack([\n",
    "                torch.tensor(edge_dict[key][0], dtype=torch.long),\n",
    "                torch.tensor(edge_dict[key][1], dtype=torch.long)\n",
    "            ])\n",
    "\n",
    "            h_data[key[0], key[1], key[2]].edge_attr = torch.vstack(\n",
    "                [edge_one_hot[key[1]] for _ in range(len(edge_dict[key][0]))])\n",
    "\n",
    "        return h_data, node_id_map\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.driver.close()\n",
    "            \n",
    "\"\"\"gs = GraphSampling(\n",
    "    node_spec=[n.value for n in included_nodes], \n",
    "    relationship_spec=[e.value for e in included_edges], \n",
    "    node_properties=[\"vec\"]\n",
    ")\n",
    "result = gs.spanning_tree(\n",
    "    start_node_type=NodeType.PUBLICATION, \n",
    "    start_node_id=\"wgKatLxf\", \n",
    "    node_types=included_nodes,\n",
    "    edge_types=included_edges,\n",
    "    max_level=2\n",
    ")\n",
    "for res in result:\n",
    "    print(len(res[\"nodes\"]), len(res[\"relationships\"]))\n",
    "    for node in res[\"nodes\"]:\n",
    "        print(node[\"labels\"], node[\"id\"])\n",
    "    for rel in res[\"relationships\"]:\n",
    "        print(rel)\n",
    "#h_data, node_id_map = GraphSampling.neo_to_pyg(result[0], \"vec\")\n",
    "#visualize_heterodata(h_data)\n",
    "\"\"\""
   ],
   "id": "e9b061ff982dbf2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs = GraphSampling(\\n    node_spec=[n.value for n in included_nodes], \\n    relationship_spec=[e.value for e in included_edges], \\n    node_properties=[\"vec\"]\\n)\\nresult = gs.spanning_tree(\\n    start_node_type=NodeType.PUBLICATION, \\n    start_node_id=\"wgKatLxf\", \\n    node_types=included_nodes,\\n    edge_types=included_edges,\\n    max_level=2\\n)\\nfor res in result:\\n    print(len(res[\"nodes\"]), len(res[\"relationships\"]))\\n    for node in res[\"nodes\"]:\\n        print(node[\"labels\"], node[\"id\"])\\n    for rel in res[\"relationships\"]:\\n        print(rel)\\n#h_data, node_id_map = GraphSampling.neo_to_pyg(result[0], \"vec\")\\n#visualize_heterodata(h_data)\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T06:40:37.251704Z",
     "start_time": "2024-09-08T06:40:28.421005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.shared.neo_to_pyg import GraphSampling\n",
    "sampler = GraphSampling(\n",
    "    node_spec=[n.value for n in included_nodes], \n",
    "    relationship_spec=[e.value for e in included_edges], \n",
    "    node_properties=[\"vec\"]\n",
    ")\n",
    "result = sampler.n_hop_neighbourhood(\n",
    "    start_node_type=NodeType.PUBLICATION, \n",
    "    start_node_id=\"wgKatLxf\", \n",
    "    node_types=included_nodes,\n",
    "    edge_types=included_edges,\n",
    "    max_level=2\n",
    ")\n",
    "#print(json.dumps(result, indent=2))\n",
    "h_data, node_id_map = GraphSampling.neo_to_pyg(result, \"vec\")\n",
    "visualize_heterodata(h_data)"
   ],
   "id": "cba5b5eb017bcdb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 40247, Relationships: 143856\n",
      "Too many nodes: 40247\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'node_offsets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#print(json.dumps(result, indent=2))\u001B[39;00m\n\u001B[1;32m     15\u001B[0m h_data, node_id_map \u001B[38;5;241m=\u001B[39m GraphSampling\u001B[38;5;241m.\u001B[39mneo_to_pyg(result, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvec\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mvisualize_heterodata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[75], line 8\u001B[0m, in \u001B[0;36mvisualize_heterodata\u001B[0;34m(data, node_colors, node_size, font_size)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvisualize_heterodata\u001B[39m(data, node_colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, node_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, font_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# Convert HeteroData to NetworkX graph\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m     G \u001B[38;5;241m=\u001B[39m \u001B[43mto_networkx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_attrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43medge_attr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Create a color map for the nodes based on type\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m node_colors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch_geometric/utils/convert.py:157\u001B[0m, in \u001B[0;36mto_networkx\u001B[0;34m(data, node_attrs, edge_attrs, graph_attrs, to_undirected, to_multi, remove_self_loops)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m graph_attrs \u001B[38;5;129;01mor\u001B[39;00m []:\n\u001B[1;32m    155\u001B[0m     G\u001B[38;5;241m.\u001B[39mgraph[key] \u001B[38;5;241m=\u001B[39m to_networkx_value(data[key])\n\u001B[0;32m--> 157\u001B[0m node_offsets \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_offsets\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node_store \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mnode_stores:\n\u001B[1;32m    159\u001B[0m     start \u001B[38;5;241m=\u001B[39m node_offsets[node_store\u001B[38;5;241m.\u001B[39m_key]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'node_offsets'"
     ]
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
