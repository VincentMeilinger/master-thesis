{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T08:46:04.286998Z",
     "start_time": "2024-11-05T08:46:04.280984Z"
    }
   },
   "source": [
    "from util import *\n",
    "from training_heterogeneous import *\n",
    "from gat_models import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn.modules.loss import TripletMarginLoss\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.shared.graph_schema import *\n",
    "from src.shared.graph_sampling import GraphSampling\n",
    "\n",
    "random.seed(40)\n",
    "np.random.seed(40)\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed_all(40)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configurations",
   "id": "ee4fa502d7e51e50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:46:15.478968Z",
     "start_time": "2024-11-05T08:46:15.472566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Graph sampling configurations\n",
    "node_spec = [\n",
    "    NodeType.PUBLICATION,\n",
    "]\n",
    "\n",
    "edge_spec = [\n",
    "    EdgeType.SIM_VENUE,\n",
    "    EdgeType.SIM_ABSTRACT,\n",
    "    EdgeType.SIM_AUTHOR,\n",
    "]\n",
    "\n",
    "node_properties = [\n",
    "    'id',\n",
    "    'title',\n",
    "    'abstract',\n",
    "    'title_emb',\n",
    "    'abstract_emb',\n",
    "    'feature_vec',\n",
    "]\n",
    "\n",
    "database = 'homogeneous-graph-compressed-emb'\n",
    "gs = GraphSampling(\n",
    "    node_spec=node_spec,\n",
    "    edge_spec=edge_spec,\n",
    "    node_properties=node_properties,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# Model configurations\n",
    "\n",
    "config = {\n",
    "    'experiment': 'GATv2 encoder (with linear layer) trained on heterogeneous graph (publication nodes with title and abstract, similarity and co-author edges) using Triplet Loss and dimension reduced embeddings',\n",
    "    'max_hops': 3,\n",
    "    'model_node_feature': 'feature_vec',  # Node feature to use for GAT encoder\n",
    "    'hidden_channels': 64,\n",
    "    'out_channels': 16,\n",
    "    'num_heads': 8,\n",
    "    'margin': 1.0,\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "model_class = HeteroGATEncoderLinear\n",
    "loss_fn = TripletMarginLoss(margin=config['margin'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TODO: Adjust result folder name!\n",
    "result_folder_name = 'hetero_edges compressed_emb linear_layer'\n",
    "result_folder_path = f'./data/results/{result_folder_name}'\n",
    "# Graph sampling configurations\n",
    "node_spec = [\n",
    "    NodeType.PUBLICATION,\n",
    "]\n",
    "\n",
    "edge_spec = [\n",
    "    #EdgeType.SIM_VENUE,\n",
    "    EdgeType.SIM_AUTHOR,\n",
    "]\n",
    "\n",
    "node_properties = [\n",
    "    'id',\n",
    "    'title',\n",
    "    'abstract',\n",
    "    'title_emb',\n",
    "    'abstract_emb',\n",
    "    'feature_vec',\n",
    "]\n",
    "\n",
    "database = 'homogeneous-graph-compressed-emb'\n",
    "gs = GraphSampling(\n",
    "    node_spec=node_spec,\n",
    "    edge_spec=edge_spec,\n",
    "    node_properties=node_properties,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# Model configurations\n",
    "\n",
    "config = {\n",
    "    'experiment': 'GATv2 encoder (with linear layer + dropout) trained on homogeneous graph (publication nodes with title and abstract, co-author edges) using Triplet Loss and dimension reduced embeddings',\n",
    "    'max_hops': 3,\n",
    "    'model_node_feature': 'feature_vec',  # Node feature to use for GAT encoder\n",
    "    'hidden_channels': 64,\n",
    "    'out_channels': 16,\n",
    "    'num_heads': 8,\n",
    "    'margin': 1.0,\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 20,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "model_class = HeteroGATEncoderLinearDropout\n",
    "loss_fn = TripletMarginLoss(margin=config['margin'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TODO: Adjust result folder name!\n",
    "result_folder_name = 'homo_edges compressed_emb linear_layer dropout'\n",
    "result_folder_path = f'./data/results/{result_folder_name}'\n",
    "if not os.path.exists(result_folder_path):\n",
    "    os.mkdir(result_folder_path)"
   ],
   "id": "91b04efb689d61f4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Configuration",
   "id": "b67cf89d3d17cc12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T17:20:53.967129Z",
     "start_time": "2024-11-04T17:17:34.248664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DatabaseWrapper(database=database)\n",
    "data_harvester = TripletDataHarvester(db=db, gs=gs, edge_spec=edge_spec, config=config)\n",
    "\n",
    "\n",
    "# Split the pairs into train and test\n",
    "\n",
    "train_size = int(0.85 * len(data_harvester.triplets))\n",
    "test_size = int(0.1 * len(data_harvester.triplets))\n",
    "eval_size = len(data_harvester.triplets) - train_size - test_size\n",
    "\n",
    "# Harvest the evaluation triplets first, since triplets are ordered by author. This will ensure that the evaluation set has authors not seen in the training set.\n",
    "eval_triplets = data_harvester.triplets[:eval_size]\n",
    "\n",
    "train_test_triplets = data_harvester.triplets[eval_size:]\n",
    "random.shuffle(train_test_triplets)\n",
    "\n",
    "train_triplets = train_test_triplets[:train_size]\n",
    "test_triplets = train_test_triplets[train_size:]\n",
    "config['train_size'] = len(train_triplets)\n",
    "config['test_size'] = len(test_triplets)\n",
    "config['eval_size'] = len(eval_triplets)\n",
    "\n",
    "print(f\"Train size: {len(train_triplets)}, Test size: {len(test_triplets)}, Eval size: {len(eval_triplets)}\")\n",
    "\n",
    "# Create the datasets from the pairs (distinct pairs for training and testing)\n",
    "train_dataset = GraphTripletDataset(train_triplets, gs, config=config)\n",
    "test_dataset = GraphTripletDataset(test_triplets, gs, config=config)\n",
    "eval_dataset = GraphTripletDataset(eval_triplets, gs, config=config)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_triplet_collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "\n",
    "# Create model\n",
    "metadata = (\n",
    "    [n.value for n in node_spec],\n",
    "    [edge_pyg_key_vals[r] for r in edge_spec]\n",
    ")\n",
    "config['node_spec'] = metadata[0]\n",
    "config['edge_spec'] = metadata[1]\n",
    "model = model_class(metadata, config['hidden_channels'], config['out_channels'], num_heads=config['num_heads']).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])"
   ],
   "id": "62ef1028a5c5fd5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 18:17:34,251 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-11-04 18:17:34,252 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing triplets...\n",
      "Loading triplets...\n",
      "Could not load triplets from file. Generating triplets...\n",
      "Checking data validity...\n",
      "Out of 20034 checked papers, 12937 are valid and 7097 are invalid.\n",
      "Preparing pairs...\n",
      "Total triplets: 11755. Done.\n",
      "Generated 11755 triplets.\n",
      "Saving triplets...\n",
      "Triplets saved.\n",
      "Train size: 9991, Test size: 1175, Eval size: 589\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "bdf9a36f9d9a6f43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-04T17:20:54.019214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = config['num_epochs']\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_correct_pos = []\n",
    "test_correct_neg = []\n",
    "\n",
    "eval_losses = []\n",
    "eval_accuracies = []\n",
    "eval_correct_pos = []\n",
    "eval_correct_neg = []\n",
    "\n",
    "current_batch = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"=== Epoch {epoch}/{num_epochs} ======================\")\n",
    "    epoch_marker_pos = list(range(0, len(train_dataloader) * epoch, len(train_dataloader)))\n",
    "    current_batch = 1\n",
    "    for batch_anchor, batch_pos, batch_neg in tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "        if batch_anchor is None or batch_pos is None or batch_neg is None:\n",
    "            continue\n",
    "        \n",
    "        if current_batch == 1 or current_batch == len(train_dataloader) // 2:\n",
    "            print(f\"___ Current Batch {current_batch}/{len(train_dataloader)} _________________________\")\n",
    "            # Model testing\n",
    "            print(\"    Test Results:\")\n",
    "            test_loss, test_num_correct, test_correct_pos_val, test_correct_neg_val = test(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=test_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracies.append(test_num_correct)\n",
    "            test_correct_pos.append(test_correct_pos_val)\n",
    "            test_correct_neg.append(test_correct_neg_val)\n",
    "    \n",
    "            plot_loss(test_losses, epoch_len=2, plot_title='Test Loss', plot_avg=False, plot_file=result_folder_path + '/test_loss.png')\n",
    "            plot_loss(test_accuracies, epoch_len=2, plot_title='Test Accuracy', plot_avg=False, plot_file=result_folder_path + '/test_accuracy.png')\n",
    "            \n",
    "            # Model evaluation\n",
    "            print(\"    Eval Results:\")\n",
    "            eval_loss, eval_num_correct, eval_correct_pos_val, eval_correct_neg_val = evaluate(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=eval_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            eval_losses.append(eval_loss)\n",
    "            eval_accuracies.append(eval_num_correct)\n",
    "            eval_correct_pos.append(eval_correct_pos_val)\n",
    "            eval_correct_neg.append(eval_correct_neg_val)\n",
    "            \n",
    "            plot_loss(eval_losses, epoch_len=2, plot_title='Evaluation Loss', plot_avg=False, plot_file=result_folder_path + '/eval_loss.png')\n",
    "            plot_loss(eval_accuracies, epoch_len=2, plot_title='Evaluation Accuracy', plot_avg=False, plot_file=result_folder_path + '/eval_accuracy.png')\n",
    "            \n",
    "        loss = train(\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            batch_anchor=batch_anchor,\n",
    "            batch_pos=batch_pos,\n",
    "            batch_neg=batch_neg,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        plot_loss(train_losses, epoch_len=len(train_dataloader), plot_title='Training Loss', plot_avg=True, plot_file=result_folder_path + '/train_loss.png')\n",
    "        current_batch += 1\n",
    "        \n",
    "    # Save config and training results\n",
    "    eval_results = {\n",
    "        'eval_losses': eval_losses,\n",
    "        'eval_accuracies': eval_accuracies,\n",
    "        'eval_correct_pos': eval_correct_pos,\n",
    "        'eval_correct_neg': eval_correct_neg\n",
    "    }\n",
    "    save_training_results(train_losses, test_losses, eval_results, config, result_folder_path + '/training_data.json')\n",
    "    \n",
    "    # Save model if loss has decreased\n",
    "    if len(test_losses) > 1 and test_losses[-1] < min(test_losses[:-1]):\n",
    "        print(f\"Saving model at epoch {epoch}...\")\n",
    "        torch.save(model.state_dict(), result_folder_path + '/gat_encoder.pt')"
   ],
   "id": "c3b28cd52881796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be21d6998155436c9708cc546ed79dab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 1/313 _________________________\n",
      "Test Loss: 1.0114\n",
      "Correct positive: 589 (100.00%), Correct negative: 0 (0.00%)\n",
      "Total correct: 589 (50.00%)\n",
      "Eval Loss: 1.0111, Eval Accuracy: 0.5000\n",
      "___ Batch 11/313 _________________________\n",
      "Test Loss: 0.8908\n",
      "Correct positive: 311 (52.80%), Correct negative: 263 (44.65%)\n",
      "Total correct: 574 (48.73%)\n",
      "Eval Loss: 1.0244, Eval Accuracy: 0.4873\n",
      "___ Batch 21/313 _________________________\n",
      "Test Loss: 0.8515\n",
      "Correct positive: 350 (59.42%), Correct negative: 285 (48.39%)\n",
      "Total correct: 635 (53.90%)\n",
      "Eval Loss: 0.8974, Eval Accuracy: 0.5390\n",
      "___ Batch 31/313 _________________________\n",
      "Test Loss: 0.7738\n",
      "Correct positive: 346 (58.74%), Correct negative: 273 (46.35%)\n",
      "Total correct: 619 (52.55%)\n",
      "Eval Loss: 0.9289, Eval Accuracy: 0.5255\n",
      "___ Batch 41/313 _________________________\n",
      "Test Loss: 0.7711\n",
      "Correct positive: 191 (32.43%), Correct negative: 338 (57.39%)\n",
      "Total correct: 529 (44.91%)\n",
      "Eval Loss: 1.1852, Eval Accuracy: 0.4491\n",
      "___ Batch 51/313 _________________________\n",
      "Test Loss: 0.7141\n",
      "Correct positive: 142 (24.11%), Correct negative: 407 (69.10%)\n",
      "Total correct: 549 (46.60%)\n",
      "Eval Loss: 1.1151, Eval Accuracy: 0.4660\n",
      "___ Batch 61/313 _________________________\n",
      "Test Loss: 0.7193\n",
      "Correct positive: 228 (38.71%), Correct negative: 329 (55.86%)\n",
      "Total correct: 557 (47.28%)\n",
      "Eval Loss: 1.0174, Eval Accuracy: 0.4728\n",
      "___ Batch 71/313 _________________________\n",
      "Test Loss: 0.6949\n",
      "Correct positive: 249 (42.28%), Correct negative: 405 (68.76%)\n",
      "Total correct: 654 (55.52%)\n",
      "Eval Loss: 0.8919, Eval Accuracy: 0.5552\n",
      "___ Batch 81/313 _________________________\n",
      "Test Loss: 0.6537\n",
      "Correct positive: 240 (40.75%), Correct negative: 436 (74.02%)\n",
      "Total correct: 676 (57.39%)\n",
      "Eval Loss: 0.9012, Eval Accuracy: 0.5739\n",
      "___ Batch 91/313 _________________________\n",
      "Test Loss: 0.6255\n",
      "Correct positive: 163 (27.67%), Correct negative: 374 (63.50%)\n",
      "Total correct: 537 (45.59%)\n",
      "Eval Loss: 1.0680, Eval Accuracy: 0.4559\n",
      "___ Batch 101/313 _________________________\n",
      "Test Loss: 0.6138\n",
      "Correct positive: 130 (22.07%), Correct negative: 384 (65.20%)\n",
      "Total correct: 514 (43.63%)\n",
      "Eval Loss: 1.1338, Eval Accuracy: 0.4363\n",
      "___ Batch 111/313 _________________________\n",
      "Test Loss: 0.6056\n",
      "Correct positive: 75 (12.73%), Correct negative: 484 (82.17%)\n",
      "Total correct: 559 (47.45%)\n",
      "Eval Loss: 1.3333, Eval Accuracy: 0.4745\n",
      "___ Batch 121/313 _________________________\n",
      "Test Loss: 0.5732\n",
      "Correct positive: 92 (15.62%), Correct negative: 481 (81.66%)\n",
      "Total correct: 573 (48.64%)\n",
      "Eval Loss: 1.3310, Eval Accuracy: 0.4864\n",
      "___ Batch 131/313 _________________________\n",
      "Test Loss: 0.5615\n",
      "Correct positive: 126 (21.39%), Correct negative: 478 (81.15%)\n",
      "Total correct: 604 (51.27%)\n",
      "Eval Loss: 1.1156, Eval Accuracy: 0.5127\n",
      "___ Batch 141/313 _________________________\n",
      "Test Loss: 0.5528\n",
      "Correct positive: 222 (37.69%), Correct negative: 366 (62.14%)\n",
      "Total correct: 588 (49.92%)\n",
      "Eval Loss: 1.0387, Eval Accuracy: 0.4992\n",
      "___ Batch 151/313 _________________________\n",
      "Test Loss: 0.5257\n",
      "Correct positive: 181 (30.73%), Correct negative: 396 (67.23%)\n",
      "Total correct: 577 (48.98%)\n",
      "Eval Loss: 1.0277, Eval Accuracy: 0.4898\n",
      "___ Batch 161/313 _________________________\n",
      "Test Loss: 0.5065\n",
      "Correct positive: 157 (26.66%), Correct negative: 460 (78.10%)\n",
      "Total correct: 617 (52.38%)\n",
      "Eval Loss: 0.9642, Eval Accuracy: 0.5238\n",
      "___ Batch 171/313 _________________________\n",
      "Test Loss: 0.5288\n",
      "Correct positive: 206 (34.97%), Correct negative: 431 (73.17%)\n",
      "Total correct: 637 (54.07%)\n",
      "Eval Loss: 0.9485, Eval Accuracy: 0.5407\n",
      "___ Batch 181/313 _________________________\n",
      "Test Loss: 0.5203\n",
      "Correct positive: 115 (19.52%), Correct negative: 501 (85.06%)\n",
      "Total correct: 616 (52.29%)\n",
      "Eval Loss: 0.9647, Eval Accuracy: 0.5229\n",
      "___ Batch 191/313 _________________________\n",
      "Test Loss: 0.5630\n",
      "Correct positive: 121 (20.54%), Correct negative: 458 (77.76%)\n",
      "Total correct: 579 (49.15%)\n",
      "Eval Loss: 1.0304, Eval Accuracy: 0.4915\n",
      "___ Batch 201/313 _________________________\n",
      "Test Loss: 0.5439\n",
      "Correct positive: 112 (19.02%), Correct negative: 493 (83.70%)\n",
      "Total correct: 605 (51.36%)\n",
      "Eval Loss: 1.1819, Eval Accuracy: 0.5136\n",
      "___ Batch 211/313 _________________________\n",
      "Test Loss: 0.5135\n",
      "Correct positive: 208 (35.31%), Correct negative: 387 (65.70%)\n",
      "Total correct: 595 (50.51%)\n",
      "Eval Loss: 1.1011, Eval Accuracy: 0.5051\n",
      "___ Batch 221/313 _________________________\n",
      "Test Loss: 0.5001\n",
      "Correct positive: 118 (20.03%), Correct negative: 498 (84.55%)\n",
      "Total correct: 616 (52.29%)\n",
      "Eval Loss: 0.9925, Eval Accuracy: 0.5229\n",
      "___ Batch 231/313 _________________________\n",
      "Test Loss: 0.4822\n",
      "Correct positive: 127 (21.56%), Correct negative: 473 (80.31%)\n",
      "Total correct: 600 (50.93%)\n",
      "Eval Loss: 1.0447, Eval Accuracy: 0.5093\n",
      "___ Batch 241/313 _________________________\n",
      "Test Loss: 0.4681\n",
      "Correct positive: 195 (33.11%), Correct negative: 362 (61.46%)\n",
      "Total correct: 557 (47.28%)\n",
      "Eval Loss: 1.0514, Eval Accuracy: 0.4728\n",
      "___ Batch 251/313 _________________________\n",
      "Test Loss: 0.4609\n",
      "Correct positive: 113 (19.19%), Correct negative: 442 (75.04%)\n",
      "Total correct: 555 (47.11%)\n",
      "Eval Loss: 1.2020, Eval Accuracy: 0.4711\n",
      "___ Batch 261/313 _________________________\n",
      "Test Loss: 0.4727\n",
      "Correct positive: 216 (36.67%), Correct negative: 350 (59.42%)\n",
      "Total correct: 566 (48.05%)\n",
      "Eval Loss: 1.0883, Eval Accuracy: 0.4805\n",
      "___ Batch 271/313 _________________________\n",
      "Test Loss: 0.4571\n",
      "Correct positive: 239 (40.58%), Correct negative: 326 (55.35%)\n",
      "Total correct: 565 (47.96%)\n",
      "Eval Loss: 0.9856, Eval Accuracy: 0.4796\n",
      "___ Batch 281/313 _________________________\n",
      "Test Loss: 0.4571\n",
      "Correct positive: 190 (32.26%), Correct negative: 473 (80.31%)\n",
      "Total correct: 663 (56.28%)\n",
      "Eval Loss: 0.8846, Eval Accuracy: 0.5628\n",
      "___ Batch 291/313 _________________________\n",
      "Test Loss: 0.4399\n",
      "Correct positive: 169 (28.69%), Correct negative: 479 (81.32%)\n",
      "Total correct: 648 (55.01%)\n",
      "Eval Loss: 0.9278, Eval Accuracy: 0.5501\n",
      "___ Batch 301/313 _________________________\n",
      "Test Loss: 0.4407\n",
      "Correct positive: 169 (28.69%), Correct negative: 480 (81.49%)\n",
      "Total correct: 649 (55.09%)\n",
      "Eval Loss: 0.8552, Eval Accuracy: 0.5509\n",
      "___ Batch 311/313 _________________________\n",
      "Test Loss: 0.4427\n",
      "Correct positive: 131 (22.24%), Correct negative: 498 (84.55%)\n",
      "Total correct: 629 (53.40%)\n",
      "Eval Loss: 0.8165, Eval Accuracy: 0.5340\n",
      "=== Epoch 2/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9810fc052b504afba04b50eaaaded622"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 8/313 _________________________\n",
      "Test Loss: 0.4258\n",
      "Correct positive: 63 (10.70%), Correct negative: 485 (82.34%)\n",
      "Total correct: 548 (46.52%)\n",
      "Eval Loss: 1.1769, Eval Accuracy: 0.4652\n",
      "___ Batch 18/313 _________________________\n",
      "Test Loss: 0.4137\n",
      "Correct positive: 154 (26.15%), Correct negative: 447 (75.89%)\n",
      "Total correct: 601 (51.02%)\n",
      "Eval Loss: 1.0103, Eval Accuracy: 0.5102\n",
      "___ Batch 28/313 _________________________\n",
      "Test Loss: 0.4248\n",
      "Correct positive: 87 (14.77%), Correct negative: 522 (88.62%)\n",
      "Total correct: 609 (51.70%)\n",
      "Eval Loss: 1.0619, Eval Accuracy: 0.5170\n",
      "___ Batch 38/313 _________________________\n",
      "Test Loss: 0.4078\n",
      "Correct positive: 240 (40.75%), Correct negative: 439 (74.53%)\n",
      "Total correct: 679 (57.64%)\n",
      "Eval Loss: 0.9016, Eval Accuracy: 0.5764\n",
      "___ Batch 48/313 _________________________\n",
      "Test Loss: 0.4057\n",
      "Correct positive: 199 (33.79%), Correct negative: 431 (73.17%)\n",
      "Total correct: 630 (53.48%)\n",
      "Eval Loss: 0.9022, Eval Accuracy: 0.5348\n",
      "___ Batch 58/313 _________________________\n",
      "Test Loss: 0.4111\n",
      "Correct positive: 90 (15.28%), Correct negative: 481 (81.66%)\n",
      "Total correct: 571 (48.47%)\n",
      "Eval Loss: 0.9900, Eval Accuracy: 0.4847\n",
      "___ Batch 68/313 _________________________\n",
      "Test Loss: 0.4153\n",
      "Correct positive: 183 (31.07%), Correct negative: 423 (71.82%)\n",
      "Total correct: 606 (51.44%)\n",
      "Eval Loss: 1.0771, Eval Accuracy: 0.5144\n",
      "___ Batch 78/313 _________________________\n",
      "Test Loss: 0.4027\n",
      "Correct positive: 70 (11.88%), Correct negative: 495 (84.04%)\n",
      "Total correct: 565 (47.96%)\n",
      "Eval Loss: 1.1631, Eval Accuracy: 0.4796\n",
      "___ Batch 88/313 _________________________\n",
      "Test Loss: 0.3753\n",
      "Correct positive: 138 (23.43%), Correct negative: 498 (84.55%)\n",
      "Total correct: 636 (53.99%)\n",
      "Eval Loss: 1.0263, Eval Accuracy: 0.5399\n",
      "___ Batch 98/313 _________________________\n",
      "Test Loss: 0.3843\n",
      "Correct positive: 237 (40.24%), Correct negative: 450 (76.40%)\n",
      "Total correct: 687 (58.32%)\n",
      "Eval Loss: 0.9728, Eval Accuracy: 0.5832\n",
      "___ Batch 108/313 _________________________\n",
      "Test Loss: 0.4068\n",
      "Correct positive: 112 (19.02%), Correct negative: 497 (84.38%)\n",
      "Total correct: 609 (51.70%)\n",
      "Eval Loss: 1.0086, Eval Accuracy: 0.5170\n",
      "___ Batch 118/313 _________________________\n",
      "Test Loss: 0.4142\n",
      "Correct positive: 131 (22.24%), Correct negative: 498 (84.55%)\n",
      "Total correct: 629 (53.40%)\n",
      "Eval Loss: 1.0102, Eval Accuracy: 0.5340\n",
      "___ Batch 128/313 _________________________\n",
      "Test Loss: 0.3571\n",
      "Correct positive: 189 (32.09%), Correct negative: 458 (77.76%)\n",
      "Total correct: 647 (54.92%)\n",
      "Eval Loss: 0.9110, Eval Accuracy: 0.5492\n",
      "___ Batch 138/313 _________________________\n",
      "Test Loss: 0.3402\n",
      "Correct positive: 173 (29.37%), Correct negative: 474 (80.48%)\n",
      "Total correct: 647 (54.92%)\n",
      "Eval Loss: 1.0079, Eval Accuracy: 0.5492\n",
      "___ Batch 148/313 _________________________\n",
      "Test Loss: 0.3648\n",
      "Correct positive: 225 (38.20%), Correct negative: 484 (82.17%)\n",
      "Total correct: 709 (60.19%)\n",
      "Eval Loss: 0.9429, Eval Accuracy: 0.6019\n",
      "___ Batch 158/313 _________________________\n",
      "Test Loss: 0.4002\n",
      "Correct positive: 103 (17.49%), Correct negative: 502 (85.23%)\n",
      "Total correct: 605 (51.36%)\n",
      "Eval Loss: 0.9192, Eval Accuracy: 0.5136\n",
      "___ Batch 168/313 _________________________\n",
      "Test Loss: 0.3847\n",
      "Correct positive: 163 (27.67%), Correct negative: 479 (81.32%)\n",
      "Total correct: 642 (54.50%)\n",
      "Eval Loss: 1.0016, Eval Accuracy: 0.5450\n",
      "___ Batch 178/313 _________________________\n",
      "Test Loss: 0.3638\n",
      "Correct positive: 164 (27.84%), Correct negative: 458 (77.76%)\n",
      "Total correct: 622 (52.80%)\n",
      "Eval Loss: 0.9468, Eval Accuracy: 0.5280\n",
      "___ Batch 188/313 _________________________\n",
      "Test Loss: 0.3472\n",
      "Correct positive: 91 (15.45%), Correct negative: 493 (83.70%)\n",
      "Total correct: 584 (49.58%)\n",
      "Eval Loss: 1.0449, Eval Accuracy: 0.4958\n",
      "___ Batch 198/313 _________________________\n",
      "Test Loss: 0.3490\n",
      "Correct positive: 190 (32.26%), Correct negative: 407 (69.10%)\n",
      "Total correct: 597 (50.68%)\n",
      "Eval Loss: 1.0846, Eval Accuracy: 0.5068\n",
      "___ Batch 208/313 _________________________\n",
      "Test Loss: 0.3477\n",
      "Correct positive: 133 (22.58%), Correct negative: 492 (83.53%)\n",
      "Total correct: 625 (53.06%)\n",
      "Eval Loss: 1.1928, Eval Accuracy: 0.5306\n",
      "___ Batch 218/313 _________________________\n",
      "Test Loss: 0.3313\n",
      "Correct positive: 144 (24.45%), Correct negative: 490 (83.19%)\n",
      "Total correct: 634 (53.82%)\n",
      "Eval Loss: 0.9870, Eval Accuracy: 0.5382\n",
      "___ Batch 228/313 _________________________\n",
      "Test Loss: 0.3196\n",
      "Correct positive: 152 (25.81%), Correct negative: 482 (81.83%)\n",
      "Total correct: 634 (53.82%)\n",
      "Eval Loss: 1.0381, Eval Accuracy: 0.5382\n",
      "___ Batch 238/313 _________________________\n",
      "Test Loss: 0.3226\n",
      "Correct positive: 127 (21.56%), Correct negative: 462 (78.44%)\n",
      "Total correct: 589 (50.00%)\n",
      "Eval Loss: 1.1040, Eval Accuracy: 0.5000\n",
      "___ Batch 248/313 _________________________\n",
      "Test Loss: 0.3340\n",
      "Correct positive: 63 (10.70%), Correct negative: 544 (92.36%)\n",
      "Total correct: 607 (51.53%)\n",
      "Eval Loss: 1.1286, Eval Accuracy: 0.5153\n",
      "___ Batch 258/313 _________________________\n",
      "Test Loss: 0.3243\n",
      "Correct positive: 242 (41.09%), Correct negative: 389 (66.04%)\n",
      "Total correct: 631 (53.57%)\n",
      "Eval Loss: 1.1163, Eval Accuracy: 0.5357\n",
      "___ Batch 268/313 _________________________\n",
      "Test Loss: 0.3388\n",
      "Correct positive: 105 (17.83%), Correct negative: 476 (80.81%)\n",
      "Total correct: 581 (49.32%)\n",
      "Eval Loss: 1.1711, Eval Accuracy: 0.4932\n",
      "___ Batch 278/313 _________________________\n",
      "Test Loss: 0.3368\n",
      "Correct positive: 212 (35.99%), Correct negative: 410 (69.61%)\n",
      "Total correct: 622 (52.80%)\n",
      "Eval Loss: 1.0624, Eval Accuracy: 0.5280\n",
      "___ Batch 288/313 _________________________\n",
      "Test Loss: 0.3096\n",
      "Correct positive: 170 (28.86%), Correct negative: 460 (78.10%)\n",
      "Total correct: 630 (53.48%)\n",
      "Eval Loss: 1.0042, Eval Accuracy: 0.5348\n",
      "___ Batch 298/313 _________________________\n",
      "Test Loss: 0.3219\n",
      "Correct positive: 230 (39.05%), Correct negative: 346 (58.74%)\n",
      "Total correct: 576 (48.90%)\n",
      "Eval Loss: 1.0801, Eval Accuracy: 0.4890\n",
      "___ Batch 308/313 _________________________\n",
      "Test Loss: 0.3077\n",
      "Correct positive: 201 (34.13%), Correct negative: 368 (62.48%)\n",
      "Total correct: 569 (48.30%)\n",
      "Eval Loss: 1.1844, Eval Accuracy: 0.4830\n",
      "Saving model at epoch 2...\n",
      "=== Epoch 3/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ee1dd736bd0475793993f74ec5d577f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 5/313 _________________________\n",
      "Test Loss: 0.3018\n",
      "Correct positive: 172 (29.20%), Correct negative: 438 (74.36%)\n",
      "Total correct: 610 (51.78%)\n",
      "Eval Loss: 1.0593, Eval Accuracy: 0.5178\n",
      "___ Batch 15/313 _________________________\n",
      "Test Loss: 0.3225\n",
      "Correct positive: 69 (11.71%), Correct negative: 535 (90.83%)\n",
      "Total correct: 604 (51.27%)\n",
      "Eval Loss: 0.8903, Eval Accuracy: 0.5127\n",
      "___ Batch 25/313 _________________________\n",
      "Test Loss: 0.3390\n",
      "Correct positive: 68 (11.54%), Correct negative: 545 (92.53%)\n",
      "Total correct: 613 (52.04%)\n",
      "Eval Loss: 0.8572, Eval Accuracy: 0.5204\n",
      "___ Batch 35/313 _________________________\n",
      "Test Loss: 0.3515\n",
      "Correct positive: 210 (35.65%), Correct negative: 505 (85.74%)\n",
      "Total correct: 715 (60.70%)\n",
      "Eval Loss: 0.8292, Eval Accuracy: 0.6070\n",
      "___ Batch 45/313 _________________________\n",
      "Test Loss: 0.3390\n",
      "Correct positive: 154 (26.15%), Correct negative: 520 (88.29%)\n",
      "Total correct: 674 (57.22%)\n",
      "Eval Loss: 0.8119, Eval Accuracy: 0.5722\n",
      "___ Batch 55/313 _________________________\n",
      "Test Loss: 0.3220\n",
      "Correct positive: 98 (16.64%), Correct negative: 500 (84.89%)\n",
      "Total correct: 598 (50.76%)\n",
      "Eval Loss: 1.1458, Eval Accuracy: 0.5076\n",
      "___ Batch 65/313 _________________________\n",
      "Test Loss: 0.3315\n",
      "Correct positive: 123 (20.88%), Correct negative: 447 (75.89%)\n",
      "Total correct: 570 (48.39%)\n",
      "Eval Loss: 1.0257, Eval Accuracy: 0.4839\n",
      "___ Batch 75/313 _________________________\n",
      "Test Loss: 0.3208\n",
      "Correct positive: 193 (32.77%), Correct negative: 470 (79.80%)\n",
      "Total correct: 663 (56.28%)\n",
      "Eval Loss: 0.9655, Eval Accuracy: 0.5628\n",
      "___ Batch 85/313 _________________________\n",
      "Test Loss: 0.3177\n",
      "Correct positive: 104 (17.66%), Correct negative: 533 (90.49%)\n",
      "Total correct: 637 (54.07%)\n",
      "Eval Loss: 0.8198, Eval Accuracy: 0.5407\n",
      "___ Batch 95/313 _________________________\n",
      "Test Loss: 0.3104\n",
      "Correct positive: 157 (26.66%), Correct negative: 485 (82.34%)\n",
      "Total correct: 642 (54.50%)\n",
      "Eval Loss: 0.8828, Eval Accuracy: 0.5450\n",
      "___ Batch 105/313 _________________________\n",
      "Test Loss: 0.3008\n",
      "Correct positive: 156 (26.49%), Correct negative: 485 (82.34%)\n",
      "Total correct: 641 (54.41%)\n",
      "Eval Loss: 1.0101, Eval Accuracy: 0.5441\n",
      "___ Batch 115/313 _________________________\n",
      "Test Loss: 0.3392\n",
      "Correct positive: 126 (21.39%), Correct negative: 468 (79.46%)\n",
      "Total correct: 594 (50.42%)\n",
      "Eval Loss: 1.1798, Eval Accuracy: 0.5042\n",
      "___ Batch 125/313 _________________________\n",
      "Test Loss: 0.2911\n",
      "Correct positive: 190 (32.26%), Correct negative: 504 (85.57%)\n",
      "Total correct: 694 (58.91%)\n",
      "Eval Loss: 0.7784, Eval Accuracy: 0.5891\n",
      "___ Batch 135/313 _________________________\n",
      "Test Loss: 0.2943\n",
      "Correct positive: 123 (20.88%), Correct negative: 534 (90.66%)\n",
      "Total correct: 657 (55.77%)\n",
      "Eval Loss: 0.9126, Eval Accuracy: 0.5577\n",
      "___ Batch 145/313 _________________________\n",
      "Test Loss: 0.2941\n",
      "Correct positive: 126 (21.39%), Correct negative: 483 (82.00%)\n",
      "Total correct: 609 (51.70%)\n",
      "Eval Loss: 1.0331, Eval Accuracy: 0.5170\n",
      "___ Batch 155/313 _________________________\n",
      "Test Loss: 0.3381\n",
      "Correct positive: 81 (13.75%), Correct negative: 543 (92.19%)\n",
      "Total correct: 624 (52.97%)\n",
      "Eval Loss: 1.0182, Eval Accuracy: 0.5297\n",
      "___ Batch 165/313 _________________________\n",
      "Test Loss: 0.3157\n",
      "Correct positive: 170 (28.86%), Correct negative: 531 (90.15%)\n",
      "Total correct: 701 (59.51%)\n",
      "Eval Loss: 0.9455, Eval Accuracy: 0.5951\n",
      "___ Batch 175/313 _________________________\n",
      "Test Loss: 0.2859\n",
      "Correct positive: 161 (27.33%), Correct negative: 527 (89.47%)\n",
      "Total correct: 688 (58.40%)\n",
      "Eval Loss: 0.9021, Eval Accuracy: 0.5840\n",
      "___ Batch 185/313 _________________________\n",
      "Test Loss: 0.2749\n",
      "Correct positive: 151 (25.64%), Correct negative: 506 (85.91%)\n",
      "Total correct: 657 (55.77%)\n",
      "Eval Loss: 0.8646, Eval Accuracy: 0.5577\n",
      "___ Batch 195/313 _________________________\n",
      "Test Loss: 0.2659\n",
      "Correct positive: 149 (25.30%), Correct negative: 534 (90.66%)\n",
      "Total correct: 683 (57.98%)\n",
      "Eval Loss: 0.7809, Eval Accuracy: 0.5798\n",
      "___ Batch 205/313 _________________________\n",
      "Test Loss: 0.2784\n",
      "Correct positive: 226 (38.37%), Correct negative: 499 (84.72%)\n",
      "Total correct: 725 (61.54%)\n",
      "Eval Loss: 0.7871, Eval Accuracy: 0.6154\n",
      "___ Batch 215/313 _________________________\n",
      "Test Loss: 0.3165\n",
      "Correct positive: 203 (34.47%), Correct negative: 492 (83.53%)\n",
      "Total correct: 695 (59.00%)\n",
      "Eval Loss: 0.7809, Eval Accuracy: 0.5900\n",
      "___ Batch 225/313 _________________________\n",
      "Test Loss: 0.2829\n",
      "Correct positive: 92 (15.62%), Correct negative: 535 (90.83%)\n",
      "Total correct: 627 (53.23%)\n",
      "Eval Loss: 0.7438, Eval Accuracy: 0.5323\n",
      "___ Batch 235/313 _________________________\n",
      "Test Loss: 0.2697\n",
      "Correct positive: 83 (14.09%), Correct negative: 527 (89.47%)\n",
      "Total correct: 610 (51.78%)\n",
      "Eval Loss: 0.9288, Eval Accuracy: 0.5178\n",
      "___ Batch 245/313 _________________________\n",
      "Test Loss: 0.3444\n",
      "Correct positive: 109 (18.51%), Correct negative: 501 (85.06%)\n",
      "Total correct: 610 (51.78%)\n",
      "Eval Loss: 0.9609, Eval Accuracy: 0.5178\n",
      "___ Batch 255/313 _________________________\n",
      "Test Loss: 0.3291\n",
      "Correct positive: 102 (17.32%), Correct negative: 521 (88.46%)\n",
      "Total correct: 623 (52.89%)\n",
      "Eval Loss: 0.7617, Eval Accuracy: 0.5289\n",
      "___ Batch 265/313 _________________________\n",
      "Test Loss: 0.3713\n",
      "Correct positive: 166 (28.18%), Correct negative: 517 (87.78%)\n",
      "Total correct: 683 (57.98%)\n",
      "Eval Loss: 0.7936, Eval Accuracy: 0.5798\n",
      "___ Batch 275/313 _________________________\n",
      "Test Loss: 0.3225\n",
      "Correct positive: 143 (24.28%), Correct negative: 482 (81.83%)\n",
      "Total correct: 625 (53.06%)\n",
      "Eval Loss: 0.9271, Eval Accuracy: 0.5306\n",
      "___ Batch 285/313 _________________________\n",
      "Test Loss: 0.2923\n",
      "Correct positive: 308 (52.29%), Correct negative: 498 (84.55%)\n",
      "Total correct: 806 (68.42%)\n",
      "Eval Loss: 0.7028, Eval Accuracy: 0.6842\n",
      "___ Batch 295/313 _________________________\n",
      "Test Loss: 0.2950\n",
      "Correct positive: 136 (23.09%), Correct negative: 505 (85.74%)\n",
      "Total correct: 641 (54.41%)\n",
      "Eval Loss: 0.7797, Eval Accuracy: 0.5441\n",
      "___ Batch 305/313 _________________________\n",
      "Test Loss: 0.3002\n",
      "Correct positive: 159 (26.99%), Correct negative: 513 (87.10%)\n",
      "Total correct: 672 (57.05%)\n",
      "Eval Loss: 0.8093, Eval Accuracy: 0.5705\n",
      "=== Epoch 4/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "898f6a61881b403db5966dd7edb3904c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 2/313 _________________________\n",
      "Test Loss: 0.3391\n",
      "Correct positive: 166 (28.18%), Correct negative: 523 (88.79%)\n",
      "Total correct: 689 (58.49%)\n",
      "Eval Loss: 0.7968, Eval Accuracy: 0.5849\n",
      "___ Batch 12/313 _________________________\n",
      "Test Loss: 0.2721\n",
      "Correct positive: 217 (36.84%), Correct negative: 487 (82.68%)\n",
      "Total correct: 704 (59.76%)\n",
      "Eval Loss: 0.8195, Eval Accuracy: 0.5976\n",
      "___ Batch 22/313 _________________________\n",
      "Test Loss: 0.2603\n",
      "Correct positive: 199 (33.79%), Correct negative: 456 (77.42%)\n",
      "Total correct: 655 (55.60%)\n",
      "Eval Loss: 0.9251, Eval Accuracy: 0.5560\n",
      "___ Batch 32/313 _________________________\n",
      "Test Loss: 0.2701\n",
      "Correct positive: 178 (30.22%), Correct negative: 448 (76.06%)\n",
      "Total correct: 626 (53.14%)\n",
      "Eval Loss: 0.9090, Eval Accuracy: 0.5314\n",
      "___ Batch 42/313 _________________________\n",
      "Test Loss: 0.2613\n",
      "Correct positive: 186 (31.58%), Correct negative: 440 (74.70%)\n",
      "Total correct: 626 (53.14%)\n",
      "Eval Loss: 0.8080, Eval Accuracy: 0.5314\n",
      "___ Batch 52/313 _________________________\n",
      "Test Loss: 0.2489\n",
      "Correct positive: 221 (37.52%), Correct negative: 456 (77.42%)\n",
      "Total correct: 677 (57.47%)\n",
      "Eval Loss: 0.8802, Eval Accuracy: 0.5747\n",
      "___ Batch 62/313 _________________________\n",
      "Test Loss: 0.2704\n",
      "Correct positive: 225 (38.20%), Correct negative: 487 (82.68%)\n",
      "Total correct: 712 (60.44%)\n",
      "Eval Loss: 0.8407, Eval Accuracy: 0.6044\n",
      "___ Batch 72/313 _________________________\n",
      "Test Loss: 0.2678\n",
      "Correct positive: 195 (33.11%), Correct negative: 447 (75.89%)\n",
      "Total correct: 642 (54.50%)\n",
      "Eval Loss: 1.0189, Eval Accuracy: 0.5450\n",
      "___ Batch 82/313 _________________________\n",
      "Test Loss: 0.2792\n",
      "Correct positive: 188 (31.92%), Correct negative: 495 (84.04%)\n",
      "Total correct: 683 (57.98%)\n",
      "Eval Loss: 0.9009, Eval Accuracy: 0.5798\n",
      "___ Batch 92/313 _________________________\n",
      "Test Loss: 0.2516\n",
      "Correct positive: 116 (19.69%), Correct negative: 498 (84.55%)\n",
      "Total correct: 614 (52.12%)\n",
      "Eval Loss: 1.1104, Eval Accuracy: 0.5212\n",
      "___ Batch 102/313 _________________________\n",
      "Test Loss: 0.3080\n",
      "Correct positive: 112 (19.02%), Correct negative: 525 (89.13%)\n",
      "Total correct: 637 (54.07%)\n",
      "Eval Loss: 1.1847, Eval Accuracy: 0.5407\n",
      "___ Batch 112/313 _________________________\n",
      "Test Loss: 0.2513\n",
      "Correct positive: 234 (39.73%), Correct negative: 471 (79.97%)\n",
      "Total correct: 705 (59.85%)\n",
      "Eval Loss: 0.7561, Eval Accuracy: 0.5985\n",
      "___ Batch 122/313 _________________________\n",
      "Test Loss: 0.2448\n",
      "Correct positive: 236 (40.07%), Correct negative: 508 (86.25%)\n",
      "Total correct: 744 (63.16%)\n",
      "Eval Loss: 0.7091, Eval Accuracy: 0.6316\n",
      "___ Batch 132/313 _________________________\n",
      "Test Loss: 0.2594\n",
      "Correct positive: 162 (27.50%), Correct negative: 547 (92.87%)\n",
      "Total correct: 709 (60.19%)\n",
      "Eval Loss: 0.6484, Eval Accuracy: 0.6019\n",
      "___ Batch 142/313 _________________________\n",
      "Test Loss: 0.2808\n",
      "Correct positive: 89 (15.11%), Correct negative: 558 (94.74%)\n",
      "Total correct: 647 (54.92%)\n",
      "Eval Loss: 0.7689, Eval Accuracy: 0.5492\n",
      "___ Batch 152/313 _________________________\n",
      "Test Loss: 0.2601\n",
      "Correct positive: 83 (14.09%), Correct negative: 551 (93.55%)\n",
      "Total correct: 634 (53.82%)\n",
      "Eval Loss: 0.9187, Eval Accuracy: 0.5382\n",
      "___ Batch 162/313 _________________________\n",
      "Test Loss: 0.2476\n",
      "Correct positive: 216 (36.67%), Correct negative: 504 (85.57%)\n",
      "Total correct: 720 (61.12%)\n",
      "Eval Loss: 0.8149, Eval Accuracy: 0.6112\n",
      "___ Batch 172/313 _________________________\n",
      "Test Loss: 0.2481\n",
      "Correct positive: 181 (30.73%), Correct negative: 523 (88.79%)\n",
      "Total correct: 704 (59.76%)\n",
      "Eval Loss: 0.6825, Eval Accuracy: 0.5976\n",
      "___ Batch 182/313 _________________________\n",
      "Test Loss: 0.2619\n",
      "Correct positive: 231 (39.22%), Correct negative: 506 (85.91%)\n",
      "Total correct: 737 (62.56%)\n",
      "Eval Loss: 0.7422, Eval Accuracy: 0.6256\n",
      "___ Batch 192/313 _________________________\n",
      "Test Loss: 0.2670\n",
      "Correct positive: 143 (24.28%), Correct negative: 502 (85.23%)\n",
      "Total correct: 645 (54.75%)\n",
      "Eval Loss: 0.7502, Eval Accuracy: 0.5475\n",
      "___ Batch 202/313 _________________________\n",
      "Test Loss: 0.2423\n",
      "Correct positive: 134 (22.75%), Correct negative: 505 (85.74%)\n",
      "Total correct: 639 (54.24%)\n",
      "Eval Loss: 0.7420, Eval Accuracy: 0.5424\n",
      "___ Batch 212/313 _________________________\n",
      "Test Loss: 0.2628\n",
      "Correct positive: 171 (29.03%), Correct negative: 508 (86.25%)\n",
      "Total correct: 679 (57.64%)\n",
      "Eval Loss: 0.9265, Eval Accuracy: 0.5764\n",
      "___ Batch 222/313 _________________________\n",
      "Test Loss: 0.2560\n",
      "Correct positive: 357 (60.61%), Correct negative: 342 (58.06%)\n",
      "Total correct: 699 (59.34%)\n",
      "Eval Loss: 0.9317, Eval Accuracy: 0.5934\n",
      "___ Batch 232/313 _________________________\n",
      "Test Loss: 0.2519\n",
      "Correct positive: 254 (43.12%), Correct negative: 498 (84.55%)\n",
      "Total correct: 752 (63.84%)\n",
      "Eval Loss: 0.7398, Eval Accuracy: 0.6384\n",
      "___ Batch 242/313 _________________________\n",
      "Test Loss: 0.2366\n",
      "Correct positive: 154 (26.15%), Correct negative: 530 (89.98%)\n",
      "Total correct: 684 (58.06%)\n",
      "Eval Loss: 0.8029, Eval Accuracy: 0.5806\n",
      "___ Batch 252/313 _________________________\n",
      "Test Loss: 0.2853\n",
      "Correct positive: 161 (27.33%), Correct negative: 499 (84.72%)\n",
      "Total correct: 660 (56.03%)\n",
      "Eval Loss: 0.8331, Eval Accuracy: 0.5603\n",
      "___ Batch 262/313 _________________________\n",
      "Test Loss: 0.3112\n",
      "Correct positive: 230 (39.05%), Correct negative: 460 (78.10%)\n",
      "Total correct: 690 (58.57%)\n",
      "Eval Loss: 0.8765, Eval Accuracy: 0.5857\n",
      "___ Batch 272/313 _________________________\n",
      "Test Loss: 0.2936\n",
      "Correct positive: 145 (24.62%), Correct negative: 541 (91.85%)\n",
      "Total correct: 686 (58.23%)\n",
      "Eval Loss: 0.9247, Eval Accuracy: 0.5823\n",
      "___ Batch 282/313 _________________________\n",
      "Test Loss: 0.2784\n",
      "Correct positive: 110 (18.68%), Correct negative: 541 (91.85%)\n",
      "Total correct: 651 (55.26%)\n",
      "Eval Loss: 0.9013, Eval Accuracy: 0.5526\n",
      "___ Batch 292/313 _________________________\n",
      "Test Loss: 0.2606\n",
      "Correct positive: 70 (11.88%), Correct negative: 528 (89.64%)\n",
      "Total correct: 598 (50.76%)\n",
      "Eval Loss: 0.8503, Eval Accuracy: 0.5076\n",
      "___ Batch 302/313 _________________________\n",
      "Test Loss: 0.2665\n",
      "Correct positive: 103 (17.49%), Correct negative: 502 (85.23%)\n",
      "Total correct: 605 (51.36%)\n",
      "Eval Loss: 1.0722, Eval Accuracy: 0.5136\n",
      "___ Batch 312/313 _________________________\n",
      "Test Loss: 0.2695\n",
      "Correct positive: 94 (15.96%), Correct negative: 510 (86.59%)\n",
      "Total correct: 604 (51.27%)\n",
      "Eval Loss: 0.9297, Eval Accuracy: 0.5127\n",
      "=== Epoch 5/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8ebc9d9d416476ab27f0a073ad40907"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 9/313 _________________________\n",
      "Test Loss: 0.2553\n",
      "Correct positive: 112 (19.02%), Correct negative: 517 (87.78%)\n",
      "Total correct: 629 (53.40%)\n",
      "Eval Loss: 0.9185, Eval Accuracy: 0.5340\n",
      "___ Batch 19/313 _________________________\n",
      "Test Loss: 0.2478\n",
      "Correct positive: 72 (12.22%), Correct negative: 524 (88.96%)\n",
      "Total correct: 596 (50.59%)\n",
      "Eval Loss: 0.9292, Eval Accuracy: 0.5059\n",
      "___ Batch 29/313 _________________________\n",
      "Test Loss: 0.2354\n",
      "Correct positive: 103 (17.49%), Correct negative: 526 (89.30%)\n",
      "Total correct: 629 (53.40%)\n",
      "Eval Loss: 0.8320, Eval Accuracy: 0.5340\n",
      "___ Batch 39/313 _________________________\n",
      "Test Loss: 0.2698\n",
      "Correct positive: 60 (10.19%), Correct negative: 525 (89.13%)\n",
      "Total correct: 585 (49.66%)\n",
      "Eval Loss: 0.9532, Eval Accuracy: 0.4966\n",
      "___ Batch 49/313 _________________________\n",
      "Test Loss: 0.2400\n",
      "Correct positive: 55 (9.34%), Correct negative: 501 (85.06%)\n",
      "Total correct: 556 (47.20%)\n",
      "Eval Loss: 1.2363, Eval Accuracy: 0.4720\n",
      "___ Batch 59/313 _________________________\n",
      "Test Loss: 0.2708\n",
      "Correct positive: 119 (20.20%), Correct negative: 467 (79.29%)\n",
      "Total correct: 586 (49.75%)\n",
      "Eval Loss: 0.8246, Eval Accuracy: 0.4975\n",
      "___ Batch 69/313 _________________________\n",
      "Test Loss: 0.2572\n",
      "Correct positive: 69 (11.71%), Correct negative: 498 (84.55%)\n",
      "Total correct: 567 (48.13%)\n",
      "Eval Loss: 1.1076, Eval Accuracy: 0.4813\n",
      "___ Batch 79/313 _________________________\n",
      "Test Loss: 0.2471\n",
      "Correct positive: 80 (13.58%), Correct negative: 500 (84.89%)\n",
      "Total correct: 580 (49.24%)\n",
      "Eval Loss: 0.9759, Eval Accuracy: 0.4924\n",
      "___ Batch 89/313 _________________________\n",
      "Test Loss: 0.2377\n",
      "Correct positive: 143 (24.28%), Correct negative: 506 (85.91%)\n",
      "Total correct: 649 (55.09%)\n",
      "Eval Loss: 0.8849, Eval Accuracy: 0.5509\n",
      "___ Batch 99/313 _________________________\n",
      "Test Loss: 0.2450\n",
      "Correct positive: 102 (17.32%), Correct negative: 521 (88.46%)\n",
      "Total correct: 623 (52.89%)\n",
      "Eval Loss: 0.9712, Eval Accuracy: 0.5289\n",
      "___ Batch 109/313 _________________________\n",
      "Test Loss: 0.2421\n",
      "Correct positive: 116 (19.69%), Correct negative: 507 (86.08%)\n",
      "Total correct: 623 (52.89%)\n",
      "Eval Loss: 0.9126, Eval Accuracy: 0.5289\n",
      "___ Batch 119/313 _________________________\n",
      "Test Loss: 0.2329\n",
      "Correct positive: 109 (18.51%), Correct negative: 528 (89.64%)\n",
      "Total correct: 637 (54.07%)\n",
      "Eval Loss: 0.9127, Eval Accuracy: 0.5407\n",
      "___ Batch 129/313 _________________________\n",
      "Test Loss: 0.2265\n",
      "Correct positive: 123 (20.88%), Correct negative: 508 (86.25%)\n",
      "Total correct: 631 (53.57%)\n",
      "Eval Loss: 0.8849, Eval Accuracy: 0.5357\n",
      "___ Batch 139/313 _________________________\n",
      "Test Loss: 0.2605\n",
      "Correct positive: 104 (17.66%), Correct negative: 524 (88.96%)\n",
      "Total correct: 628 (53.31%)\n",
      "Eval Loss: 1.0265, Eval Accuracy: 0.5331\n",
      "___ Batch 149/313 _________________________\n",
      "Test Loss: 0.2317\n",
      "Correct positive: 147 (24.96%), Correct negative: 510 (86.59%)\n",
      "Total correct: 657 (55.77%)\n",
      "Eval Loss: 0.7471, Eval Accuracy: 0.5577\n",
      "___ Batch 159/313 _________________________\n",
      "Test Loss: 0.2354\n",
      "Correct positive: 126 (21.39%), Correct negative: 506 (85.91%)\n",
      "Total correct: 632 (53.65%)\n",
      "Eval Loss: 0.8349, Eval Accuracy: 0.5365\n",
      "___ Batch 169/313 _________________________\n",
      "Test Loss: 0.2397\n",
      "Correct positive: 112 (19.02%), Correct negative: 537 (91.17%)\n",
      "Total correct: 649 (55.09%)\n",
      "Eval Loss: 0.7552, Eval Accuracy: 0.5509\n",
      "___ Batch 179/313 _________________________\n",
      "Test Loss: 0.2446\n",
      "Correct positive: 113 (19.19%), Correct negative: 510 (86.59%)\n",
      "Total correct: 623 (52.89%)\n",
      "Eval Loss: 0.7787, Eval Accuracy: 0.5289\n",
      "___ Batch 189/313 _________________________\n",
      "Test Loss: 0.2566\n",
      "Correct positive: 116 (19.69%), Correct negative: 487 (82.68%)\n",
      "Total correct: 603 (51.19%)\n",
      "Eval Loss: 0.8737, Eval Accuracy: 0.5119\n",
      "___ Batch 199/313 _________________________\n",
      "Test Loss: 0.2269\n",
      "Correct positive: 124 (21.05%), Correct negative: 470 (79.80%)\n",
      "Total correct: 594 (50.42%)\n",
      "Eval Loss: 0.7773, Eval Accuracy: 0.5042\n",
      "___ Batch 209/313 _________________________\n",
      "Test Loss: 0.2168\n",
      "Correct positive: 107 (18.17%), Correct negative: 496 (84.21%)\n",
      "Total correct: 603 (51.19%)\n",
      "Eval Loss: 0.7598, Eval Accuracy: 0.5119\n",
      "___ Batch 219/313 _________________________\n",
      "Test Loss: 0.2242\n",
      "Correct positive: 95 (16.13%), Correct negative: 530 (89.98%)\n",
      "Total correct: 625 (53.06%)\n",
      "Eval Loss: 0.7411, Eval Accuracy: 0.5306\n",
      "___ Batch 229/313 _________________________\n",
      "Test Loss: 0.2384\n",
      "Correct positive: 83 (14.09%), Correct negative: 527 (89.47%)\n",
      "Total correct: 610 (51.78%)\n",
      "Eval Loss: 0.7915, Eval Accuracy: 0.5178\n",
      "___ Batch 239/313 _________________________\n",
      "Test Loss: 0.2098\n",
      "Correct positive: 124 (21.05%), Correct negative: 494 (83.87%)\n",
      "Total correct: 618 (52.46%)\n",
      "Eval Loss: 0.8194, Eval Accuracy: 0.5246\n",
      "___ Batch 249/313 _________________________\n",
      "Test Loss: 0.2417\n",
      "Correct positive: 124 (21.05%), Correct negative: 491 (83.36%)\n",
      "Total correct: 615 (52.21%)\n",
      "Eval Loss: 1.0817, Eval Accuracy: 0.5221\n",
      "___ Batch 259/313 _________________________\n",
      "Test Loss: 0.2355\n",
      "Correct positive: 62 (10.53%), Correct negative: 517 (87.78%)\n",
      "Total correct: 579 (49.15%)\n",
      "Eval Loss: 1.2732, Eval Accuracy: 0.4915\n",
      "___ Batch 269/313 _________________________\n",
      "Test Loss: 0.2282\n",
      "Correct positive: 94 (15.96%), Correct negative: 543 (92.19%)\n",
      "Total correct: 637 (54.07%)\n",
      "Eval Loss: 0.9705, Eval Accuracy: 0.5407\n",
      "___ Batch 279/313 _________________________\n",
      "Test Loss: 0.2206\n",
      "Correct positive: 114 (19.35%), Correct negative: 550 (93.38%)\n",
      "Total correct: 664 (56.37%)\n",
      "Eval Loss: 0.7612, Eval Accuracy: 0.5637\n",
      "___ Batch 289/313 _________________________\n",
      "Test Loss: 0.2426\n",
      "Correct positive: 140 (23.77%), Correct negative: 506 (85.91%)\n",
      "Total correct: 646 (54.84%)\n",
      "Eval Loss: 0.9424, Eval Accuracy: 0.5484\n",
      "___ Batch 299/313 _________________________\n",
      "Test Loss: 0.2319\n",
      "Correct positive: 100 (16.98%), Correct negative: 472 (80.14%)\n",
      "Total correct: 572 (48.56%)\n",
      "Eval Loss: 0.8831, Eval Accuracy: 0.4856\n",
      "___ Batch 309/313 _________________________\n",
      "Test Loss: 0.2077\n",
      "Correct positive: 123 (20.88%), Correct negative: 460 (78.10%)\n",
      "Total correct: 583 (49.49%)\n",
      "Eval Loss: 1.0750, Eval Accuracy: 0.4949\n",
      "Saving model at epoch 5...\n",
      "=== Epoch 6/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef1f7fb8aa544dd4a1798ea30473abc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 6/313 _________________________\n",
      "Test Loss: 0.2443\n",
      "Correct positive: 111 (18.85%), Correct negative: 524 (88.96%)\n",
      "Total correct: 635 (53.90%)\n",
      "Eval Loss: 0.8782, Eval Accuracy: 0.5390\n",
      "___ Batch 16/313 _________________________\n",
      "Test Loss: 0.2467\n",
      "Correct positive: 135 (22.92%), Correct negative: 536 (91.00%)\n",
      "Total correct: 671 (56.96%)\n",
      "Eval Loss: 0.7620, Eval Accuracy: 0.5696\n",
      "___ Batch 26/313 _________________________\n",
      "Test Loss: 0.2386\n",
      "Correct positive: 143 (24.28%), Correct negative: 516 (87.61%)\n",
      "Total correct: 659 (55.94%)\n",
      "Eval Loss: 0.9698, Eval Accuracy: 0.5594\n",
      "___ Batch 36/313 _________________________\n",
      "Test Loss: 0.2300\n",
      "Correct positive: 207 (35.14%), Correct negative: 482 (81.83%)\n",
      "Total correct: 689 (58.49%)\n",
      "Eval Loss: 0.8735, Eval Accuracy: 0.5849\n",
      "___ Batch 46/313 _________________________\n",
      "Test Loss: 0.2243\n",
      "Correct positive: 154 (26.15%), Correct negative: 493 (83.70%)\n",
      "Total correct: 647 (54.92%)\n",
      "Eval Loss: 0.8428, Eval Accuracy: 0.5492\n",
      "___ Batch 56/313 _________________________\n",
      "Test Loss: 0.2128\n",
      "Correct positive: 127 (21.56%), Correct negative: 470 (79.80%)\n",
      "Total correct: 597 (50.68%)\n",
      "Eval Loss: 1.1078, Eval Accuracy: 0.5068\n",
      "___ Batch 66/313 _________________________\n",
      "Test Loss: 0.2036\n",
      "Correct positive: 135 (22.92%), Correct negative: 485 (82.34%)\n",
      "Total correct: 620 (52.63%)\n",
      "Eval Loss: 1.0037, Eval Accuracy: 0.5263\n",
      "___ Batch 76/313 _________________________\n",
      "Test Loss: 0.2119\n",
      "Correct positive: 126 (21.39%), Correct negative: 501 (85.06%)\n",
      "Total correct: 627 (53.23%)\n",
      "Eval Loss: 1.0375, Eval Accuracy: 0.5323\n",
      "___ Batch 86/313 _________________________\n",
      "Test Loss: 0.2161\n",
      "Correct positive: 87 (14.77%), Correct negative: 518 (87.95%)\n",
      "Total correct: 605 (51.36%)\n",
      "Eval Loss: 1.1664, Eval Accuracy: 0.5136\n",
      "___ Batch 96/313 _________________________\n",
      "Test Loss: 0.2378\n",
      "Correct positive: 98 (16.64%), Correct negative: 459 (77.93%)\n",
      "Total correct: 557 (47.28%)\n",
      "Eval Loss: 1.2748, Eval Accuracy: 0.4728\n",
      "___ Batch 106/313 _________________________\n",
      "Test Loss: 0.2265\n",
      "Correct positive: 156 (26.49%), Correct negative: 437 (74.19%)\n",
      "Total correct: 593 (50.34%)\n",
      "Eval Loss: 1.0303, Eval Accuracy: 0.5034\n",
      "___ Batch 116/313 _________________________\n",
      "Test Loss: 0.2383\n",
      "Correct positive: 146 (24.79%), Correct negative: 457 (77.59%)\n",
      "Total correct: 603 (51.19%)\n",
      "Eval Loss: 0.8659, Eval Accuracy: 0.5119\n",
      "___ Batch 126/313 _________________________\n",
      "Test Loss: 0.2301\n",
      "Correct positive: 106 (18.00%), Correct negative: 514 (87.27%)\n",
      "Total correct: 620 (52.63%)\n",
      "Eval Loss: 0.9157, Eval Accuracy: 0.5263\n",
      "___ Batch 136/313 _________________________\n",
      "Test Loss: 0.2529\n",
      "Correct positive: 90 (15.28%), Correct negative: 526 (89.30%)\n",
      "Total correct: 616 (52.29%)\n",
      "Eval Loss: 0.9337, Eval Accuracy: 0.5229\n",
      "___ Batch 146/313 _________________________\n",
      "Test Loss: 0.2457\n",
      "Correct positive: 185 (31.41%), Correct negative: 470 (79.80%)\n",
      "Total correct: 655 (55.60%)\n",
      "Eval Loss: 0.7416, Eval Accuracy: 0.5560\n",
      "___ Batch 156/313 _________________________\n",
      "Test Loss: 0.2449\n",
      "Correct positive: 118 (20.03%), Correct negative: 541 (91.85%)\n",
      "Total correct: 659 (55.94%)\n",
      "Eval Loss: 0.7101, Eval Accuracy: 0.5594\n",
      "___ Batch 166/313 _________________________\n",
      "Test Loss: 0.2136\n",
      "Correct positive: 105 (17.83%), Correct negative: 548 (93.04%)\n",
      "Total correct: 653 (55.43%)\n",
      "Eval Loss: 0.7365, Eval Accuracy: 0.5543\n",
      "___ Batch 176/313 _________________________\n",
      "Test Loss: 0.2327\n",
      "Correct positive: 82 (13.92%), Correct negative: 546 (92.70%)\n",
      "Total correct: 628 (53.31%)\n",
      "Eval Loss: 0.7929, Eval Accuracy: 0.5331\n",
      "___ Batch 186/313 _________________________\n",
      "Test Loss: 0.2475\n",
      "Correct positive: 105 (17.83%), Correct negative: 518 (87.95%)\n",
      "Total correct: 623 (52.89%)\n",
      "Eval Loss: 0.8054, Eval Accuracy: 0.5289\n",
      "___ Batch 196/313 _________________________\n",
      "Test Loss: 0.2232\n",
      "Correct positive: 90 (15.28%), Correct negative: 526 (89.30%)\n",
      "Total correct: 616 (52.29%)\n",
      "Eval Loss: 0.9177, Eval Accuracy: 0.5229\n",
      "___ Batch 206/313 _________________________\n",
      "Test Loss: 0.2347\n",
      "Correct positive: 98 (16.64%), Correct negative: 516 (87.61%)\n",
      "Total correct: 614 (52.12%)\n",
      "Eval Loss: 0.8812, Eval Accuracy: 0.5212\n",
      "___ Batch 216/313 _________________________\n",
      "Test Loss: 0.2401\n",
      "Correct positive: 135 (22.92%), Correct negative: 522 (88.62%)\n",
      "Total correct: 657 (55.77%)\n",
      "Eval Loss: 1.0684, Eval Accuracy: 0.5577\n",
      "___ Batch 226/313 _________________________\n",
      "Test Loss: 0.2346\n",
      "Correct positive: 164 (27.84%), Correct negative: 488 (82.85%)\n",
      "Total correct: 652 (55.35%)\n",
      "Eval Loss: 1.0530, Eval Accuracy: 0.5535\n",
      "___ Batch 236/313 _________________________\n",
      "Test Loss: 0.2243\n",
      "Correct positive: 163 (27.67%), Correct negative: 459 (77.93%)\n",
      "Total correct: 622 (52.80%)\n",
      "Eval Loss: 1.1887, Eval Accuracy: 0.5280\n",
      "___ Batch 246/313 _________________________\n",
      "Test Loss: 0.2242\n",
      "Correct positive: 110 (18.68%), Correct negative: 432 (73.34%)\n",
      "Total correct: 542 (46.01%)\n",
      "Eval Loss: 1.2481, Eval Accuracy: 0.4601\n",
      "___ Batch 256/313 _________________________\n",
      "Test Loss: 0.2189\n",
      "Correct positive: 75 (12.73%), Correct negative: 475 (80.65%)\n",
      "Total correct: 550 (46.69%)\n",
      "Eval Loss: 1.0662, Eval Accuracy: 0.4669\n",
      "___ Batch 266/313 _________________________\n",
      "Test Loss: 0.1996\n",
      "Correct positive: 210 (35.65%), Correct negative: 443 (75.21%)\n",
      "Total correct: 653 (55.43%)\n",
      "Eval Loss: 0.9351, Eval Accuracy: 0.5543\n",
      "___ Batch 276/313 _________________________\n",
      "Test Loss: 0.2046\n",
      "Correct positive: 97 (16.47%), Correct negative: 512 (86.93%)\n",
      "Total correct: 609 (51.70%)\n",
      "Eval Loss: 0.8422, Eval Accuracy: 0.5170\n",
      "___ Batch 286/313 _________________________\n",
      "Test Loss: 0.2340\n",
      "Correct positive: 139 (23.60%), Correct negative: 526 (89.30%)\n",
      "Total correct: 665 (56.45%)\n",
      "Eval Loss: 0.7413, Eval Accuracy: 0.5645\n",
      "___ Batch 296/313 _________________________\n",
      "Test Loss: 0.2061\n",
      "Correct positive: 149 (25.30%), Correct negative: 483 (82.00%)\n",
      "Total correct: 632 (53.65%)\n",
      "Eval Loss: 0.8463, Eval Accuracy: 0.5365\n",
      "___ Batch 306/313 _________________________\n",
      "Test Loss: 0.2512\n",
      "Correct positive: 199 (33.79%), Correct negative: 414 (70.29%)\n",
      "Total correct: 613 (52.04%)\n",
      "Eval Loss: 1.0367, Eval Accuracy: 0.5204\n",
      "=== Epoch 7/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0ff2b3cab5d40848093c332bb5025ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 3/313 _________________________\n",
      "Test Loss: 0.2201\n",
      "Correct positive: 114 (19.35%), Correct negative: 477 (80.98%)\n",
      "Total correct: 591 (50.17%)\n",
      "Eval Loss: 0.9898, Eval Accuracy: 0.5017\n",
      "___ Batch 13/313 _________________________\n",
      "Test Loss: 0.2576\n",
      "Correct positive: 72 (12.22%), Correct negative: 527 (89.47%)\n",
      "Total correct: 599 (50.85%)\n",
      "Eval Loss: 1.4135, Eval Accuracy: 0.5085\n",
      "___ Batch 23/313 _________________________\n",
      "Test Loss: 0.2199\n",
      "Correct positive: 110 (18.68%), Correct negative: 524 (88.96%)\n",
      "Total correct: 634 (53.82%)\n",
      "Eval Loss: 0.9170, Eval Accuracy: 0.5382\n",
      "___ Batch 33/313 _________________________\n",
      "Test Loss: 0.2180\n",
      "Correct positive: 92 (15.62%), Correct negative: 512 (86.93%)\n",
      "Total correct: 604 (51.27%)\n",
      "Eval Loss: 1.0765, Eval Accuracy: 0.5127\n",
      "___ Batch 43/313 _________________________\n",
      "Test Loss: 0.2234\n",
      "Correct positive: 109 (18.51%), Correct negative: 529 (89.81%)\n",
      "Total correct: 638 (54.16%)\n",
      "Eval Loss: 0.8159, Eval Accuracy: 0.5416\n",
      "___ Batch 53/313 _________________________\n",
      "Test Loss: 0.2201\n",
      "Correct positive: 71 (12.05%), Correct negative: 529 (89.81%)\n",
      "Total correct: 600 (50.93%)\n",
      "Eval Loss: 0.9378, Eval Accuracy: 0.5093\n",
      "___ Batch 63/313 _________________________\n",
      "Test Loss: 0.2219\n",
      "Correct positive: 96 (16.30%), Correct negative: 531 (90.15%)\n",
      "Total correct: 627 (53.23%)\n",
      "Eval Loss: 0.8828, Eval Accuracy: 0.5323\n",
      "___ Batch 73/313 _________________________\n",
      "Test Loss: 0.2435\n",
      "Correct positive: 77 (13.07%), Correct negative: 529 (89.81%)\n",
      "Total correct: 606 (51.44%)\n",
      "Eval Loss: 0.7858, Eval Accuracy: 0.5144\n",
      "___ Batch 83/313 _________________________\n",
      "Test Loss: 0.2259\n",
      "Correct positive: 85 (14.43%), Correct negative: 531 (90.15%)\n",
      "Total correct: 616 (52.29%)\n",
      "Eval Loss: 0.8798, Eval Accuracy: 0.5229\n",
      "___ Batch 93/313 _________________________\n",
      "Test Loss: 0.2523\n",
      "Correct positive: 74 (12.56%), Correct negative: 506 (85.91%)\n",
      "Total correct: 580 (49.24%)\n",
      "Eval Loss: 1.1712, Eval Accuracy: 0.4924\n",
      "___ Batch 103/313 _________________________\n",
      "Test Loss: 0.2073\n",
      "Correct positive: 77 (13.07%), Correct negative: 525 (89.13%)\n",
      "Total correct: 602 (51.10%)\n",
      "Eval Loss: 0.7578, Eval Accuracy: 0.5110\n",
      "___ Batch 113/313 _________________________\n",
      "Test Loss: 0.2191\n",
      "Correct positive: 58 (9.85%), Correct negative: 542 (92.02%)\n",
      "Total correct: 600 (50.93%)\n",
      "Eval Loss: 0.7740, Eval Accuracy: 0.5093\n",
      "___ Batch 123/313 _________________________\n",
      "Test Loss: 0.2042\n",
      "Correct positive: 90 (15.28%), Correct negative: 530 (89.98%)\n",
      "Total correct: 620 (52.63%)\n",
      "Eval Loss: 0.7930, Eval Accuracy: 0.5263\n",
      "___ Batch 133/313 _________________________\n",
      "Test Loss: 0.2194\n",
      "Correct positive: 111 (18.85%), Correct negative: 489 (83.02%)\n",
      "Total correct: 600 (50.93%)\n",
      "Eval Loss: 0.8811, Eval Accuracy: 0.5093\n",
      "___ Batch 143/313 _________________________\n",
      "Test Loss: 0.1952\n",
      "Correct positive: 179 (30.39%), Correct negative: 508 (86.25%)\n",
      "Total correct: 687 (58.32%)\n",
      "Eval Loss: 0.6994, Eval Accuracy: 0.5832\n",
      "___ Batch 153/313 _________________________\n",
      "Test Loss: 0.1985\n",
      "Correct positive: 79 (13.41%), Correct negative: 545 (92.53%)\n",
      "Total correct: 624 (52.97%)\n",
      "Eval Loss: 0.7969, Eval Accuracy: 0.5297\n",
      "___ Batch 163/313 _________________________\n",
      "Test Loss: 0.1893\n",
      "Correct positive: 154 (26.15%), Correct negative: 518 (87.95%)\n",
      "Total correct: 672 (57.05%)\n",
      "Eval Loss: 0.7669, Eval Accuracy: 0.5705\n",
      "___ Batch 173/313 _________________________\n",
      "Test Loss: 0.2101\n",
      "Correct positive: 178 (30.22%), Correct negative: 490 (83.19%)\n",
      "Total correct: 668 (56.71%)\n",
      "Eval Loss: 0.8947, Eval Accuracy: 0.5671\n",
      "___ Batch 183/313 _________________________\n",
      "Test Loss: 0.1967\n",
      "Correct positive: 150 (25.47%), Correct negative: 525 (89.13%)\n",
      "Total correct: 675 (57.30%)\n",
      "Eval Loss: 0.7535, Eval Accuracy: 0.5730\n",
      "___ Batch 193/313 _________________________\n",
      "Test Loss: 0.1901\n",
      "Correct positive: 158 (26.83%), Correct negative: 508 (86.25%)\n",
      "Total correct: 666 (56.54%)\n",
      "Eval Loss: 0.8694, Eval Accuracy: 0.5654\n",
      "___ Batch 203/313 _________________________\n",
      "Test Loss: 0.1904\n",
      "Correct positive: 104 (17.66%), Correct negative: 527 (89.47%)\n",
      "Total correct: 631 (53.57%)\n",
      "Eval Loss: 0.9507, Eval Accuracy: 0.5357\n",
      "___ Batch 213/313 _________________________\n",
      "Test Loss: 0.1901\n",
      "Correct positive: 159 (26.99%), Correct negative: 485 (82.34%)\n",
      "Total correct: 644 (54.67%)\n",
      "Eval Loss: 0.9133, Eval Accuracy: 0.5467\n",
      "___ Batch 223/313 _________________________\n",
      "Test Loss: 0.2314\n",
      "Correct positive: 167 (28.35%), Correct negative: 487 (82.68%)\n",
      "Total correct: 654 (55.52%)\n",
      "Eval Loss: 0.8709, Eval Accuracy: 0.5552\n",
      "___ Batch 233/313 _________________________\n",
      "Test Loss: 0.2159\n",
      "Correct positive: 130 (22.07%), Correct negative: 523 (88.79%)\n",
      "Total correct: 653 (55.43%)\n",
      "Eval Loss: 0.9216, Eval Accuracy: 0.5543\n",
      "___ Batch 243/313 _________________________\n",
      "Test Loss: 0.2152\n",
      "Correct positive: 114 (19.35%), Correct negative: 519 (88.12%)\n",
      "Total correct: 633 (53.74%)\n",
      "Eval Loss: 1.0773, Eval Accuracy: 0.5374\n",
      "___ Batch 253/313 _________________________\n",
      "Test Loss: 0.1967\n",
      "Correct positive: 135 (22.92%), Correct negative: 512 (86.93%)\n",
      "Total correct: 647 (54.92%)\n",
      "Eval Loss: 0.8574, Eval Accuracy: 0.5492\n",
      "___ Batch 263/313 _________________________\n",
      "Test Loss: 0.2050\n",
      "Correct positive: 100 (16.98%), Correct negative: 484 (82.17%)\n",
      "Total correct: 584 (49.58%)\n",
      "Eval Loss: 1.0222, Eval Accuracy: 0.4958\n",
      "___ Batch 273/313 _________________________\n",
      "Test Loss: 0.2261\n",
      "Correct positive: 104 (17.66%), Correct negative: 524 (88.96%)\n",
      "Total correct: 628 (53.31%)\n",
      "Eval Loss: 0.9829, Eval Accuracy: 0.5331\n",
      "___ Batch 283/313 _________________________\n",
      "Test Loss: 0.2228\n",
      "Correct positive: 91 (15.45%), Correct negative: 534 (90.66%)\n",
      "Total correct: 625 (53.06%)\n",
      "Eval Loss: 0.9393, Eval Accuracy: 0.5306\n",
      "___ Batch 293/313 _________________________\n",
      "Test Loss: 0.2324\n",
      "Correct positive: 95 (16.13%), Correct negative: 505 (85.74%)\n",
      "Total correct: 600 (50.93%)\n",
      "Eval Loss: 1.1491, Eval Accuracy: 0.5093\n",
      "___ Batch 303/313 _________________________\n",
      "Test Loss: 0.2042\n",
      "Correct positive: 138 (23.43%), Correct negative: 518 (87.95%)\n",
      "Total correct: 656 (55.69%)\n",
      "Eval Loss: 0.8764, Eval Accuracy: 0.5569\n",
      "___ Batch 313/313 _________________________\n",
      "Test Loss: 0.2092\n",
      "Correct positive: 147 (24.96%), Correct negative: 483 (82.00%)\n",
      "Total correct: 630 (53.48%)\n",
      "Eval Loss: 0.9767, Eval Accuracy: 0.5348\n",
      "=== Epoch 8/20 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5f7a66ed06549b48afc9d0375d7fcfb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Batch 10/313 _________________________\n",
      "Test Loss: 0.2142\n",
      "Correct positive: 163 (27.67%), Correct negative: 483 (82.00%)\n",
      "Total correct: 646 (54.84%)\n",
      "Eval Loss: 0.9249, Eval Accuracy: 0.5484\n",
      "___ Batch 20/313 _________________________\n",
      "Test Loss: 0.2041\n",
      "Correct positive: 107 (18.17%), Correct negative: 512 (86.93%)\n",
      "Total correct: 619 (52.55%)\n",
      "Eval Loss: 0.9365, Eval Accuracy: 0.5255\n",
      "___ Batch 30/313 _________________________\n",
      "Test Loss: 0.1943\n",
      "Correct positive: 110 (18.68%), Correct negative: 494 (83.87%)\n",
      "Total correct: 604 (51.27%)\n",
      "Eval Loss: 0.9279, Eval Accuracy: 0.5127\n",
      "___ Batch 40/313 _________________________\n",
      "Test Loss: 0.1913\n",
      "Correct positive: 119 (20.20%), Correct negative: 513 (87.10%)\n",
      "Total correct: 632 (53.65%)\n",
      "Eval Loss: 0.9512, Eval Accuracy: 0.5365\n",
      "___ Batch 50/313 _________________________\n",
      "Test Loss: 0.1933\n",
      "Correct positive: 103 (17.49%), Correct negative: 493 (83.70%)\n",
      "Total correct: 596 (50.59%)\n",
      "Eval Loss: 1.0239, Eval Accuracy: 0.5059\n",
      "___ Batch 60/313 _________________________\n",
      "Test Loss: 0.2002\n",
      "Correct positive: 108 (18.34%), Correct negative: 469 (79.63%)\n",
      "Total correct: 577 (48.98%)\n",
      "Eval Loss: 1.0642, Eval Accuracy: 0.4898\n",
      "___ Batch 70/313 _________________________\n",
      "Test Loss: 0.2181\n",
      "Correct positive: 118 (20.03%), Correct negative: 492 (83.53%)\n",
      "Total correct: 610 (51.78%)\n",
      "Eval Loss: 0.8122, Eval Accuracy: 0.5178\n",
      "___ Batch 80/313 _________________________\n",
      "Test Loss: 0.2116\n",
      "Correct positive: 116 (19.69%), Correct negative: 486 (82.51%)\n",
      "Total correct: 602 (51.10%)\n",
      "Eval Loss: 1.0911, Eval Accuracy: 0.5110\n",
      "___ Batch 90/313 _________________________\n",
      "Test Loss: 0.2220\n",
      "Correct positive: 94 (15.96%), Correct negative: 508 (86.25%)\n",
      "Total correct: 602 (51.10%)\n",
      "Eval Loss: 1.1856, Eval Accuracy: 0.5110\n",
      "___ Batch 100/313 _________________________\n",
      "Test Loss: 0.2138\n",
      "Correct positive: 113 (19.19%), Correct negative: 502 (85.23%)\n",
      "Total correct: 615 (52.21%)\n",
      "Eval Loss: 0.8162, Eval Accuracy: 0.5221\n",
      "___ Batch 110/313 _________________________\n",
      "Test Loss: 0.2097\n",
      "Correct positive: 107 (18.17%), Correct negative: 441 (74.87%)\n",
      "Total correct: 548 (46.52%)\n",
      "Eval Loss: 1.2633, Eval Accuracy: 0.4652\n",
      "___ Batch 120/313 _________________________\n",
      "Test Loss: 0.2014\n",
      "Correct positive: 122 (20.71%), Correct negative: 465 (78.95%)\n",
      "Total correct: 587 (49.83%)\n",
      "Eval Loss: 1.0341, Eval Accuracy: 0.4983\n",
      "___ Batch 130/313 _________________________\n",
      "Test Loss: 0.2013\n",
      "Correct positive: 214 (36.33%), Correct negative: 429 (72.84%)\n",
      "Total correct: 643 (54.58%)\n",
      "Eval Loss: 0.7733, Eval Accuracy: 0.5458\n",
      "___ Batch 140/313 _________________________\n",
      "Test Loss: 0.1878\n",
      "Correct positive: 157 (26.66%), Correct negative: 426 (72.33%)\n",
      "Total correct: 583 (49.49%)\n",
      "Eval Loss: 1.0679, Eval Accuracy: 0.4949\n",
      "___ Batch 150/313 _________________________\n",
      "Test Loss: 0.2069\n",
      "Correct positive: 122 (20.71%), Correct negative: 496 (84.21%)\n",
      "Total correct: 618 (52.46%)\n",
      "Eval Loss: 1.0889, Eval Accuracy: 0.5246\n",
      "___ Batch 160/313 _________________________\n",
      "Test Loss: 0.2294\n",
      "Correct positive: 108 (18.34%), Correct negative: 510 (86.59%)\n",
      "Total correct: 618 (52.46%)\n",
      "Eval Loss: 1.1825, Eval Accuracy: 0.5246\n",
      "___ Batch 170/313 _________________________\n",
      "Test Loss: 0.2030\n",
      "Correct positive: 100 (16.98%), Correct negative: 487 (82.68%)\n",
      "Total correct: 587 (49.83%)\n",
      "Eval Loss: 1.1325, Eval Accuracy: 0.4983\n",
      "___ Batch 180/313 _________________________\n",
      "Test Loss: 0.2089\n",
      "Correct positive: 160 (27.16%), Correct negative: 498 (84.55%)\n",
      "Total correct: 658 (55.86%)\n",
      "Eval Loss: 0.8770, Eval Accuracy: 0.5586\n",
      "___ Batch 190/313 _________________________\n",
      "Test Loss: 0.1952\n",
      "Correct positive: 139 (23.60%), Correct negative: 516 (87.61%)\n",
      "Total correct: 655 (55.60%)\n",
      "Eval Loss: 0.9908, Eval Accuracy: 0.5560\n",
      "___ Batch 200/313 _________________________\n",
      "Test Loss: 0.2039\n",
      "Correct positive: 101 (17.15%), Correct negative: 519 (88.12%)\n",
      "Total correct: 620 (52.63%)\n",
      "Eval Loss: 1.0907, Eval Accuracy: 0.5263\n",
      "___ Batch 210/313 _________________________\n",
      "Test Loss: 0.1871\n",
      "Correct positive: 133 (22.58%), Correct negative: 508 (86.25%)\n",
      "Total correct: 641 (54.41%)\n",
      "Eval Loss: 0.9644, Eval Accuracy: 0.5441\n",
      "___ Batch 220/313 _________________________\n",
      "Test Loss: 0.1850\n",
      "Correct positive: 141 (23.94%), Correct negative: 487 (82.68%)\n",
      "Total correct: 628 (53.31%)\n",
      "Eval Loss: 0.9167, Eval Accuracy: 0.5331\n",
      "___ Batch 230/313 _________________________\n",
      "Test Loss: 0.1967\n",
      "Correct positive: 139 (23.60%), Correct negative: 474 (80.48%)\n",
      "Total correct: 613 (52.04%)\n",
      "Eval Loss: 0.9077, Eval Accuracy: 0.5204\n",
      "___ Batch 240/313 _________________________\n",
      "Test Loss: 0.1882\n",
      "Correct positive: 176 (29.88%), Correct negative: 481 (81.66%)\n",
      "Total correct: 657 (55.77%)\n",
      "Eval Loss: 0.8070, Eval Accuracy: 0.5577\n",
      "___ Batch 250/313 _________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Workspace.__del__ at 0x7cf8b72c8a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vincie/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/workspace.py\", line 62, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m___ Batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_batch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_dataloader)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m _________________________\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Model testing\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m test_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m test_losses\u001B[38;5;241m.\u001B[39mappend(test_loss)\n\u001B[1;32m     25\u001B[0m test_epoch_marker_pos \u001B[38;5;241m=\u001B[39m [marker\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m10\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m marker \u001B[38;5;129;01min\u001B[39;00m epoch_marker_pos \u001B[38;5;28;01mif\u001B[39;00m marker \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[13], line 32\u001B[0m, in \u001B[0;36mtest\u001B[0;34m(model, dataloader)\u001B[0m\n\u001B[1;32m     29\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_anchor, batch_pos, batch_neg \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m     33\u001B[0m         batch_anchor \u001B[38;5;241m=\u001B[39m batch_anchor\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     34\u001B[0m         batch_pos \u001B[38;5;241m=\u001B[39m batch_pos\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Git/master-thesis/notebooks/util.py:346\u001B[0m, in \u001B[0;36mGraphTripletDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;66;03m# Get n-hop neighbourhood for each paper\u001B[39;00m\n\u001B[1;32m    345\u001B[0m     g_a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, anchor, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 346\u001B[0m     g_p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_hop_neighbourhood\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNodeType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPUBLICATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_hops\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     g_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, neg, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;66;03m# Convert to PyG Data objects\u001B[39;00m\n",
      "File \u001B[0;32m~/Git/master-thesis/src/shared/graph_sampling.py:56\u001B[0m, in \u001B[0;36mGraphSampling.n_hop_neighbourhood\u001B[0;34m(self, start_node_type, start_node_id, node_types, edge_types, max_level)\u001B[0m\n\u001B[1;32m     46\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;124m        MATCH (start:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124mid: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124m        CALL apoc.path.subgraphAll(start, \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;124m        RETURN nodes, relationships\u001B[39m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     55\u001B[0m result \u001B[38;5;241m=\u001B[39m session\u001B[38;5;241m.\u001B[39mrun(query)\n\u001B[0;32m---> 56\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msingle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:485\u001B[0m, in \u001B[0;36mResult.single\u001B[0;34m(self, strict)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;129m@NonConcurrentMethodChecker\u001B[39m\u001B[38;5;241m.\u001B[39mnon_concurrent_method\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msingle\u001B[39m(\u001B[38;5;28mself\u001B[39m, strict: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mOptional[Record]:\n\u001B[1;32m    451\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Obtain the next and only remaining record or None.\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \n\u001B[1;32m    453\u001B[0m \u001B[38;5;124;03m    Calling this method always exhausts the result.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;124;03m        * Can raise :exc:`.ResultConsumedError`.\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 485\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    486\u001B[0m     buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer \u001B[38;5;241m=\u001B[39m deque()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:318\u001B[0m, in \u001B[0;36mResult._buffer\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    317\u001B[0m record_buffer \u001B[38;5;241m=\u001B[39m deque()\n\u001B[0;32m--> 318\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m    319\u001B[0m     record_buffer\u001B[38;5;241m.\u001B[39mappend(record)\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(record_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m n:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:270\u001B[0m, in \u001B[0;36mResult.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_record_buffer\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_streaming:\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discarding:\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_discard()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:178\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py:846\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    845\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[0;32m--> 846\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhydration_hooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponses\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhydration_hooks\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    849\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_message(tag, fields)\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m monotonic()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:72\u001B[0m, in \u001B[0;36mInbox.pop\u001B[0;34m(self, hydration_hooks)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpop\u001B[39m(\u001B[38;5;28mself\u001B[39m, hydration_hooks):\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer_one_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     74\u001B[0m         size, tag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unpacker\u001B[38;5;241m.\u001B[39munpack_structure_header()\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:51\u001B[0m, in \u001B[0;36mInbox._buffer_one_chunk\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m chunk_size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;66;03m# Determine the chunk size and skip noop\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m         \u001B[43mreceive_into_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_socket\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m         chunk_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer\u001B[38;5;241m.\u001B[39mpop_u16()\n\u001B[1;32m     53\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk_size \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:326\u001B[0m, in \u001B[0;36mreceive_into_buffer\u001B[0;34m(sock, buffer, n_bytes)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(buffer\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;28;01mas\u001B[39;00m view:\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mused \u001B[38;5;241m<\u001B[39m end:\n\u001B[0;32m--> 326\u001B[0m         n \u001B[38;5;241m=\u001B[39m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mview\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mused\u001B[49m\u001B[43m:\u001B[49m\u001B[43mend\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mused\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    328\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py:493\u001B[0m, in \u001B[0;36mBoltSocket.recv_into\u001B[0;34m(self, buffer, nbytes)\u001B[0m\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrecv_into\u001B[39m(\u001B[38;5;28mself\u001B[39m, buffer, nbytes):\n\u001B[0;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_io\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_socket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py:468\u001B[0m, in \u001B[0;36mBoltSocket._wait_for_io\u001B[0;34m(self, func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wait_for_io\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deadline \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 468\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    469\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_socket\u001B[38;5;241m.\u001B[39mgettimeout()\n\u001B[1;32m    470\u001B[0m     deadline_timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deadline\u001B[38;5;241m.\u001B[39mto_timeout()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
