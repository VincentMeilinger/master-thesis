{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_geometric.nn.models.dimenet import triplets\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from torch_geometric.data import HeteroData\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import TripletMarginLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.datasets.who_is_who import WhoIsWhoDataset\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot, edge_pyg_key_vals\n",
    "from src.model.loss.triplet_loss import TripletLoss\n",
    "from src.shared import config\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, HeteroConv\n",
    "from torch_geometric.nn import Linear\n",
    "\n",
    "\n",
    "class TestGATv2Encoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            out_channels,\n",
    "            edge_feature_dim,\n",
    "            edge_types,\n",
    "            node_types,\n",
    "            heads=5,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=True\n",
    "    ):\n",
    "        super(TestGATv2Encoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = HeteroConv({\n",
    "            edge_type: GATv2Conv(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                heads=heads,\n",
    "                concat=concat,\n",
    "                negative_slope=negative_slope,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=add_self_loops,\n",
    "                edge_dim=edge_feature_dim\n",
    "            )\n",
    "            for edge_type in edge_types\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv_2 = HeteroConv({\n",
    "            edge_type: GATv2Conv(\n",
    "                in_channels=heads * hidden_channels if concat else hidden_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                heads=heads,\n",
    "                concat=concat,\n",
    "                negative_slope=negative_slope,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=add_self_loops,\n",
    "                edge_dim=edge_feature_dim\n",
    "            )\n",
    "            for edge_type in edge_types\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.lin_out = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_out[node_type] = torch.nn.Sequential(\n",
    "                Linear(heads * hidden_channels, hidden_channels),\n",
    "                torch.nn.Dropout(dropout),\n",
    "                Linear(hidden_channels, out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_feature_dict):\n",
    "        \"\"\"\n",
    "        :param x_dict: dict of torch.Tensor\n",
    "            Node feature vectors for each node type.\n",
    "        :param edge_index_dict: dict of torch.Tensor\n",
    "            Edge indices for each edge type.\n",
    "        :param edge_feature_dict: dict of torch.Tensor\n",
    "            Edge attribute vectors for each edge type.\n",
    "        \"\"\"\n",
    "        \n",
    "        x_dict = self.conv_1(x_dict, edge_index_dict, edge_feature_dict)\n",
    "        for node_type in x_dict.keys():\n",
    "            x_dict[node_type] = F.dropout(F.relu(x_dict[node_type]), p=0.5, training=self.training)\n",
    "\n",
    "        x_dict = self.conv_2(x_dict, edge_index_dict, edge_feature_dict)\n",
    "        for node_type in x_dict.keys():\n",
    "            x_dict[node_type] = F.dropout(F.relu(x_dict[node_type]), p=0.5, training=self.training)\n",
    "\n",
    "        out_dict = {}\n",
    "        for node_type in x_dict.keys():\n",
    "            out_dict[node_type] = self.lin_out[node_type](x_dict[node_type])\n",
    "\n",
    "        return out_dict"
   ],
   "id": "8d8f242984835d71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "node_feature_dim = 32\n",
    "edge_feature_dim = EdgeType.SIM_TITLE.one_hot().shape[0]\n",
    "gat_embedding_dim = 32\n",
    "\n",
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "]\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(device)\n",
    "\n",
    "encoder = TestGATv2Encoder(\n",
    "    in_channels=node_feature_dim,\n",
    "    hidden_channels=32,\n",
    "    out_channels=gat_embedding_dim,\n",
    "    edge_feature_dim=edge_feature_dim,\n",
    "    edge_types=[edge_pyg_key_vals[edge_type] for edge_type in included_edges],\n",
    "    node_types=[node_type.value for node_type in included_nodes],\n",
    "    add_self_loops=False\n",
    ")\n",
    "encoder.to(device)"
   ],
   "id": "ab76e036f95625a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.shared.neo_to_pyg import GraphSampling\n",
    "class TripletDataset:\n",
    "    def __init__(self, train_ratio=0.7):\n",
    "        self.train_ratio = train_ratio\n",
    "        \n",
    "    def iter_generated_triplets(self):\n",
    "        for triplets in WhoIsWhoDataset.sample_triplets(node_spec=included_nodes, edge_spec=included_edges, node_properties=[\"vec\"]):\n",
    "            train_split = int(len(triplets) * self.train_ratio)\n",
    "            yield triplets[:train_split], triplets[train_split:]"
   ],
   "id": "5fed188e49fbd8ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_loss(loss, acc, save_file: str = 'plot.png'):\n",
    "    plt.close()\n",
    "    path = \"./data/plots/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    save_file = os.path.join(path, save_file)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(acc, marker='o', linestyle='-', color='r')\n",
    "    \n",
    "    plt.xlabel(f'Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_file)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def train(encoder, triplets: list, optimizer, triplet_loss):\n",
    "    encoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_samples = 0\n",
    "    # Training loop\n",
    "    for triplet in triplets:    \n",
    "        anchor, pos, neg = triplet\n",
    "        anchor = anchor.to(device)\n",
    "        pos = pos.to(device)\n",
    "        neg = neg.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        anchor_emb = encoder.forward(anchor.x_dict, anchor.edge_index_dict, anchor.edge_attr_dict)\n",
    "        pos_emb = encoder.forward(pos.x_dict, pos.edge_index_dict, pos.edge_attr_dict)\n",
    "        neg_emb = encoder.forward(neg.x_dict, neg.edge_index_dict, neg.edge_attr_dict)\n",
    "        \n",
    "        # Retrieve embedding of respective start nodes\n",
    "        anchor_emb = anchor_emb[\"Publication\"][0]\n",
    "        pos_emb = pos_emb[\"Publication\"][0]\n",
    "        neg_emb = neg_emb[\"Publication\"][0]\n",
    "        #print(anchor_emb.shape, pos_emb.shape, neg_emb.shape)\n",
    "        \n",
    "        loss = triplet_loss(anchor_emb, pos_emb, neg_emb)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_samples += 1\n",
    "        \n",
    "    return total_loss / num_samples\n",
    "\n",
    "def validate(encoder, triplets: list, triplet_loss):\n",
    "    encoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for anchor, pos, neg in triplets:            \n",
    "            anchor = anchor.to(device)\n",
    "            pos = pos.to(device)\n",
    "            neg = neg.to(device)\n",
    "            \n",
    "            anchor_emb = encoder.forward(anchor.x_dict, anchor.edge_index_dict, anchor.edge_attr_dict)\n",
    "            pos_emb = encoder.forward(pos.x_dict, pos.edge_index_dict, pos.edge_attr_dict)\n",
    "            neg_emb = encoder.forward(neg.x_dict, neg.edge_index_dict, neg.edge_attr_dict)\n",
    "            \n",
    "            # Retrieve embedding of respective start nodes\n",
    "            anchor_emb = anchor_emb[\"Publication\"][0]\n",
    "            pos_emb = pos_emb[\"Publication\"][0]\n",
    "            neg_emb = neg_emb[\"Publication\"][0]\n",
    "            \n",
    "            loss = triplet_loss(anchor_emb, pos_emb, neg_emb)\n",
    "            total_loss += loss.item()\n",
    "            num_samples += 1\n",
    "    return total_loss / num_samples\n",
    "\n",
    "def test(model, data_loader: TripletDataset):\n",
    "    model.eval()\n",
    "    \n",
    "    accuracy = []\n",
    "    with torch.no_grad():\n",
    "        for anchor, pos, neg in data_loader.iter_generated_triplets(test=True):            \n",
    "            anchor.to(device)\n",
    "            pos.to(device)\n",
    "            neg.to(device)\n",
    "            \n",
    "            anchor_emb = encoder.forward(anchor.x_dict, anchor.edge_index_dict, anchor.edge_attr_dict)\n",
    "            pos_emb = encoder.forward(pos.x_dict, pos.edge_index_dict, pos.edge_attr_dict)\n",
    "            neg_emb = encoder.forward(neg.x_dict, neg.edge_index_dict, neg.edge_attr_dict)\n",
    "            \n",
    "            # Retrieve embedding of respective start nodes\n",
    "            anchor_emb = anchor_emb[\"Publication\"][0]\n",
    "            pos_emb = pos_emb[\"Publication\"][0]\n",
    "            neg_emb = neg_emb[\"Publication\"][0]\n",
    "            \n",
    "            pos_dist = F.pairwise_distance(anchor_emb, pos_emb, p=2)\n",
    "            neg_dist = F.pairwise_distance(anchor_emb, neg_emb, p=2)\n",
    "            \n",
    "            score = 1 if pos_dist < neg_dist else 0\n",
    "            accuracy.append(score)\n",
    "    \n",
    "    # Return percentage of correct predictions \n",
    "    return sum(accuracy) / len(accuracy)\n",
    "            "
   ],
   "id": "fbe7895a5630320a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "triplet_loss = TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
    "optimizer = optim.Adam(list(encoder.parameters()), lr=0.01)\n",
    "ds = TripletDataset()\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# To keep track of the best validation performance\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "save_path = \"./data/models/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "    # Training\n",
    "    for train_triplets, val_triplets in ds.iter_generated_triplets():\n",
    "        print(\"Train_triplets: \", train_triplets)\n",
    "        train_loss = train(encoder, train_triplets, optimizer, triplet_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = validate(encoder, val_triplets, triplet_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        plot_loss(train_losses, val_losses, save_file=f\"gat_loss.png\")\n",
    "    \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = encoder.state_dict()\n",
    "            torch.save(best_model_state, os.path.join(save_path, \"gat_encoder.pt\"))\n",
    "            print(\"New best model found and saved.\")\n",
    "    \n",
    "    \n",
    "\n"
   ],
   "id": "30219d0bb507a174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load best model state\n",
    "best_model_state = torch.load(os.path.join(save_path, \"gat_encoder.pt\"))\n",
    "encoder.load_state_dict(best_model_state)\n",
    "ds = TripletDataset(\"./data/train_set\")\n",
    "# Testing\n",
    "accuracy_score = test(encoder, ds)\n",
    "print(f\"Accuracy: {accuracy_score:.4f}\")"
   ],
   "id": "ad365c6fbd80212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "97512a92726b33ac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
