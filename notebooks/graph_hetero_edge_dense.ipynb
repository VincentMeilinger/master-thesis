{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T08:37:53.836547Z",
     "start_time": "2024-11-25T08:37:53.834448Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from src.datasets.who_is_who import WhoIsWhoDataset\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.shared.graph_schema import NodeType, EdgeType\n",
    "from src.shared.graph_sampling import GraphSampling"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "f934f5daf06dbc1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:37:53.881657Z",
     "start_time": "2024-11-25T08:37:53.879482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_iterations = 20000\n",
    "add_true_authors = False\n",
    "link_true_authors = True\n",
    "link_co_authors = True\n",
    "link_title = True\n",
    "link_abstract = True\n",
    "link_venue = True\n",
    "\n",
    "co_author_overlap_threshold = 0.15\n",
    "link_title_threshold = 0.7\n",
    "link_abstract_threshold = 0.7\n",
    "link_venue_threshold = 0.7\n",
    "\n",
    "link_title_k = 15\n",
    "link_abstract_k = 15\n",
    "link_venue_k = 8"
   ],
   "id": "bb1b78124474912c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:38:01.835566Z",
     "start_time": "2024-11-25T08:37:57.058983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "db = DatabaseWrapper(database='dense-graph')\n",
    "db.delete_all_nodes()"
   ],
   "id": "39befe6e82597c35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 09:37:57,059 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-11-25 09:37:57,060 - DatabaseWrapper - INFO - Database ready.\n",
      "2024-11-25 09:37:57,138 - DatabaseWrapper - INFO - Deleted all nodes.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:38:14.816716Z",
     "start_time": "2024-11-25T08:38:05.388624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = WhoIsWhoDataset.parse_data()\n",
    "train_data = WhoIsWhoDataset.parse_train()"
   ],
   "id": "7b4f2bfe1943d12a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:38:19.689708Z",
     "start_time": "2024-11-25T08:38:18.365779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    device='cuda'\n",
    ")\n",
    "print(f\"Model dim: {model.get_sentence_embedding_dimension()}\")"
   ],
   "id": "9a313d7d87172b1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dim: 384\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add publication nodes to the graph database",
   "id": "15768f9232b8a006"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:38:22.803333Z",
     "start_time": "2024-11-25T08:38:22.800710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batch(batch):\n",
    "    if not batch[NodeType.PUBLICATION]:\n",
    "        return\n",
    "    title_embs = model.encode(\n",
    "        [node['title'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    abstract_embs = model.encode(\n",
    "        [node['abstract'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    venue_embs = model.encode(\n",
    "        [node['venue'] for node in batch[NodeType.PUBLICATION]]\n",
    "    )\n",
    "    for i, node in enumerate(batch[NodeType.PUBLICATION]):\n",
    "        node['title_emb'] = title_embs[i]\n",
    "        node['abstract_emb'] = abstract_embs[i]\n",
    "        node['venue_emb'] = venue_embs[i]\n",
    "        # vertically stack the embeddings\n",
    "        node['feature_vec'] = list(title_embs[i]) + list(abstract_embs[i])\n",
    "    db.merge_nodes(NodeType.PUBLICATION, batch[NodeType.PUBLICATION])\n",
    "    batch[NodeType.PUBLICATION] = []"
   ],
   "id": "fb863533ee3db7cb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:41:41.704649Z",
     "start_time": "2024-11-25T08:38:26.438827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_nodes = defaultdict(list)\n",
    "current_iteration = 0\n",
    "\n",
    "with tqdm(total=max_iterations) as pbar:\n",
    "    for author_id, values in train_data.items():\n",
    "        papers = values.get('normal_data', [])\n",
    "        papers.extend(values.get('outliers', []))\n",
    "        \n",
    "        if max_iterations is not None and current_iteration >= max_iterations:\n",
    "            break\n",
    "        current_iteration += len(papers)\n",
    "        \n",
    "        for paper_id in papers:\n",
    "            values = data[paper_id]\n",
    "            paper_node = {\n",
    "                'id': values['id'],\n",
    "                'title': values['title'],\n",
    "                'abstract': values['abstract'],\n",
    "                'year': values['year'],\n",
    "                'venue': values['venue'],\n",
    "            }\n",
    "            batch_nodes[NodeType.PUBLICATION].append(paper_node)\n",
    "            \n",
    "            if len(batch_nodes[NodeType.PUBLICATION]) % 1000 == 0:\n",
    "                process_batch(batch_nodes)\n",
    "                \n",
    "            pbar.update(1)\n",
    "        \n",
    "process_batch(batch_nodes)"
   ],
   "id": "29946cd86c709ff8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c1577918fb84e3c946e246b74c7612b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincie/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:500: UserWarning: Expected a result with a single record, but found multiple.\n",
      "  warn(\"Expected a result with a single record, \"\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add true author data to the nodes",
   "id": "ebf992fa74894e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:44:44.501490Z",
     "start_time": "2024-11-25T08:41:41.803866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reverse_dict(author_dict):\n",
    "    paper_to_author = {}\n",
    "    for author_id, values in author_dict.items():\n",
    "        normal_papers = values.get('normal_data', [])\n",
    "        for paper_id in normal_papers:\n",
    "            paper_to_author[paper_id] = author_id\n",
    "    return paper_to_author\n",
    "\n",
    "def add_true_authors(db: DatabaseWrapper, train_data):\n",
    "    paper_id_to_author = reverse_dict(train_data)\n",
    "\n",
    "    with tqdm(total=db.count_nodes(NodeType.PUBLICATION), desc=\"Merging WhoIsWho train_author.json\") as pbar:\n",
    "        for nodes in db.iter_nodes(NodeType.PUBLICATION, ['id']):\n",
    "            for node in nodes:\n",
    "                true_author_id = paper_id_to_author.get(node['id'], '')\n",
    "                true_author_name = train_data.get(true_author_id, {}).get('name', '')\n",
    "                \n",
    "                db.merge_properties(\n",
    "                    type=NodeType.PUBLICATION, \n",
    "                    node_id=node['id'], \n",
    "                    properties={'true_author_id': true_author_id, 'true_author_name': true_author_name}\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "if add_true_authors:\n",
    "    add_true_authors(db, train_data)"
   ],
   "id": "9b2f2a4cbd1f8ad1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merging WhoIsWho train_author.json:   0%|          | 0/20034 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "291630c392d442f8ab7e05ea9a18592b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Link publication nodes if they share the same true author",
   "id": "c55bcbf69531cd7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:50:33.879134Z",
     "start_time": "2024-11-25T08:44:44.596424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def get_sample_size(num_papers):\n",
    "    random_k = 3 + random.random() * 0.2\n",
    "    return int(num_papers**0.5 * random_k)\n",
    "\n",
    "def link_true_authors(db: DatabaseWrapper, train_data):\n",
    "    node_type = NodeType.PUBLICATION\n",
    "    edges_to_merge = []\n",
    "    current_iteration = 0\n",
    "    \n",
    "    with tqdm(total=max_iterations, desc=\"Merging true-author edges\") as pbar:\n",
    "        for author_id, values in train_data.items():\n",
    "            papers = values.get('normal_data', [])\n",
    "            print(f\"Number of papers: {len(papers)}\")\n",
    "            \n",
    "            pbar.update(len(papers) + len(values.get('outliers', [])))\n",
    "            if max_iterations is not None and current_iteration >= max_iterations:\n",
    "                break \n",
    "            current_iteration += len(papers) + len(values.get('outliers', []))\n",
    "            \n",
    "            for i in range(len(papers)):\n",
    "                for j in range(len(papers)):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    edges_to_merge.append([papers[i], papers[j]])\n",
    "            \n",
    "            print(f\"Number of edges to merge: {len(edges_to_merge)}\")\n",
    "            # Randomly sample 10-40% of the edges_to_merge list\n",
    "            sample_size = get_sample_size(len(edges_to_merge))\n",
    "            print(f\"Sample size: {sample_size}\")\n",
    "            edges_to_merge = random.sample(edges_to_merge, sample_size)\n",
    "            print(f\"Sampled number of edges to merge: {len(edges_to_merge)}\")\n",
    "             \n",
    "            if len(edges_to_merge) > 1000:\n",
    "                db.merge_edges(start_label=node_type, end_label=node_type, edge_type=EdgeType.SAME_AUTHOR, edges=edges_to_merge)\n",
    "                edges_to_merge.clear()\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        if edges_to_merge:\n",
    "            db.merge_edges(start_label=node_type, end_label=node_type, edge_type=EdgeType.SAME_AUTHOR, edges=edges_to_merge)\n",
    "            edges_to_merge.clear()\n",
    "            \n",
    "if link_true_authors:\n",
    "    db.delete_edges(EdgeType.SAME_AUTHOR)\n",
    "    link_true_authors(db, train_data)"
   ],
   "id": "5a54f0712c36cbe6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merging true-author edges:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17f163b6d33d4d7380999ae93263dbcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 565\n",
      "Number of edges to merge: 318660\n",
      "Sample size: 1731\n",
      "Sampled number of edges to merge: 1731\n",
      "Number of papers: 40\n",
      "Number of edges to merge: 1560\n",
      "Sample size: 119\n",
      "Sampled number of edges to merge: 119\n",
      "Number of papers: 74\n",
      "Number of edges to merge: 5521\n",
      "Sample size: 233\n",
      "Sampled number of edges to merge: 233\n",
      "Number of papers: 53\n",
      "Number of edges to merge: 2989\n",
      "Sample size: 167\n",
      "Sampled number of edges to merge: 167\n",
      "Number of papers: 36\n",
      "Number of edges to merge: 1427\n",
      "Sample size: 116\n",
      "Sampled number of edges to merge: 116\n",
      "Number of papers: 34\n",
      "Number of edges to merge: 1238\n",
      "Sample size: 105\n",
      "Sampled number of edges to merge: 105\n",
      "Number of papers: 149\n",
      "Number of edges to merge: 22157\n",
      "Sample size: 457\n",
      "Sampled number of edges to merge: 457\n",
      "Number of papers: 145\n",
      "Number of edges to merge: 21337\n",
      "Sample size: 439\n",
      "Sampled number of edges to merge: 439\n",
      "Number of papers: 36\n",
      "Number of edges to merge: 1699\n",
      "Sample size: 131\n",
      "Sampled number of edges to merge: 131\n",
      "Number of papers: 172\n",
      "Number of edges to merge: 29543\n",
      "Sample size: 521\n",
      "Sampled number of edges to merge: 521\n",
      "Number of papers: 441\n",
      "Number of edges to merge: 194561\n",
      "Sample size: 1375\n",
      "Sampled number of edges to merge: 1375\n",
      "Number of papers: 266\n",
      "Number of edges to merge: 70490\n",
      "Sample size: 833\n",
      "Sampled number of edges to merge: 833\n",
      "Number of papers: 85\n",
      "Number of edges to merge: 7973\n",
      "Sample size: 276\n",
      "Sampled number of edges to merge: 276\n",
      "Number of papers: 66\n",
      "Number of edges to merge: 4566\n",
      "Sample size: 213\n",
      "Sampled number of edges to merge: 213\n",
      "Number of papers: 462\n",
      "Number of edges to merge: 213195\n",
      "Sample size: 1469\n",
      "Sampled number of edges to merge: 1469\n",
      "Number of papers: 91\n",
      "Number of edges to merge: 8190\n",
      "Sample size: 274\n",
      "Sampled number of edges to merge: 274\n",
      "Number of papers: 412\n",
      "Number of edges to merge: 169606\n",
      "Sample size: 1244\n",
      "Sampled number of edges to merge: 1244\n",
      "Number of papers: 24\n",
      "Number of edges to merge: 552\n",
      "Sample size: 74\n",
      "Sampled number of edges to merge: 74\n",
      "Number of papers: 112\n",
      "Number of edges to merge: 12506\n",
      "Sample size: 349\n",
      "Sampled number of edges to merge: 349\n",
      "Number of papers: 233\n",
      "Number of edges to merge: 54405\n",
      "Sample size: 732\n",
      "Sampled number of edges to merge: 732\n",
      "Number of papers: 74\n",
      "Number of edges to merge: 6134\n",
      "Sample size: 248\n",
      "Sampled number of edges to merge: 248\n",
      "Number of papers: 372\n",
      "Number of edges to merge: 138260\n",
      "Sample size: 1155\n",
      "Sampled number of edges to merge: 1155\n",
      "Number of papers: 176\n",
      "Number of edges to merge: 30800\n",
      "Sample size: 542\n",
      "Sampled number of edges to merge: 542\n",
      "Number of papers: 49\n",
      "Number of edges to merge: 2894\n",
      "Sample size: 162\n",
      "Sampled number of edges to merge: 162\n",
      "Number of papers: 56\n",
      "Number of edges to merge: 3242\n",
      "Sample size: 178\n",
      "Sampled number of edges to merge: 178\n",
      "Number of papers: 121\n",
      "Number of edges to merge: 14698\n",
      "Sample size: 377\n",
      "Sampled number of edges to merge: 377\n",
      "Number of papers: 922\n",
      "Number of edges to merge: 849539\n",
      "Sample size: 2934\n",
      "Sampled number of edges to merge: 2934\n",
      "Number of papers: 91\n",
      "Number of edges to merge: 8190\n",
      "Sample size: 280\n",
      "Sampled number of edges to merge: 280\n",
      "Number of papers: 216\n",
      "Number of edges to merge: 46720\n",
      "Sample size: 673\n",
      "Sampled number of edges to merge: 673\n",
      "Number of papers: 153\n",
      "Number of edges to merge: 23929\n",
      "Sample size: 488\n",
      "Sampled number of edges to merge: 488\n",
      "Number of papers: 74\n",
      "Number of edges to merge: 5890\n",
      "Sample size: 233\n",
      "Sampled number of edges to merge: 233\n",
      "Number of papers: 14\n",
      "Number of edges to merge: 415\n",
      "Sample size: 61\n",
      "Sampled number of edges to merge: 61\n",
      "Number of papers: 111\n",
      "Number of edges to merge: 12271\n",
      "Sample size: 336\n",
      "Sampled number of edges to merge: 336\n",
      "Number of papers: 310\n",
      "Number of edges to merge: 96126\n",
      "Sample size: 952\n",
      "Sampled number of edges to merge: 952\n",
      "Number of papers: 107\n",
      "Number of edges to merge: 12294\n",
      "Sample size: 344\n",
      "Sampled number of edges to merge: 344\n",
      "Number of papers: 392\n",
      "Number of edges to merge: 153616\n",
      "Sample size: 1247\n",
      "Sampled number of edges to merge: 1247\n",
      "Number of papers: 372\n",
      "Number of edges to merge: 138012\n",
      "Sample size: 1169\n",
      "Sampled number of edges to merge: 1169\n",
      "Number of papers: 106\n",
      "Number of edges to merge: 11130\n",
      "Sample size: 317\n",
      "Sampled number of edges to merge: 317\n",
      "Number of papers: 87\n",
      "Number of edges to merge: 7799\n",
      "Sample size: 277\n",
      "Sampled number of edges to merge: 277\n",
      "Number of papers: 36\n",
      "Number of edges to merge: 1537\n",
      "Sample size: 123\n",
      "Sampled number of edges to merge: 123\n",
      "Number of papers: 49\n",
      "Number of edges to merge: 2475\n",
      "Sample size: 155\n",
      "Sampled number of edges to merge: 155\n",
      "Number of papers: 312\n",
      "Number of edges to merge: 97187\n",
      "Sample size: 996\n",
      "Sampled number of edges to merge: 996\n",
      "Number of papers: 65\n",
      "Number of edges to merge: 5156\n",
      "Sample size: 226\n",
      "Sampled number of edges to merge: 226\n",
      "Number of papers: 134\n",
      "Number of edges to merge: 18048\n",
      "Sample size: 408\n",
      "Sampled number of edges to merge: 408\n",
      "Number of papers: 160\n",
      "Number of edges to merge: 25848\n",
      "Sample size: 513\n",
      "Sampled number of edges to merge: 513\n",
      "Number of papers: 115\n",
      "Number of edges to merge: 13623\n",
      "Sample size: 373\n",
      "Sampled number of edges to merge: 373\n",
      "Number of papers: 311\n",
      "Number of edges to merge: 96783\n",
      "Sample size: 955\n",
      "Sampled number of edges to merge: 955\n",
      "Number of papers: 93\n",
      "Number of edges to merge: 9511\n",
      "Sample size: 295\n",
      "Sampled number of edges to merge: 295\n",
      "Number of papers: 152\n",
      "Number of edges to merge: 23247\n",
      "Sample size: 459\n",
      "Sampled number of edges to merge: 459\n",
      "Number of papers: 161\n",
      "Number of edges to merge: 26219\n",
      "Sample size: 488\n",
      "Sampled number of edges to merge: 488\n",
      "Number of papers: 36\n",
      "Number of edges to merge: 1748\n",
      "Sample size: 126\n",
      "Sampled number of edges to merge: 126\n",
      "Number of papers: 200\n",
      "Number of edges to merge: 39926\n",
      "Sample size: 613\n",
      "Sampled number of edges to merge: 613\n",
      "Number of papers: 1731\n",
      "Number of edges to merge: 2995243\n",
      "Sample size: 5496\n",
      "Sampled number of edges to merge: 5496\n",
      "Number of papers: 630\n",
      "Number of edges to merge: 396270\n",
      "Sample size: 1941\n",
      "Sampled number of edges to merge: 1941\n",
      "Number of papers: 322\n",
      "Number of edges to merge: 103362\n",
      "Sample size: 974\n",
      "Sampled number of edges to merge: 974\n",
      "Number of papers: 379\n",
      "Number of edges to merge: 144236\n",
      "Sample size: 1213\n",
      "Sampled number of edges to merge: 1213\n",
      "Number of papers: 535\n",
      "Number of edges to merge: 285690\n",
      "Sample size: 1667\n",
      "Sampled number of edges to merge: 1667\n",
      "Number of papers: 21\n",
      "Number of edges to merge: 420\n",
      "Sample size: 61\n",
      "Sampled number of edges to merge: 61\n",
      "Number of papers: 119\n",
      "Number of edges to merge: 14103\n",
      "Sample size: 358\n",
      "Sampled number of edges to merge: 358\n",
      "Number of papers: 62\n",
      "Number of edges to merge: 4140\n",
      "Sample size: 199\n",
      "Sampled number of edges to merge: 199\n",
      "Number of papers: 20\n",
      "Number of edges to merge: 579\n",
      "Sample size: 75\n",
      "Sampled number of edges to merge: 75\n",
      "Number of papers: 76\n",
      "Number of edges to merge: 5775\n",
      "Sample size: 237\n",
      "Sampled number of edges to merge: 237\n",
      "Number of papers: 63\n",
      "Number of edges to merge: 4143\n",
      "Sample size: 201\n",
      "Sampled number of edges to merge: 201\n",
      "Number of papers: 68\n",
      "Number of edges to merge: 4757\n",
      "Sample size: 211\n",
      "Sampled number of edges to merge: 211\n",
      "Number of papers: 130\n",
      "Number of edges to merge: 16981\n",
      "Sample size: 403\n",
      "Sampled number of edges to merge: 403\n",
      "Number of papers: 506\n",
      "Number of edges to merge: 255933\n",
      "Sample size: 1542\n",
      "Sampled number of edges to merge: 1542\n",
      "Number of papers: 96\n",
      "Number of edges to merge: 9120\n",
      "Sample size: 294\n",
      "Sampled number of edges to merge: 294\n",
      "Number of papers: 309\n",
      "Number of edges to merge: 95466\n",
      "Sample size: 976\n",
      "Sampled number of edges to merge: 976\n",
      "Number of papers: 50\n",
      "Number of edges to merge: 3426\n",
      "Sample size: 181\n",
      "Sampled number of edges to merge: 181\n",
      "Number of papers: 43\n",
      "Number of edges to merge: 1987\n",
      "Sample size: 142\n",
      "Sampled number of edges to merge: 142\n",
      "Number of papers: 365\n",
      "Number of edges to merge: 133002\n",
      "Sample size: 1162\n",
      "Sampled number of edges to merge: 1162\n",
      "Number of papers: 337\n",
      "Number of edges to merge: 113232\n",
      "Sample size: 1020\n",
      "Sampled number of edges to merge: 1020\n",
      "Number of papers: 463\n",
      "Number of edges to merge: 213906\n",
      "Sample size: 1420\n",
      "Sampled number of edges to merge: 1420\n",
      "Number of papers: 37\n",
      "Number of edges to merge: 1332\n",
      "Sample size: 111\n",
      "Sampled number of edges to merge: 111\n",
      "Number of papers: 41\n",
      "Number of edges to merge: 1751\n",
      "Sample size: 128\n",
      "Sampled number of edges to merge: 128\n",
      "Number of papers: 72\n",
      "Number of edges to merge: 5240\n",
      "Sample size: 225\n",
      "Sampled number of edges to merge: 225\n",
      "Number of papers: 133\n",
      "Number of edges to merge: 17781\n",
      "Sample size: 413\n",
      "Sampled number of edges to merge: 413\n",
      "Number of papers: 636\n",
      "Number of edges to merge: 404273\n",
      "Sample size: 1917\n",
      "Sampled number of edges to merge: 1917\n",
      "Number of papers: 86\n",
      "Number of edges to merge: 7310\n",
      "Sample size: 272\n",
      "Sampled number of edges to merge: 272\n",
      "Number of papers: 76\n",
      "Number of edges to merge: 5972\n",
      "Sample size: 232\n",
      "Sampled number of edges to merge: 232\n",
      "Number of papers: 70\n",
      "Number of edges to merge: 5062\n",
      "Sample size: 221\n",
      "Sampled number of edges to merge: 221\n",
      "Number of papers: 127\n",
      "Number of edges to merge: 16223\n",
      "Sample size: 403\n",
      "Sampled number of edges to merge: 403\n",
      "Number of papers: 45\n",
      "Number of edges to merge: 2383\n",
      "Sample size: 153\n",
      "Sampled number of edges to merge: 153\n",
      "Number of papers: 164\n",
      "Number of edges to merge: 26885\n",
      "Sample size: 504\n",
      "Sampled number of edges to merge: 504\n",
      "Number of papers: 38\n",
      "Number of edges to merge: 1910\n",
      "Sample size: 132\n",
      "Sampled number of edges to merge: 132\n",
      "Number of papers: 81\n",
      "Number of edges to merge: 6612\n",
      "Sample size: 253\n",
      "Sampled number of edges to merge: 253\n",
      "Number of papers: 270\n",
      "Number of edges to merge: 72883\n",
      "Sample size: 813\n",
      "Sampled number of edges to merge: 813\n",
      "Number of papers: 166\n",
      "Number of edges to merge: 28203\n",
      "Sample size: 508\n",
      "Sampled number of edges to merge: 508\n",
      "Number of papers: 123\n",
      "Number of edges to merge: 15514\n",
      "Sample size: 380\n",
      "Sampled number of edges to merge: 380\n",
      "Number of papers: 66\n",
      "Number of edges to merge: 4670\n",
      "Sample size: 213\n",
      "Sampled number of edges to merge: 213\n",
      "Number of papers: 36\n",
      "Number of edges to merge: 1473\n",
      "Sample size: 117\n",
      "Sampled number of edges to merge: 117\n",
      "Number of papers: 210\n",
      "Number of edges to merge: 44007\n",
      "Sample size: 642\n",
      "Sampled number of edges to merge: 642\n",
      "Number of papers: 46\n",
      "Number of edges to merge: 2712\n",
      "Sample size: 164\n",
      "Sampled number of edges to merge: 164\n",
      "Number of papers: 74\n",
      "Number of edges to merge: 5566\n",
      "Sample size: 236\n",
      "Sampled number of edges to merge: 236\n",
      "Number of papers: 29\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Link nodes based on co-author relationships",
   "id": "f289de4073e4964f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:50:33.963778Z",
     "start_time": "2024-11-25T08:50:33.959162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_co_author_network(db: DatabaseWrapper, node_type: NodeType):\n",
    "    num_nodes = db.count_nodes(node_type)\n",
    "    attrs = ['id']\n",
    "    co_author_map = defaultdict(list)\n",
    "    co_author_overlap = defaultdict(int)\n",
    "        \n",
    "    print(f\"Linking {node_type.value} nodes based on co-authorship ...\")\n",
    "    with tqdm(total=num_nodes, desc=f\"Progress {node_type.value} co-authorship\") as pbar:\n",
    "        for nodes in db.iter_nodes(node_type, attrs):\n",
    "            for node in nodes:\n",
    "                co_authors = [author[\"name\"] for author in data[node['id']]['authors']]\n",
    "                for author in co_authors:\n",
    "                    name = author.strip()\n",
    "                    name = re.sub(r'[^A-Za-z\\s]', '', name)\n",
    "                    name_parts = name.split()\n",
    "                    if len(name_parts) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    surname = name_parts[-1]\n",
    "                    given_name_initial = (name_parts[0] if len(name_parts) > 1 else ' ')[0]\n",
    "                    abbrev = f\"{surname} {given_name_initial}\"\n",
    "                    co_author_map[abbrev].append(node['id'])\n",
    "                pbar.update(1)\n",
    "    \n",
    "    for k, v in co_author_map.items():\n",
    "        for i in range(len(v)):\n",
    "            for j in range(i + 1, len(v)):\n",
    "                co_author_overlap[(v[i], v[j])] += 1\n",
    "                \n",
    "    for k, v in co_author_overlap.items():\n",
    "        total_num_authors = data[k[0]][\"authors\"] + data[k[1]][\"authors\"]\n",
    "        co_author_overlap[k] = v / len(total_num_authors)\n",
    "    \n",
    "    print(f\"Max. co-authors: {max(len(v) for v in co_author_map.values())}\")\n",
    "    print(f\"Max. co-author overlap: {max(co_author_overlap.values())}\")\n",
    "    \n",
    "    print(\"Number of co-author pairs:\", len(co_author_overlap))\n",
    "    print(\"Number of co-author pairs with overlap > 0.25:\", len([v for v in co_author_overlap.values() if v > co_author_overlap_threshold]))\n",
    "    \n",
    "    print(\"Merging edges ...\")\n",
    "    edges_to_merge = [[k[0], k[1], {'sim': v}] for k, v in co_author_overlap.items() if v > co_author_overlap_threshold]\n",
    "    with tqdm(total=len(edges_to_merge), desc=\"Merging co-author edges\") as pbar:\n",
    "        for i in range(0, len(edges_to_merge), 1000):\n",
    "            db.merge_edges_with_properties(start_label=node_type, end_label=node_type, edge_type=EdgeType.SIM_AUTHOR, edges=edges_to_merge[i:i+1000])\n",
    "            pbar.update(1000)"
   ],
   "id": "a7757bd1c39b85df",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:10:00.662833Z",
     "start_time": "2024-11-25T08:50:34.035967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if link_co_authors:\n",
    "    link_co_author_network(db, NodeType.PUBLICATION)"
   ],
   "id": "e663cedfc1fbdc51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking Publication nodes based on co-authorship ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication co-authorship:   0%|          | 0/20034 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "885ef355a83d488ba2567f92b1a645e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. co-authors: 1796\n",
      "Max. co-author overlap: 1.2181571815718157\n",
      "Number of co-author pairs: 6293688\n",
      "Number of co-author pairs with overlap > 0.25: 776093\n",
      "Merging edges ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Merging co-author edges:   0%|          | 0/776093 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23aba07ab6ef4844aed19fd3d3ac634a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Link nodes based on cosine similarity of their embeddings",
   "id": "4a98eaadf5534888"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T11:44:01.180999Z",
     "start_time": "2024-11-25T11:44:01.177060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_node_attr_cosine(db: DatabaseWrapper, node_type: NodeType, vec_attr: str, edge_type: EdgeType, threshold: float = 0.7, k=8, filter_empty_original_attr: str = None):\n",
    "    num_nodes = db.count_nodes(node_type)\n",
    "    edges = []\n",
    "    attrs = ['id', vec_attr]\n",
    "    if filter_empty_original_attr:\n",
    "        attrs.append(filter_empty_original_attr)\n",
    "        \n",
    "    print(f\"Linking {node_type.value} nodes based on {vec_attr} attribute ...\")\n",
    "    with tqdm(total=num_nodes, desc=f\"Progress {node_type.value} {vec_attr}\") as pbar:\n",
    "        for nodes in db.iter_nodes(node_type, attrs):\n",
    "            for node in nodes:\n",
    "                if filter_empty_original_attr and not node[filter_empty_original_attr]:\n",
    "                    pbar.update(1)\n",
    "                    print(f\"Skipping node {node['id']} because {filter_empty_original_attr} is empty\")\n",
    "                    continue\n",
    "                similar_nodes = db.get_similar_nodes_vec(\n",
    "                    node_type,\n",
    "                    vec_attr,\n",
    "                    node[vec_attr],\n",
    "                    threshold,\n",
    "                    k\n",
    "                )\n",
    "                for ix, row in similar_nodes.iterrows():\n",
    "                    if row['id'] == node['id']:\n",
    "                        continue\n",
    "                    edges.append([node['id'], row['id'], {\"sim\": row['sim']}])\n",
    "                    #db.merge_edge(node_type, node['id'], node_type, row['id'], edge_type, {\"sim\": row['sim']})\n",
    "                if len(edges) > 1000:\n",
    "                    print(f\"Merging {len(edges)} edges ...\")\n",
    "                    #db.merge_edges(start_label=node_type, end_label=node_type, edge_type=edge_type, edges=edges)\n",
    "                    db.merge_edges_with_properties(start_label=node_type, end_label=node_type, edge_type=edge_type, edges=edges)\n",
    "                    edges.clear()\n",
    "                    \n",
    "                pbar.update(1)\n",
    "    if edges:\n",
    "        db.merge_edges(start_label=node_type, end_label=node_type, edge_type=edge_type, edges=edges)"
   ],
   "id": "df5874196d002a6",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T16:17:38.089481Z",
     "start_time": "2024-11-25T11:44:06.811971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dim = model.get_sentence_embedding_dimension()\n",
    "\n",
    "# Create vector index and link nodes based on cosine similarity\n",
    "if link_title:\n",
    "    db.create_vector_index('title_index', NodeType.PUBLICATION, 'title_emb', model_dim)\n",
    "    link_node_attr_cosine(db, NodeType.PUBLICATION, 'title_emb', EdgeType.SIM_TITLE, threshold=link_title_threshold, k=link_title_k)\n",
    "    \n",
    "if link_abstract:\n",
    "    db.create_vector_index('abstract_index', NodeType.PUBLICATION, 'abstract_emb', model_dim)\n",
    "    link_node_attr_cosine(db, NodeType.PUBLICATION, 'abstract_emb', EdgeType.SIM_ABSTRACT, threshold=link_abstract_threshold, k=link_abstract_k)\n",
    "    \n",
    "if link_venue:\n",
    "    db.create_vector_index('venue_index', NodeType.PUBLICATION, 'venue_emb', model_dim)\n",
    "    link_node_attr_cosine(db, NodeType.PUBLICATION, 'venue_emb', EdgeType.SIM_VENUE, threshold=link_venue_threshold, k=link_venue_k)"
   ],
   "id": "71010a3d4cd7ff1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking Publication nodes based on title_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication title_emb:   0%|          | 0/20034 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9754df257b19415e873aaafdd83528a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1015 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Linking Publication nodes based on abstract_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication abstract_emb:   0%|          | 0/20034 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2c106b6928246218e012a83d112d7e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1012 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1011 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1015 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1015 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1011 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1010 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1015 edges ...\n",
      "Merging 1011 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1012 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1009 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1014 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1013 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1010 edges ...\n",
      "Linking Publication nodes based on venue_emb attribute ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Progress Publication venue_emb:   0%|          | 0/20034 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5834b2eb44994fdfbf1cd1c75c71bd3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 1005 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1006 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1002 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1008 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1003 edges ...\n",
      "Merging 1001 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1004 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1007 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1005 edges ...\n",
      "Merging 1004 edges ...\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T16:17:38.974459Z",
     "start_time": "2024-11-25T16:17:38.102228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove edges if according attribute is empty\n",
    "if link_title:\n",
    "    db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_TITLE, 'title')\n",
    "    \n",
    "if link_abstract:\n",
    "    db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_ABSTRACT, 'abstract')\n",
    "    \n",
    "if link_venue:\n",
    "    db.delete_edges_for_empty_attr(NodeType.PUBLICATION, EdgeType.SIM_VENUE, 'venue')"
   ],
   "id": "837c860f5efe8056",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Number of publication nodes:\", db.count_nodes(NodeType.PUBLICATION))",
   "id": "f02c30d1f448354f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publication nodes: 20034\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c65655086c89b42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
