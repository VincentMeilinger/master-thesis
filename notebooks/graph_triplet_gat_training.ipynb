{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T15:23:57.709504Z",
     "start_time": "2024-08-27T15:23:57.705435Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from torch_geometric.data import HeteroData\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.datasets.who_is_who import WhoIsWhoDataset\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot, edge_pyg_key_vals\n",
    "from src.model.loss.triplet_loss import TripletLoss\n",
    "from src.shared import config\n",
    "\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:23:57.739739Z",
     "start_time": "2024-08-27T15:23:57.723761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, HeteroConv\n",
    "from torch_geometric.nn import Linear\n",
    "\n",
    "\n",
    "class TestGATv2Encoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            out_channels,\n",
    "            edge_feature_dim,\n",
    "            edge_types,\n",
    "            node_types,\n",
    "            heads=5,\n",
    "            concat=True,\n",
    "            negative_slope=0.2,\n",
    "            dropout=0.0,\n",
    "            add_self_loops=True\n",
    "    ):\n",
    "        super(TestGATv2Encoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = HeteroConv({\n",
    "            edge_type: GATv2Conv(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                heads=heads,\n",
    "                concat=concat,\n",
    "                negative_slope=negative_slope,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=add_self_loops,\n",
    "                edge_dim=edge_feature_dim\n",
    "            )\n",
    "            for edge_type in edge_types\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv_2 = HeteroConv({\n",
    "            edge_type: GATv2Conv(\n",
    "                in_channels=heads * hidden_channels if concat else hidden_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                heads=heads,\n",
    "                concat=concat,\n",
    "                negative_slope=negative_slope,\n",
    "                dropout=dropout,\n",
    "                add_self_loops=add_self_loops,\n",
    "                edge_dim=edge_feature_dim\n",
    "            )\n",
    "            for edge_type in edge_types\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.lin_out = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_out[node_type] = torch.nn.Sequential(\n",
    "                Linear(heads * hidden_channels, hidden_channels),\n",
    "                torch.nn.Dropout(dropout),\n",
    "                Linear(hidden_channels, out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_feature_dict):\n",
    "        \"\"\"\n",
    "        :param x_dict: dict of torch.Tensor\n",
    "            Node feature vectors for each node type.\n",
    "        :param edge_index_dict: dict of torch.Tensor\n",
    "            Edge indices for each edge type.\n",
    "        :param edge_feature_dict: dict of torch.Tensor\n",
    "            Edge attribute vectors for each edge type.\n",
    "        \"\"\"\n",
    "        \n",
    "        x_dict = self.conv_1(x_dict, edge_index_dict, edge_feature_dict)\n",
    "        for node_type in x_dict.keys():\n",
    "            x_dict[node_type] = F.dropout(F.relu(x_dict[node_type]), p=0.5, training=self.training)\n",
    "\n",
    "        x_dict = self.conv_2(x_dict, edge_index_dict, edge_feature_dict)\n",
    "        for node_type in x_dict.keys():\n",
    "            x_dict[node_type] = F.dropout(F.relu(x_dict[node_type]), p=0.5, training=self.training)\n",
    "\n",
    "        out_dict = {}\n",
    "        for node_type in x_dict.keys():\n",
    "            out_dict[node_type] = self.lin_out[node_type](x_dict[node_type])\n",
    "\n",
    "        return out_dict"
   ],
   "id": "8d8f242984835d71",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:23:57.808886Z",
     "start_time": "2024-08-27T15:23:57.771690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_feature_dim = 32\n",
    "edge_feature_dim = EdgeType.SIM_TITLE.one_hot().shape[0]\n",
    "gat_embedding_dim = 32\n",
    "\n",
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION,\n",
    "    NodeType.AUTHOR,\n",
    "    NodeType.CO_AUTHOR\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE,\n",
    "    EdgeType.VENUE_PUB,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    EdgeType.PUB_AUTHOR,\n",
    "    EdgeType.AUTHOR_PUB,\n",
    "    EdgeType.AUTHOR_ORG,\n",
    "    EdgeType.ORG_AUTHOR,\n",
    "    EdgeType.PUB_ORG,\n",
    "    EdgeType.ORG_PUB,\n",
    "]\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(device)\n",
    "\n",
    "encoder = TestGATv2Encoder(\n",
    "    in_channels=node_feature_dim,\n",
    "    hidden_channels=32,\n",
    "    out_channels=gat_embedding_dim,\n",
    "    edge_feature_dim=edge_feature_dim,\n",
    "    edge_types=[edge_pyg_key_vals[edge_type] for edge_type in included_edges],\n",
    "    node_types=[node_type.value for node_type in included_nodes],\n",
    "    add_self_loops=False\n",
    ")\n",
    "encoder.to(device)"
   ],
   "id": "ab76e036f95625a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestGATv2Encoder(\n",
       "  (conv_1): HeteroConv(num_relations=8)\n",
       "  (conv_2): HeteroConv(num_relations=8)\n",
       "  (lin_out): ModuleDict(\n",
       "    (Publication): Sequential(\n",
       "      (0): Linear(160, 32, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(32, 32, bias=True)\n",
       "    )\n",
       "    (Venue): Sequential(\n",
       "      (0): Linear(160, 32, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(32, 32, bias=True)\n",
       "    )\n",
       "    (Organization): Sequential(\n",
       "      (0): Linear(160, 32, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(32, 32, bias=True)\n",
       "    )\n",
       "    (Author): Sequential(\n",
       "      (0): Linear(160, 32, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(32, 32, bias=True)\n",
       "    )\n",
       "    (CoAuthor): Sequential(\n",
       "      (0): Linear(160, 32, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Linear(32, 32, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:23:57.822532Z",
     "start_time": "2024-08-27T15:23:57.820247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TripletDataset:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.batch_files = os.listdir(dataset_path)\n",
    "        \n",
    "    def iter_triplets(self):\n",
    "        for batch_file in self.batch_files:\n",
    "            file_path = os.path.join(self.dataset_path, batch_file)\n",
    "            batch = torch.load(file_path)\n",
    "            for triplet in batch:\n",
    "                yield triplet\n",
    "                \n",
    "    def __len__(self, batch_size):\n",
    "        return len(self.batch_files) * batch_size\n",
    "        "
   ],
   "id": "5fed188e49fbd8ef",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T15:23:57.868442Z",
     "start_time": "2024-08-27T15:23:57.864229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.modules.loss import TripletMarginLoss\n",
    "\n",
    "def train_gat(encoder, ds: TripletDataset, epochs=1000, lr=0.01):\n",
    "    # Define the optimizer for the gat model\n",
    "    optimizer = optim.SGD(list(encoder.parameters()), lr=lr)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for triplet in ds.iter_triplets():\n",
    "            anchor, pos, neg = triplet['anchor'], triplet['pos'], triplet['neg']\n",
    "            \n",
    "            anchor_data = anchor['data']\n",
    "            pos_data = pos['data']\n",
    "            neg_data = neg['data']\n",
    "            \n",
    "            anchor_id_map = anchor['node_id_map']\n",
    "            pos_id_map = pos['node_id_map']\n",
    "            neg_id_map = neg['node_id_map']\n",
    "            \n",
    "            anchor_data.to(device)\n",
    "            pos_data.to(device)\n",
    "            neg_data.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the encoder\n",
    "            #print(f\"Anchor node: {anchor['pub_node_id']}\")\n",
    "            #print(f\"Node features: {anchor_data.x_dict}\")\n",
    "            #print(f\"Edge index: {anchor_data.edge_index_dict}\")\n",
    "            \n",
    "            anchor_emb = encoder.forward(anchor_data.x_dict, anchor_data.edge_index_dict, anchor_data.edge_attr_dict)\n",
    "            pos_emb = encoder.forward(pos_data.x_dict, pos_data.edge_index_dict, pos_data.edge_attr_dict)\n",
    "            neg_emb = encoder.forward(neg_data.x_dict, neg_data.edge_index_dict, neg_data.edge_attr_dict)\n",
    "            \n",
    "            # Retrieve embedding of respective start nodes\n",
    "            anchor_emb = anchor_emb[\"Publication\"][anchor_id_map[anchor[\"pub_node_id\"]]]\n",
    "            pos_emb = pos_emb[\"Publication\"][pos_id_map[pos[\"pub_node_id\"]]]\n",
    "            neg_emb = neg_emb[\"Publication\"][neg_id_map[neg[\"pub_node_id\"]]]\n",
    "            #print(anchor_emb.shape, pos_emb.shape, neg_emb.shape)\n",
    "            \n",
    "            # loss = triplet_loss.forward(anchor_emb, pos_emb, neg_emb)\n",
    "            loss = criterion(anchor_emb, pos_emb, neg_emb)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / ds.__len__(10)}')"
   ],
   "id": "2e4940736d78156c",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-27T15:23:57.911658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = TripletDataset(\"./data/triplet_dataset\")\n",
    "train_gat(encoder, ds, epochs=1000, lr=0.01)"
   ],
   "id": "94e69b7f6005b121",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.1363968921013368\n",
      "Epoch 10, Loss: 0.8635011682143579\n",
      "Epoch 20, Loss: 0.7420051929278252\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30219d0bb507a174"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
