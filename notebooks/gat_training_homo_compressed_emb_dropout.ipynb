{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T12:04:03.692020Z",
     "start_time": "2024-11-06T12:04:03.689039Z"
    }
   },
   "source": [
    "from notebooks.util_homogeneous import HomogeneousGraphTripletDataset\n",
    "from util_homogeneous import *\n",
    "from util import plot_loss, save_training_results\n",
    "from training_homogeneous import *\n",
    "from gat_models import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn.modules.loss import TripletMarginLoss\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.shared.graph_schema import *\n",
    "from src.shared.graph_sampling import GraphSampling\n",
    "\n",
    "random.seed(40)\n",
    "np.random.seed(40)\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed_all(40)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configurations",
   "id": "ee4fa502d7e51e50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:04:03.736678Z",
     "start_time": "2024-11-06T12:04:03.733637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Graph sampling configurations\n",
    "node_spec = NodeType.PUBLICATION\n",
    "\n",
    "edge_spec = EdgeType.SIM_TITLE\n",
    "\n",
    "node_properties = [\n",
    "    'id',\n",
    "    'feature_vec',\n",
    "]\n",
    "\n",
    "database = 'homogeneous-graph-compressed-emb'\n",
    "gs = GraphSampling(\n",
    "    node_spec=[node_spec],\n",
    "    edge_spec=[edge_spec],\n",
    "    node_properties=node_properties,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# Model configurations\n",
    "\n",
    "config = {\n",
    "    'experiment': 'GATv2 encoder (with linear layer + dropout) trained on homogeneous graph (publication nodes with title and abstract, co-author edges) using Triplet Loss and dimension reduced embeddings',\n",
    "    'max_hops': 3,\n",
    "    'model_node_feature': 'feature_vec',  # Node feature to use for GAT encoder\n",
    "    'hidden_channels': 32,\n",
    "    'out_channels': 16,\n",
    "    'num_heads': 8,\n",
    "    'margin': 1.0,\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "model_class = HomoGATEncoderLinearDropout\n",
    "loss_fn = TripletMarginLoss(margin=config['margin'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TODO: Adjust result folder name!\n",
    "result_folder_name = 'homogeneous (title) compressed_emb linear_layer dropout'\n",
    "result_folder_path = f'./data/results/{result_folder_name}'\n",
    "if not os.path.exists(result_folder_path):\n",
    "    os.mkdir(result_folder_path)"
   ],
   "id": "91b04efb689d61f4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:04:03.807343Z",
     "start_time": "2024-11-06T12:04:03.779515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DatabaseWrapper(database=database)\n",
    "data_harvester = TripletDataHarvester(db=db, gs=gs, edge_spec=edge_spec, config=config)\n",
    "\n",
    "\n",
    "# Split the pairs into train and test\n",
    "\n",
    "train_size = int(0.85 * len(data_harvester.triplets))\n",
    "test_size = int(0.1 * len(data_harvester.triplets))\n",
    "eval_size = len(data_harvester.triplets) - train_size - test_size\n",
    "\n",
    "# Harvest the evaluation triplets first, since triplets are ordered by author. This will ensure that the evaluation set has authors not seen in the training set.\n",
    "eval_triplets = data_harvester.triplets[:eval_size]\n",
    "\n",
    "train_test_triplets = data_harvester.triplets[eval_size:]\n",
    "random.shuffle(train_test_triplets)\n",
    "\n",
    "train_triplets = train_test_triplets[:train_size]\n",
    "test_triplets = train_test_triplets[train_size:]\n",
    "config['train_size'] = len(train_triplets)\n",
    "config['test_size'] = len(test_triplets)\n",
    "config['eval_size'] = len(eval_triplets)\n",
    "\n",
    "print(f\"Train size: {len(train_triplets)}, Test size: {len(test_triplets)}, Eval size: {len(eval_triplets)}\")\n",
    "\n",
    "# Create the datasets from the pairs (distinct pairs for training and testing)\n",
    "train_dataset = HomogeneousGraphTripletDataset(train_triplets, gs, config=config)\n",
    "test_dataset = HomogeneousGraphTripletDataset(test_triplets, gs, config=config)\n",
    "eval_dataset = HomogeneousGraphTripletDataset(eval_triplets, gs, config=config)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=custom_triplet_collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=custom_triplet_collate)\n",
    "\n",
    "# Create model\n",
    "metadata = (\n",
    "    node_spec.value,\n",
    "    edge_spec.value\n",
    ")\n",
    "config['node_spec'] = metadata[0]\n",
    "config['edge_spec'] = metadata[1]\n",
    "model = model_class(config['hidden_channels'], config['out_channels'], num_heads=config['num_heads']).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])"
   ],
   "id": "62ef1028a5c5fd5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:04:03,782 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-11-06 13:04:03,782 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing triplets...\n",
      "Loading triplets...\n",
      "Loaded 11755 triplets.\n",
      "Train size: 9991, Test size: 1175, Eval size: 589\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:40:47.421278Z",
     "start_time": "2024-11-06T12:04:03.942522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = config['num_epochs']\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_correct_pos = []\n",
    "test_correct_neg = []\n",
    "\n",
    "eval_losses = []\n",
    "eval_accuracies = []\n",
    "eval_correct_pos = []\n",
    "eval_correct_neg = []\n",
    "\n",
    "current_batch = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"=== Epoch {epoch}/{num_epochs} ======================\")\n",
    "    epoch_marker_pos = list(range(0, len(train_dataloader) * epoch, len(train_dataloader)))\n",
    "    current_batch = 1\n",
    "    for batch_anchor, batch_pos, batch_neg in tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "        if batch_anchor is None or batch_pos is None or batch_neg is None:\n",
    "            continue\n",
    "        \n",
    "        if current_batch == 1 or current_batch == len(train_dataloader) // 2:\n",
    "            print(f\"___ Current Batch {current_batch}/{len(train_dataloader)} _________________________\")\n",
    "            # Model testing\n",
    "            print(\"    Test Results:\")\n",
    "            test_loss, test_num_correct, test_correct_pos_val, test_correct_neg_val = test(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=test_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracies.append(test_num_correct)\n",
    "            test_correct_pos.append(test_correct_pos_val)\n",
    "            test_correct_neg.append(test_correct_neg_val)\n",
    "    \n",
    "            plot_loss(test_losses, epoch_len=2, plot_title='Test Loss', plot_avg=False, plot_file=result_folder_path + '/test_loss.png')\n",
    "            plot_loss(\n",
    "                test_accuracies,\n",
    "                epoch_len=2,\n",
    "                plot_title='Test Accuracy',\n",
    "                plot_avg=False, \n",
    "                x_label='Test Iterations',\n",
    "                y_label='Accuracy',\n",
    "                line_label='Accuracy',\n",
    "                plot_file=result_folder_path + '/test_accuracy.png'\n",
    "            )\n",
    "            \n",
    "            # Model evaluation\n",
    "            print(\"    Eval Results:\")\n",
    "            eval_loss, eval_num_correct, eval_correct_pos_val, eval_correct_neg_val = evaluate(\n",
    "                model=model,\n",
    "                loss_fn=loss_fn,\n",
    "                dataloader=eval_dataloader,\n",
    "                margin=config['margin']\n",
    "            )\n",
    "            eval_losses.append(eval_loss)\n",
    "            eval_accuracies.append(eval_num_correct)\n",
    "            eval_correct_pos.append(eval_correct_pos_val)\n",
    "            eval_correct_neg.append(eval_correct_neg_val)\n",
    "            \n",
    "            plot_loss(eval_losses, epoch_len=2, plot_title='Evaluation Loss', plot_avg=False, plot_file=result_folder_path + '/eval_loss.png')\n",
    "            plot_loss(\n",
    "                eval_accuracies, \n",
    "                epoch_len=2, \n",
    "                plot_title='Evaluation Accuracy', \n",
    "                plot_avg=False, \n",
    "                x_label='Eval Iterations',\n",
    "                y_label='Accuracy',\n",
    "                line_label='Accuracy',\n",
    "                plot_file=result_folder_path + '/eval_accuracy.png'\n",
    "            )\n",
    "            \n",
    "        loss = train(\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            batch_anchor=batch_anchor,\n",
    "            batch_pos=batch_pos,\n",
    "            batch_neg=batch_neg,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        plot_loss(train_losses, epoch_len=len(train_dataloader), plot_title='Training Loss', plot_avg=True, plot_file=result_folder_path + '/train_loss.png')\n",
    "        current_batch += 1\n",
    "        \n",
    "    # Save config and training results\n",
    "    eval_results = {\n",
    "        'eval_losses': eval_losses,\n",
    "        'eval_accuracies': eval_accuracies,\n",
    "        'eval_correct_pos': eval_correct_pos,\n",
    "        'eval_correct_neg': eval_correct_neg\n",
    "    }\n",
    "    save_training_results(train_losses, test_losses, eval_results, config, result_folder_path + '/training_data.json')\n",
    "    \n",
    "    # Save model if loss has decreased\n",
    "    if len(test_losses) > 1 and test_losses[-1] < min(test_losses[:-1]):\n",
    "        print(f\"Saving model at epoch {epoch}...\")\n",
    "        torch.save(model.state_dict(), result_folder_path + '/gat_encoder.pt')"
   ],
   "id": "c3b28cd52881796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4a9548bf5a34d6aa054f75df9354b75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 1175 (100.00%), Correct negative: 0 (0.00%)\n",
      "        Total correct: 1175 (50.00%)\n",
      "        Test Loss: 1.0668, Test Accuracy: 0.5000\n",
      "    Eval Results:\n",
      "        Correct positive: 589 (100.00%), Correct negative: 0 (0.00%)\n",
      "        Total correct: 589 (50.00%)\n",
      "        Eval Loss: 1.0338, Eval Accuracy: 0.5000\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 981 (83.49%), Correct negative: 502 (42.72%)\n",
      "        Total correct: 1483 (63.11%)\n",
      "        Test Loss: 0.7659, Test Accuracy: 0.6311\n",
      "    Eval Results:\n",
      "        Correct positive: 552 (93.72%), Correct negative: 28 (4.75%)\n",
      "        Total correct: 580 (49.24%)\n",
      "        Eval Loss: 0.9873, Eval Accuracy: 0.4924\n",
      "Saving model at epoch 1...\n",
      "=== Epoch 2/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1710c262d2ea4b0391573b3cf0067bad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 887 (75.49%), Correct negative: 693 (58.98%)\n",
      "        Total correct: 1580 (67.23%)\n",
      "        Test Loss: 0.6219, Test Accuracy: 0.6723\n",
      "    Eval Results:\n",
      "        Correct positive: 517 (87.78%), Correct negative: 109 (18.51%)\n",
      "        Total correct: 626 (53.14%)\n",
      "        Eval Loss: 0.8970, Eval Accuracy: 0.5314\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 954 (81.19%), Correct negative: 631 (53.70%)\n",
      "        Total correct: 1585 (67.45%)\n",
      "        Test Loss: 0.5915, Test Accuracy: 0.6745\n",
      "    Eval Results:\n",
      "        Correct positive: 499 (84.72%), Correct negative: 156 (26.49%)\n",
      "        Total correct: 655 (55.60%)\n",
      "        Eval Loss: 0.8561, Eval Accuracy: 0.5560\n",
      "Saving model at epoch 2...\n",
      "=== Epoch 3/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff6d367145f643249646fba229214d90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 930 (79.15%), Correct negative: 752 (64.00%)\n",
      "        Total correct: 1682 (71.57%)\n",
      "        Test Loss: 0.5325, Test Accuracy: 0.7157\n",
      "    Eval Results:\n",
      "        Correct positive: 528 (89.64%), Correct negative: 86 (14.60%)\n",
      "        Total correct: 614 (52.12%)\n",
      "        Eval Loss: 0.8942, Eval Accuracy: 0.5212\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 951 (80.94%), Correct negative: 789 (67.15%)\n",
      "        Total correct: 1740 (74.04%)\n",
      "        Test Loss: 0.4609, Test Accuracy: 0.7404\n",
      "    Eval Results:\n",
      "        Correct positive: 516 (87.61%), Correct negative: 168 (28.52%)\n",
      "        Total correct: 684 (58.06%)\n",
      "        Eval Loss: 0.8367, Eval Accuracy: 0.5806\n",
      "Saving model at epoch 3...\n",
      "=== Epoch 4/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abe7406173bf4bcf862ac465ee4a5be6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 826 (70.30%), Correct negative: 890 (75.74%)\n",
      "        Total correct: 1716 (73.02%)\n",
      "        Test Loss: 0.4364, Test Accuracy: 0.7302\n",
      "    Eval Results:\n",
      "        Correct positive: 414 (70.29%), Correct negative: 217 (36.84%)\n",
      "        Total correct: 631 (53.57%)\n",
      "        Eval Loss: 0.8787, Eval Accuracy: 0.5357\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 940 (80.00%), Correct negative: 779 (66.30%)\n",
      "        Total correct: 1719 (73.15%)\n",
      "        Test Loss: 0.4695, Test Accuracy: 0.7315\n",
      "    Eval Results:\n",
      "        Correct positive: 530 (89.98%), Correct negative: 218 (37.01%)\n",
      "        Total correct: 748 (63.50%)\n",
      "        Eval Loss: 0.7733, Eval Accuracy: 0.6350\n",
      "=== Epoch 5/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e24791cf50874578bab5233f31eeffe0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 856 (72.85%), Correct negative: 910 (77.45%)\n",
      "        Total correct: 1766 (75.15%)\n",
      "        Test Loss: 0.4038, Test Accuracy: 0.7515\n",
      "    Eval Results:\n",
      "        Correct positive: 508 (86.25%), Correct negative: 131 (22.24%)\n",
      "        Total correct: 639 (54.24%)\n",
      "        Eval Loss: 0.9136, Eval Accuracy: 0.5424\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 982 (83.57%), Correct negative: 790 (67.23%)\n",
      "        Total correct: 1772 (75.40%)\n",
      "        Test Loss: 0.4138, Test Accuracy: 0.7540\n",
      "    Eval Results:\n",
      "        Correct positive: 500 (84.89%), Correct negative: 120 (20.37%)\n",
      "        Total correct: 620 (52.63%)\n",
      "        Eval Loss: 0.9694, Eval Accuracy: 0.5263\n",
      "=== Epoch 6/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e7f88c2e1fd4983901bc58ae1deaaf7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 908 (77.28%), Correct negative: 887 (75.49%)\n",
      "        Total correct: 1795 (76.38%)\n",
      "        Test Loss: 0.3787, Test Accuracy: 0.7638\n",
      "    Eval Results:\n",
      "        Correct positive: 435 (73.85%), Correct negative: 128 (21.73%)\n",
      "        Total correct: 563 (47.79%)\n",
      "        Eval Loss: 0.9634, Eval Accuracy: 0.4779\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 927 (78.89%), Correct negative: 865 (73.62%)\n",
      "        Total correct: 1792 (76.26%)\n",
      "        Test Loss: 0.3945, Test Accuracy: 0.7626\n",
      "    Eval Results:\n",
      "        Correct positive: 511 (86.76%), Correct negative: 229 (38.88%)\n",
      "        Total correct: 740 (62.82%)\n",
      "        Eval Loss: 0.7496, Eval Accuracy: 0.6282\n",
      "=== Epoch 7/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f99c3431de8477da69cfd00c36bdde0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 855 (72.77%), Correct negative: 978 (83.23%)\n",
      "        Total correct: 1833 (78.00%)\n",
      "        Test Loss: 0.3226, Test Accuracy: 0.7800\n",
      "    Eval Results:\n",
      "        Correct positive: 407 (69.10%), Correct negative: 106 (18.00%)\n",
      "        Total correct: 513 (43.55%)\n",
      "        Eval Loss: 1.1342, Eval Accuracy: 0.4355\n",
      "___ Current Batch 156/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 954 (81.19%), Correct negative: 864 (73.53%)\n",
      "        Total correct: 1818 (77.36%)\n",
      "        Test Loss: 0.3522, Test Accuracy: 0.7736\n",
      "    Eval Results:\n",
      "        Correct positive: 443 (75.21%), Correct negative: 65 (11.04%)\n",
      "        Total correct: 508 (43.12%)\n",
      "        Eval Loss: 1.1560, Eval Accuracy: 0.4312\n",
      "=== Epoch 8/10 ======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/313 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d3abd1fbdda4432bb3e592b2ba5771e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Current Batch 1/313 _________________________\n",
      "    Test Results:\n",
      "        Correct positive: 929 (79.06%), Correct negative: 939 (79.91%)\n",
      "        Total correct: 1868 (79.49%)\n",
      "        Test Loss: 0.3141, Test Accuracy: 0.7949\n",
      "    Eval Results:\n",
      "        Correct positive: 505 (85.74%), Correct negative: 55 (9.34%)\n",
      "        Total correct: 560 (47.54%)\n",
      "        Eval Loss: 1.0793, Eval Accuracy: 0.4754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m epoch_marker_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(train_dataloader) \u001B[38;5;241m*\u001B[39m epoch, \u001B[38;5;28mlen\u001B[39m(train_dataloader)))\n\u001B[1;32m     19\u001B[0m current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_anchor, batch_pos, batch_neg \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch_anchor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m batch_pos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m batch_neg \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/tqdm/notebook.py:250\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    249\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m    253\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/Git/master-thesis/notebooks/util_homogeneous.py:127\u001B[0m, in \u001B[0;36mHomogeneousGraphTripletDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    125\u001B[0m g_a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, anchor, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    126\u001B[0m g_p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgs\u001B[38;5;241m.\u001B[39mn_hop_neighbourhood(NodeType\u001B[38;5;241m.\u001B[39mPUBLICATION, pos, max_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_hops\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 127\u001B[0m g_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_hop_neighbourhood\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNodeType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPUBLICATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_hops\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;66;03m# Convert to PyG Data objects\u001B[39;00m\n\u001B[1;32m    130\u001B[0m data_a, node_map_a \u001B[38;5;241m=\u001B[39m neo_to_pyg_homogeneous(g_a, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_node_feature\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Git/master-thesis/src/shared/graph_sampling.py:55\u001B[0m, in \u001B[0;36mGraphSampling.n_hop_neighbourhood\u001B[0;34m(self, start_node_type, start_node_id, node_types, edge_types, max_level)\u001B[0m\n\u001B[1;32m     41\u001B[0m edge_filter \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     42\u001B[0m     [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m et \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_spec] \u001B[38;5;28;01mif\u001B[39;00m edge_types \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[1;32m     43\u001B[0m     [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00met\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m et \u001B[38;5;129;01min\u001B[39;00m edge_types]\n\u001B[1;32m     44\u001B[0m )\n\u001B[1;32m     46\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;124m        MATCH (start:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124mid: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_node_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124m        CALL apoc.path.subgraphAll(start, \u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;124m        RETURN nodes, relationships\u001B[39m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 55\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m data \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39msingle()\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/session.py:307\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    304\u001B[0m cx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\n\u001B[1;32m    306\u001B[0m cx\u001B[38;5;241m.\u001B[39mtelemetry(TelemetryAPI\u001B[38;5;241m.\u001B[39mAUTO_COMMIT)\n\u001B[0;32m--> 307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result \u001B[38;5;241m=\u001B[39m \u001B[43mResult\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_result_closed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_result_error\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m bookmarks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bookmarks()\n\u001B[1;32m    312\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(parameters \u001B[38;5;129;01mor\u001B[39;00m {}, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/work/result.py:86\u001B[0m, in \u001B[0;36mResult.__init__\u001B[0;34m(self, connection, fetch_size, on_closed, on_error)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, connection, fetch_size, on_closed, on_error):\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection \u001B[38;5;241m=\u001B[39m ConnectionErrorHandler(\n\u001B[1;32m     84\u001B[0m         connection, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection_error_handler\n\u001B[1;32m     85\u001B[0m     )\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hydration_scope \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_hydration_scope\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_error \u001B[38;5;241m=\u001B[39m on_error\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_closed \u001B[38;5;241m=\u001B[39m on_closed\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py:779\u001B[0m, in \u001B[0;36mBolt.new_hydration_scope\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_hydration_scope\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 779\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhydration_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_hydration_scope\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/hydration/v2/hydration_handler.py:65\u001B[0m, in \u001B[0;36mHydrationHandler.new_hydration_scope\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_hydration_scope\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_scope \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mHydrationScope\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_GraphHydrator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.anaconda3/envs/master/lib/python3.9/site-packages/neo4j/_codec/hydration/_common.py:103\u001B[0m, in \u001B[0;36mHydrationScope.__init__\u001B[0;34m(self, hydration_handler, graph_hydrator)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph_hydrator \u001B[38;5;241m=\u001B[39m graph_hydrator\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_struct_hydration_functions \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhydration_handler\u001B[38;5;241m.\u001B[39mstruct_hydration_functions,\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgraph_hydrator\u001B[38;5;241m.\u001B[39mstruct_hydration_functions,\n\u001B[1;32m    102\u001B[0m }\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhydration_hooks \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    104\u001B[0m     Structure: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hydrate_structure,\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28mlist\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hydrate_list,\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28mdict\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hydrate_dict,\n\u001B[1;32m    107\u001B[0m }\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdehydration_hooks \u001B[38;5;241m=\u001B[39m hydration_handler\u001B[38;5;241m.\u001B[39mdehydration_hooks\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
