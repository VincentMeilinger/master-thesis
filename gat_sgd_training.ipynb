{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.542935Z",
     "start_time": "2024-08-04T08:40:41.540125Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.shared.database_wrapper import DatabaseWrapper\n",
    "from src.model.GAT.gat_encoder import GATv2Encoder\n",
    "from src.model.GAT.gat_decoder import GATv2Decoder\n",
    "from src.shared.graph_schema import NodeType, EdgeType, node_one_hot, edge_one_hot\n",
    "from src.shared import config"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.554069Z",
     "start_time": "2024-08-04T08:40:41.543646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ],
   "id": "f4212cea93939031",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.582426Z",
     "start_time": "2024-08-04T08:40:41.554627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "auth = (config.DB_USER, config.DB_PASSWORD)\n",
    "gds = GraphDataScience(config.DB_URI, auth=auth)\n",
    "\n",
    "included_nodes = [\n",
    "    NodeType.PUBLICATION, \n",
    "    NodeType.VENUE, \n",
    "    NodeType.ORGANIZATION\n",
    "]\n",
    "included_edges = [\n",
    "    EdgeType.PUB_VENUE, \n",
    "    EdgeType.PUB_ORG, \n",
    "    EdgeType.SIM_VENUE,\n",
    "    EdgeType.SIM_ORG,\n",
    "    EdgeType.ORG_PUB, \n",
    "    EdgeType.VENUE_PUB\n",
    "]\n",
    "\n",
    "node_spec = [node_type.value for node_type in included_nodes]\n",
    "relationship_spec = [edge_type.value for edge_type in included_edges]"
   ],
   "id": "5533b16412bb619c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.584411Z",
     "start_time": "2024-08-04T08:40:41.583270Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2988aa59c144ade",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.587909Z",
     "start_time": "2024-08-04T08:40:41.584830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_topology(new_idx_to_old, topology):\n",
    "    # Reverse index mapping based on new idx -> old idx\n",
    "    old_idx_to_new = dict((v, k) for k, v in new_idx_to_old.items())\n",
    "    return {rel_type: [[old_idx_to_new[node_id] for node_id in nodes] for nodes in topology] for rel_type, topology in topology.items()}\n",
    "\n",
    "def create_edge_index(topology):\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for rel_type, nodes in topology.items():\n",
    "        src_nodes, dst_nodes = nodes\n",
    "        edges = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "        edge_index.append(edges)\n",
    "        edge_feature_vec = edge_one_hot[rel_type]\n",
    "        edge_features.extend([edge_feature_vec for _ in range(len(src_nodes))])\n",
    "    return torch.cat(edge_index, dim=1), torch.vstack(edge_features)\n",
    "\n",
    "def project_node_embeddings(node_df):\n",
    "    def stack_one_hot(row):\n",
    "        one_hot_enc = node_one_hot[row[\"nodeLabels\"][0]]\n",
    "        return torch.hstack((one_hot_enc, torch.tensor(row[\"vec\"])))\n",
    "    return node_df.apply(stack_one_hot, axis=1)\n"
   ],
   "id": "7af7c76c9910e14a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.598822Z",
     "start_time": "2024-08-04T08:40:41.588426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "driver = GraphDatabase.driver(config.DB_URI, auth=(config.DB_USER, config.DB_PASSWORD))\n",
    "\n",
    "def fetch_n_hop_neighbourhood(start_node_type: NodeType, start_node_id: str, node_attr: str, node_types: list = None, edge_types: list = None, max_level: int = 6):\n",
    "    with driver.session() as session:\n",
    "        node_filter = '|'.join(\n",
    "            [nt.value for nt in NodeType] if node_types is None else \n",
    "            [nt.value for nt in node_types]\n",
    "        )\n",
    "        edge_filter = '|'.join(\n",
    "            [et.value for et in EdgeType] if edge_types is None else \n",
    "            [et.value for et in edge_types]\n",
    "        )\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                MATCH (start:{start_node_type.value} {{id: '{start_node_id}'}})\n",
    "                CALL apoc.path.subgraphAll(start, {{\n",
    "                  maxLevel: {max_level},\n",
    "                  relationshipFilter: '<{edge_filter}>',\n",
    "                  labelFilter: '+{node_filter}'\n",
    "                }}) YIELD nodes, relationships\n",
    "                RETURN nodes, relationships\n",
    "            \"\"\"\n",
    "        result = session.run(query)\n",
    "        data = result.single()\n",
    "        nodes = data[\"nodes\"]\n",
    "        relationships = data[\"relationships\"]\n",
    "\n",
    "        # Process nodes\n",
    "        node_data = []\n",
    "        for node in nodes:\n",
    "            node_id = node.get(\"id\")\n",
    "            attr = node.get(node_attr, None)\n",
    "            node_data.append({\"nodeId\": node_id, node_attr: attr, \"nodeLabels\": list(node.labels)})\n",
    "        \n",
    "        node_df = pd.DataFrame(node_data)\n",
    "        \n",
    "        # Process relationships\n",
    "        edge_dict = {}\n",
    "        for rel in relationships:\n",
    "            if rel.type not in edge_dict:\n",
    "                edge_dict[rel.type] = [[], []]\n",
    "            source_id = rel.start_node.get(\"id\")\n",
    "            target_id = rel.end_node.get(\"id\")\n",
    "            \n",
    "            edge_dict[rel.type][0].append(source_id)\n",
    "            edge_dict[rel.type][1].append(target_id)\n",
    "    \n",
    "    return node_df, edge_dict\n",
    "        \n"
   ],
   "id": "ecf63735832cd563",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:40:41.613300Z",
     "start_time": "2024-08-04T08:40:41.599414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_subgraph(node_list):\n",
    "    dataset = []\n",
    "    for node_id in node_list:\n",
    "        node_df, topology = fetch_n_hop_neighbourhood(\n",
    "            start_node_type=NodeType.PUBLICATION, \n",
    "            start_node_id=node_id, \n",
    "            node_attr=\"vec\",\n",
    "            node_types=included_nodes,\n",
    "            edge_types=included_edges,\n",
    "            max_level=5\n",
    "        )\n",
    "        node_df[\"vec_projected\"] = project_node_embeddings(node_df)\n",
    "        normalized_node_ids = {new_idx: old_idx for new_idx, old_idx in enumerate(node_df[\"nodeId\"])}\n",
    "        normalized_topology = normalize_topology(normalized_node_ids, topology)\n",
    "        if len(normalized_topology) == 0:\n",
    "            continue\n",
    "            \n",
    "        edge_index, edge_features = create_edge_index(normalized_topology)\n",
    "        node_features = torch.vstack(node_df[\"vec_projected\"].tolist())\n",
    "        \n",
    "        dataset.append(Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features\n",
    "        ))\n",
    "    return DataLoader(dataset)"
   ],
   "id": "16465ddeb3ddcffb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:41:17.923980Z",
     "start_time": "2024-08-04T08:40:41.613824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_wrapper = DatabaseWrapper()\n",
    "start_nodes = []\n",
    "for nodes in db_wrapper.iter_nodes(NodeType.PUBLICATION, [\"id\"]):\n",
    "    for node in nodes:\n",
    "        start_nodes.append(node[\"id\"])\n",
    "        \n",
    "    break\n",
    "dataset = sample_subgraph(start_nodes)"
   ],
   "id": "dc0cbea84e93fb80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 10:40:41,627 - DatabaseWrapper - INFO - Connecting to the database ...\n",
      "2024-08-04 10:40:41,627 - DatabaseWrapper - INFO - Database ready.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T08:41:18.009623Z",
     "start_time": "2024-08-04T08:41:17.924952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_feature_dim = 38\n",
    "edge_feature_dim = EdgeType.PUB_YEAR.one_hot().shape[0]\n",
    "gat_embedding_dim = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "encoder = GATv2Encoder(\n",
    "    in_channels=node_feature_dim,\n",
    "    out_channels=gat_embedding_dim,\n",
    "    edge_dim=edge_feature_dim,\n",
    "    add_self_loops=False\n",
    ")\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = GATv2Decoder(\n",
    "    in_channels=gat_embedding_dim,\n",
    "    out_channels=node_feature_dim\n",
    ")\n",
    "decoder.to(device)"
   ],
   "id": "65cda043db9a88fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GATv2Decoder(\n",
       "  (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T09:04:05.294984Z",
     "start_time": "2024-08-04T08:41:18.010143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_gat(encoder, decoder, dataloader, epochs=1000, lr=0.01):\n",
    "    # Define the optimizer for the encoder and decoder\n",
    "    optimizer = optim.SGD(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "    \n",
    "    # Define a loss function\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            batch.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the encoder\n",
    "            encoded_nodes = encoder(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "            # Forward pass through the decoder\n",
    "            decoded_graph = decoder(encoded_nodes, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "            # Compute loss (assuming your decoder returns node features to be compared with the original)\n",
    "            loss = criterion(decoded_graph, batch.x)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "\n",
    "train_gat(encoder, decoder, dataset)\n"
   ],
   "id": "921a79247a6e9d92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.6991263862904902\n",
      "Epoch 10, Loss: 0.7182479475329562\n",
      "Epoch 20, Loss: 0.6474938346539291\n",
      "Epoch 30, Loss: 0.6019467816655841\n",
      "Epoch 40, Loss: 0.5914328539402096\n",
      "Epoch 50, Loss: 0.5862988346903101\n",
      "Epoch 60, Loss: 0.5829303072758296\n",
      "Epoch 70, Loss: 0.5797445497957365\n",
      "Epoch 80, Loss: 0.5682526034839805\n",
      "Epoch 90, Loss: 0.5630976225372609\n",
      "Epoch 100, Loss: 0.5603424912660511\n",
      "Epoch 110, Loss: 0.5584748582448212\n",
      "Epoch 120, Loss: 0.5572052574853995\n",
      "Epoch 130, Loss: 0.5562624087573934\n",
      "Epoch 140, Loss: 0.5555271729539999\n",
      "Epoch 150, Loss: 0.5549195307822221\n",
      "Epoch 160, Loss: 0.5543473370000241\n",
      "Epoch 170, Loss: 0.5538498581182666\n",
      "Epoch 180, Loss: 0.5533817627960972\n",
      "Epoch 190, Loss: 0.5529147990631353\n",
      "Epoch 200, Loss: 0.5524237294213916\n",
      "Epoch 210, Loss: 0.5519596584456876\n",
      "Epoch 220, Loss: 0.5514514290743217\n",
      "Epoch 230, Loss: 0.5509896007711989\n",
      "Epoch 240, Loss: 0.5505499010750203\n",
      "Epoch 250, Loss: 0.550146761310881\n",
      "Epoch 260, Loss: 0.549777979090982\n",
      "Epoch 270, Loss: 0.5494318231462055\n",
      "Epoch 280, Loss: 0.5490892633164495\n",
      "Epoch 290, Loss: 0.5488255803828368\n",
      "Epoch 300, Loss: 0.5485718555949313\n",
      "Epoch 310, Loss: 0.548306884562097\n",
      "Epoch 320, Loss: 0.5480756342449299\n",
      "Epoch 330, Loss: 0.5478685449077167\n",
      "Epoch 340, Loss: 0.5476694082188515\n",
      "Epoch 350, Loss: 0.547481618391228\n",
      "Epoch 360, Loss: 0.5472979539663403\n",
      "Epoch 370, Loss: 0.5471224294394369\n",
      "Epoch 380, Loss: 0.5469596179749755\n",
      "Epoch 390, Loss: 0.5468031396953071\n",
      "Epoch 400, Loss: 0.5466492461262986\n",
      "Epoch 410, Loss: 0.5464996733010504\n",
      "Epoch 420, Loss: 0.5463537818277602\n",
      "Epoch 430, Loss: 0.5462125790555302\n",
      "Epoch 440, Loss: 0.5460893358552257\n",
      "Epoch 450, Loss: 0.5459522893975115\n",
      "Epoch 460, Loss: 0.5458087783416826\n",
      "Epoch 470, Loss: 0.54568870025131\n",
      "Epoch 480, Loss: 0.5455714991753765\n",
      "Epoch 490, Loss: 0.5454614533922026\n",
      "Epoch 500, Loss: 0.5453751077433147\n",
      "Epoch 510, Loss: 0.5452726036310196\n",
      "Epoch 520, Loss: 0.5451618417887082\n",
      "Epoch 530, Loss: 0.5451016562664462\n",
      "Epoch 540, Loss: 0.5449999602026138\n",
      "Epoch 550, Loss: 0.5449176391488627\n",
      "Epoch 560, Loss: 0.5448317657462746\n",
      "Epoch 570, Loss: 0.5447741384415938\n",
      "Epoch 580, Loss: 0.5446961603781378\n",
      "Epoch 590, Loss: 0.5446157830364438\n",
      "Epoch 600, Loss: 0.5445725295563565\n",
      "Epoch 610, Loss: 0.5445020775548607\n",
      "Epoch 620, Loss: 0.5444271528330633\n",
      "Epoch 630, Loss: 0.5443827440634619\n",
      "Epoch 640, Loss: 0.5443226369683641\n",
      "Epoch 650, Loss: 0.5442603019296893\n",
      "Epoch 660, Loss: 0.5441805319203032\n",
      "Epoch 670, Loss: 0.5441455987971922\n",
      "Epoch 680, Loss: 0.5440927104634712\n",
      "Epoch 690, Loss: 0.5440309767698599\n",
      "Epoch 700, Loss: 0.543942729740455\n",
      "Epoch 710, Loss: 0.5439294128079776\n",
      "Epoch 720, Loss: 0.5438669276291048\n",
      "Epoch 730, Loss: 0.5438154869651917\n",
      "Epoch 740, Loss: 0.5437751000744694\n",
      "Epoch 750, Loss: 0.5437198457653624\n",
      "Epoch 760, Loss: 0.5436704134107095\n",
      "Epoch 770, Loss: 0.5436146276906152\n",
      "Epoch 780, Loss: 0.5435792367250225\n",
      "Epoch 790, Loss: 0.5435228510371222\n",
      "Epoch 800, Loss: 0.5434736314113701\n",
      "Epoch 810, Loss: 0.5434159154074795\n",
      "Epoch 820, Loss: 0.5433535126153862\n",
      "Epoch 830, Loss: 0.5433158179379244\n",
      "Epoch 840, Loss: 0.5432487460324332\n",
      "Epoch 850, Loss: 0.5432088583593038\n",
      "Epoch 860, Loss: 0.5431386922343857\n",
      "Epoch 870, Loss: 0.5431237553601393\n",
      "Epoch 880, Loss: 0.5430881387729853\n",
      "Epoch 890, Loss: 0.5430548554322226\n",
      "Epoch 900, Loss: 0.5429902864435977\n",
      "Epoch 910, Loss: 0.5429702880523324\n",
      "Epoch 920, Loss: 0.5429315538132451\n",
      "Epoch 930, Loss: 0.5428973413975157\n",
      "Epoch 940, Loss: 0.5428071992235098\n",
      "Epoch 950, Loss: 0.5428138927333009\n",
      "Epoch 960, Loss: 0.5427659308114621\n",
      "Epoch 970, Loss: 0.542717898419947\n",
      "Epoch 980, Loss: 0.5426862982982849\n",
      "Epoch 990, Loss: 0.5426283974932156\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T09:04:05.296870Z",
     "start_time": "2024-08-04T09:04:05.295591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "27f06580ae97a378",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
